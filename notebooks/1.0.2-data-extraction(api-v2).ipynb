{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Twitter Data Extraction (Twitter API v2)\n",
    "Monthly data extraction from Twitter API guided by the following [plan](https://docs.google.com/document/d/1d_4WeDetmZUkk9JJUEWiqqZaBaFsxy1ZDFNiL0JVaok/edit?usp=sharing) | [ISP Selection Guidelines](https://docs.google.com/document/d/12n9hZNdCLmrIVfK05MCa1CUhEYoCR9Ib0fPnxQZql_E/edit?usp=sharing) | [Twitter API Operators](https://developer.twitter.com/en/docs/twitter-api/tweets/search/integrate/build-a-query#limits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting git+https://github.com/tweepy/tweepy.git\n",
      "  Cloning https://github.com/tweepy/tweepy.git to /private/var/folders/j5/540q0bw12gx3g56qg4llbmlh0000gn/T/pip-req-build-jjxw37fx\n",
      "  Running command git clone -q https://github.com/tweepy/tweepy.git /private/var/folders/j5/540q0bw12gx3g56qg4llbmlh0000gn/T/pip-req-build-jjxw37fx\n",
      "  Resolved https://github.com/tweepy/tweepy.git to commit 277a739863f099be084f084d6f064712401d9579\n",
      "Requirement already satisfied: requests<3,>=2.11.1 in /Users/koredeakande/opt/anaconda3/lib/python3.7/site-packages (from tweepy==4.0.0) (2.26.0)\n",
      "Requirement already satisfied: requests_oauthlib<2,>=1.0.0 in /Users/koredeakande/opt/anaconda3/lib/python3.7/site-packages (from tweepy==4.0.0) (1.3.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/koredeakande/opt/anaconda3/lib/python3.7/site-packages (from requests<3,>=2.11.1->tweepy==4.0.0) (2.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /Users/koredeakande/opt/anaconda3/lib/python3.7/site-packages (from requests<3,>=2.11.1->tweepy==4.0.0) (2.0.5)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/koredeakande/opt/anaconda3/lib/python3.7/site-packages (from requests<3,>=2.11.1->tweepy==4.0.0) (1.25.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/koredeakande/opt/anaconda3/lib/python3.7/site-packages (from requests<3,>=2.11.1->tweepy==4.0.0) (2019.11.28)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /Users/koredeakande/opt/anaconda3/lib/python3.7/site-packages (from requests_oauthlib<2,>=1.0.0->tweepy==4.0.0) (3.1.0)\n"
     ]
    }
   ],
   "source": [
    "#Tweepy v4 not yet merged to master as of 28/09/2021 â€“ Install directly from Github\n",
    "!pip install git+https://github.com/tweepy/tweepy.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tweepy==4.0.0 in /Users/koredeakande/opt/anaconda3/lib/python3.7/site-packages (4.0.0)\n",
      "Requirement already satisfied: requests<3,>=2.11.1 in /Users/koredeakande/opt/anaconda3/lib/python3.7/site-packages (from tweepy==4.0.0) (2.26.0)\n",
      "Requirement already satisfied: requests-oauthlib<2,>=1.0.0 in /Users/koredeakande/opt/anaconda3/lib/python3.7/site-packages (from tweepy==4.0.0) (1.3.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/koredeakande/opt/anaconda3/lib/python3.7/site-packages (from requests<3,>=2.11.1->tweepy==4.0.0) (1.25.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /Users/koredeakande/opt/anaconda3/lib/python3.7/site-packages (from requests<3,>=2.11.1->tweepy==4.0.0) (2.0.5)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/koredeakande/opt/anaconda3/lib/python3.7/site-packages (from requests<3,>=2.11.1->tweepy==4.0.0) (2.8)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/koredeakande/opt/anaconda3/lib/python3.7/site-packages (from requests<3,>=2.11.1->tweepy==4.0.0) (2019.11.28)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /Users/koredeakande/opt/anaconda3/lib/python3.7/site-packages (from requests-oauthlib<2,>=1.0.0->tweepy==4.0.0) (3.1.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install tweepy==4.0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import relevant libraries\n",
    "import tweepy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tweepy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'tweepy' has no attribute 'Client'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-8bfc72aca8f6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtweepy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mClient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: module 'tweepy' has no attribute 'Client'"
     ]
    }
   ],
   "source": [
    "tweepy.Client()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "absl-py==0.11.0\r\n",
      "alabaster==0.7.12\r\n",
      "anaconda-client==1.7.2\r\n",
      "anaconda-navigator==1.9.12\r\n",
      "anaconda-project==0.8.3\r\n",
      "applaunchservices==0.2.1\r\n",
      "appnope==0.1.0\r\n",
      "appscript==1.0.1\r\n",
      "argh==0.26.2\r\n",
      "arrow==1.1.1\r\n",
      "asn1crypto==1.3.0\r\n",
      "astroid==2.4.2\r\n",
      "astropy==4.0\r\n",
      "astunparse==1.6.3\r\n",
      "atomicwrites==1.3.0\r\n",
      "attrs==19.3.0\r\n",
      "Automat==20.2.0\r\n",
      "autopep8==1.4.4\r\n",
      "Babel==2.8.0\r\n",
      "backcall==0.1.0\r\n",
      "backports.functools-lru-cache==1.6.1\r\n",
      "backports.shutil-get-terminal-size==1.0.0\r\n",
      "backports.tempfile==1.0\r\n",
      "backports.weakref==1.0.post1\r\n",
      "beautifulsoup4==4.8.2\r\n",
      "binaryornot==0.4.4\r\n",
      "bitarray==1.2.1\r\n",
      "bkcharts==0.2\r\n",
      "bleach==3.1.0\r\n",
      "bokeh==1.4.0\r\n",
      "boto==2.49.0\r\n",
      "Bottleneck==1.3.2\r\n",
      "Brotli==1.0.9\r\n",
      "cachetools==4.2.0\r\n",
      "certifi==2019.11.28\r\n",
      "cffi==1.14.0\r\n",
      "chardet==3.0.4\r\n",
      "charset-normalizer==2.0.5\r\n",
      "Click==7.0\r\n",
      "cloudpickle==1.3.0\r\n",
      "clyent==1.2.2\r\n",
      "colorama==0.4.3\r\n",
      "conda==4.9.2\r\n",
      "conda-build==3.18.11\r\n",
      "conda-package-handling==1.6.0\r\n",
      "conda-verify==3.4.2\r\n",
      "constantly==15.1.0\r\n",
      "contextlib2==0.6.0.post1\r\n",
      "cookiecutter==1.7.3\r\n",
      "cryptography==2.8\r\n",
      "cssselect==1.1.0\r\n",
      "cycler==0.10.0\r\n",
      "Cython==0.29.15\r\n",
      "cytoolz==0.10.1\r\n",
      "dash==1.20.0\r\n",
      "dash-core-components==1.16.0\r\n",
      "dash-html-components==1.1.3\r\n",
      "dash-renderer==1.9.1\r\n",
      "dash-table==4.11.3\r\n",
      "dask==2.11.0\r\n",
      "decorator==4.4.1\r\n",
      "defusedxml==0.6.0\r\n",
      "delayed==0.11.0b1\r\n",
      "diff-match-patch==20181111\r\n",
      "distributed==2.11.0\r\n",
      "docutils==0.16\r\n",
      "entrypoints==0.3\r\n",
      "et-xmlfile==1.0.1\r\n",
      "fastcache==1.1.0\r\n",
      "filelock==3.0.12\r\n",
      "flake8==3.7.9\r\n",
      "Flask==1.1.1\r\n",
      "Flask-Compress==1.9.0\r\n",
      "flatbuffers==1.12\r\n",
      "fsspec==0.6.2\r\n",
      "future==0.18.2\r\n",
      "gast==0.3.3\r\n",
      "gevent==1.4.0\r\n",
      "gitdb==4.0.5\r\n",
      "GitPython==3.1.11\r\n",
      "glob2==0.7\r\n",
      "gmpy2==2.0.8\r\n",
      "google-auth==1.24.0\r\n",
      "google-auth-oauthlib==0.4.2\r\n",
      "google-pasta==0.2.0\r\n",
      "greenlet==0.4.15\r\n",
      "grpcio==1.32.0\r\n",
      "h5py==2.10.0\r\n",
      "HeapDict==1.0.1\r\n",
      "hiredis==2.0.0\r\n",
      "html5lib==1.0.1\r\n",
      "htmlmin==0.1.12\r\n",
      "hyperlink==19.0.0\r\n",
      "hypothesis==5.5.4\r\n",
      "idna==2.8\r\n",
      "ImageHash==4.2.1\r\n",
      "imageio==2.6.1\r\n",
      "imagesize==1.2.0\r\n",
      "importlib-metadata==1.5.0\r\n",
      "incremental==17.5.0\r\n",
      "intervaltree==3.0.2\r\n",
      "ipykernel==5.1.4\r\n",
      "ipython==7.12.0\r\n",
      "ipython_genutils==0.2.0\r\n",
      "ipywidgets==7.5.1\r\n",
      "isort==4.3.21\r\n",
      "itemadapter==0.1.0\r\n",
      "itsdangerous==1.1.0\r\n",
      "jdcal==1.4.1\r\n",
      "jedi==0.14.1\r\n",
      "Jinja2==2.11.1\r\n",
      "jinja2-time==0.2.0\r\n",
      "joblib==0.14.1\r\n",
      "json5==0.9.1\r\n",
      "jsonschema==3.2.0\r\n",
      "jupyter==1.0.0\r\n",
      "jupyter-client==7.0.2\r\n",
      "jupyter-console==6.1.0\r\n",
      "jupyter-core==4.7.1\r\n",
      "jupyterlab==1.2.6\r\n",
      "jupyterlab-server==1.0.6\r\n",
      "Keras==2.4.3\r\n",
      "Keras-Preprocessing==1.1.2\r\n",
      "keyring==21.1.0\r\n",
      "kiwisolver==1.1.0\r\n",
      "lazy-object-proxy==1.4.3\r\n",
      "libarchive-c==2.8\r\n",
      "lief==0.9.0\r\n",
      "line-profiler==3.0.2\r\n",
      "llvmlite==0.31.0\r\n",
      "locket==0.2.0\r\n",
      "lxml==4.5.0\r\n",
      "Markdown==3.3.3\r\n",
      "MarkupSafe==1.1.1\r\n",
      "matplotlib==3.4.3\r\n",
      "mccabe==0.6.1\r\n",
      "memory-profiler==0.57.0\r\n",
      "missingno==0.5.0\r\n",
      "mistune==0.8.4\r\n",
      "mkl-fft==1.0.15\r\n",
      "mkl-random==1.1.0\r\n",
      "mkl-service==2.3.0\r\n",
      "mock==4.0.1\r\n",
      "more-itertools==8.2.0\r\n",
      "mpmath==1.1.0\r\n",
      "msgpack==0.6.1\r\n",
      "multimethod==1.4\r\n",
      "multipledispatch==0.6.0\r\n",
      "navigator-updater==0.2.1\r\n",
      "nbconvert==5.6.1\r\n",
      "nbformat==5.0.4\r\n",
      "nest-asyncio==1.5.1\r\n",
      "networkx==2.4\r\n",
      "nltk==3.4.5\r\n",
      "nose==1.3.7\r\n",
      "notebook==6.0.3\r\n",
      "numba==0.48.0\r\n",
      "numexpr==2.7.1\r\n",
      "numpy==1.19.4\r\n",
      "numpydoc==0.9.2\r\n",
      "oauthlib==3.1.0\r\n",
      "olefile==0.46\r\n",
      "openpyxl==3.0.3\r\n",
      "opt-einsum==3.3.0\r\n",
      "packaging==20.1\r\n",
      "pandas==1.3.3\r\n",
      "pandas-profiling==3.0.0\r\n",
      "pandocfilters==1.4.2\r\n",
      "parsel==1.6.0\r\n",
      "parso==0.5.2\r\n",
      "partd==1.1.0\r\n",
      "path==13.1.0\r\n",
      "pathlib2==2.3.5\r\n",
      "pathtools==0.1.2\r\n",
      "patsy==0.5.1\r\n",
      "pep8==1.7.1\r\n",
      "pexpect==4.8.0\r\n",
      "phik==0.12.0\r\n",
      "pickleshare==0.7.5\r\n",
      "Pillow==7.0.0\r\n",
      "pkginfo==1.5.0.1\r\n",
      "plotly==4.14.3\r\n",
      "pluggy==0.13.1\r\n",
      "ply==3.11\r\n",
      "poyo==0.5.0\r\n",
      "prometheus-client==0.7.1\r\n",
      "prompt-toolkit==3.0.3\r\n",
      "Protego==0.1.16\r\n",
      "protobuf==3.14.0\r\n",
      "psutil==5.6.7\r\n",
      "ptyprocess==0.6.0\r\n",
      "py==1.8.1\r\n",
      "pyaml==21.8.3\r\n",
      "pyasn1==0.4.8\r\n",
      "pyasn1-modules==0.2.8\r\n",
      "pycodestyle==2.5.0\r\n",
      "pycosat==0.6.3\r\n",
      "pycparser==2.19\r\n",
      "pycrypto==2.6.1\r\n",
      "pycurl==7.43.0.5\r\n",
      "pydantic==1.8.2\r\n",
      "PyDispatcher==2.0.5\r\n",
      "pydocstyle==4.0.1\r\n",
      "pyflakes==2.1.1\r\n",
      "pygame==1.9.6\r\n",
      "Pygments==2.5.2\r\n",
      "PyHamcrest==2.0.2\r\n",
      "pylint==2.5.3\r\n",
      "pyodbc===4.0.0-unsupported\r\n",
      "pyOpenSSL==19.1.0\r\n",
      "pyparsing==2.4.6\r\n",
      "pyrsistent==0.15.7\r\n",
      "PySocks==1.7.1\r\n",
      "pystan==2.19.1.1\r\n",
      "pyswip==0.2.10\r\n",
      "pytest==5.3.5\r\n",
      "pytest-arraydiff==0.3\r\n",
      "pytest-astropy==0.8.0\r\n",
      "pytest-astropy-header==0.1.2\r\n",
      "pytest-doctestplus==0.5.0\r\n",
      "pytest-openfiles==0.4.0\r\n",
      "pytest-remotedata==0.3.2\r\n",
      "python-dateutil==2.8.1\r\n",
      "python-jsonrpc-server==0.3.4\r\n",
      "python-language-server==0.31.7\r\n",
      "python-resize-image==1.1.19\r\n",
      "python-slugify==5.0.2\r\n",
      "pytz==2019.3\r\n",
      "PyWavelets==1.1.1\r\n",
      "PyYAML==5.3\r\n",
      "pyzmq==18.1.1\r\n",
      "QDarkStyle==2.8\r\n",
      "QtAwesome==0.6.1\r\n",
      "qtconsole==4.6.0\r\n",
      "QtPy==1.9.0\r\n",
      "queuelib==1.5.0\r\n",
      "redis==3.5.3\r\n",
      "requests==2.26.0\r\n",
      "requests-oauthlib==1.3.0\r\n",
      "retrying==1.3.3\r\n",
      "rope==0.16.0\r\n",
      "rsa==4.6\r\n",
      "Rtree==0.9.3\r\n",
      "ruamel_yaml==0.15.87\r\n",
      "scikit-image==0.16.2\r\n",
      "scikit-learn==0.24.2\r\n",
      "scikit-optimize==0.8.1\r\n",
      "scipy==1.7.1\r\n",
      "Scrapy==2.2.1\r\n",
      "seaborn==0.11.2\r\n",
      "selenium==3.141.0\r\n",
      "Send2Trash==1.5.0\r\n",
      "service-identity==18.1.0\r\n",
      "simplegeneric==0.8.1\r\n",
      "singledispatch==3.4.0.3\r\n",
      "six==1.15.0\r\n",
      "sklearn-pandas==2.2.0\r\n",
      "smmap==3.0.4\r\n",
      "snowballstemmer==2.0.0\r\n",
      "sortedcollections==1.1.2\r\n",
      "sortedcontainers==2.1.0\r\n",
      "soupsieve==1.9.5\r\n",
      "Sphinx==2.4.0\r\n",
      "sphinxcontrib-applehelp==1.0.1\r\n",
      "sphinxcontrib-devhelp==1.0.1\r\n",
      "sphinxcontrib-htmlhelp==1.0.2\r\n",
      "sphinxcontrib-jsmath==1.0.1\r\n",
      "sphinxcontrib-qthelp==1.0.2\r\n",
      "sphinxcontrib-serializinghtml==1.1.3\r\n",
      "sphinxcontrib-websupport==1.2.0\r\n",
      "spyder==4.0.1\r\n",
      "spyder-kernels==1.8.1\r\n",
      "SQLAlchemy==1.3.13\r\n",
      "statsmodels==0.11.0\r\n",
      "sympy==1.5.1\r\n",
      "tables==3.6.1\r\n",
      "tabulate==0.8.7\r\n",
      "tangled-up-in-unicode==0.1.0\r\n",
      "tblib==1.6.0\r\n",
      "tensorboard==2.4.0\r\n",
      "tensorboard-plugin-wit==1.7.0\r\n",
      "tensorflow==2.4.0\r\n",
      "tensorflow-estimator==2.4.0\r\n",
      "termcolor==1.1.0\r\n",
      "terminado==0.8.3\r\n",
      "testpath==0.4.4\r\n",
      "text-unidecode==1.3\r\n",
      "textblob==0.15.3\r\n",
      "threadpoolctl==2.2.0\r\n",
      "toml==0.10.1\r\n",
      "toolz==0.10.0\r\n",
      "tornado==6.0.3\r\n",
      "tqdm==4.62.2\r\n",
      "traitlets==4.3.3\r\n",
      "tweepy @ file:///Users/koredeakande/tweepy\r\n",
      "Twisted==20.3.0\r\n",
      "typed-ast==1.4.1\r\n",
      "typing-extensions==3.7.4.3\r\n",
      "ujson==1.35\r\n",
      "unicodecsv==0.14.1\r\n",
      "urllib3==1.25.8\r\n",
      "visions==0.7.1\r\n",
      "w3lib==1.22.0\r\n",
      "watchdog==0.10.2\r\n",
      "wcwidth==0.1.8\r\n",
      "webencodings==0.5.1\r\n",
      "Werkzeug==1.0.0\r\n",
      "widgetsnbextension==3.5.1\r\n",
      "wrapt==1.12.1\r\n",
      "wurlitzer==2.0.0\r\n",
      "xlrd==1.2.0\r\n",
      "XlsxWriter==1.2.7\r\n",
      "xlwings==0.17.1\r\n",
      "xlwt==1.3.0\r\n",
      "xmltodict==0.12.0\r\n",
      "yapf==0.28.0\r\n",
      "zict==1.0.0\r\n",
      "zipp==2.2.0\r\n",
      "zope.interface==5.1.0\r\n"
     ]
    }
   ],
   "source": [
    "!pip freeze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'tweepy'...\n",
      "remote: Enumerating objects: 11839, done.\u001b[K\n",
      "remote: Counting objects: 100% (2282/2282), done.\u001b[K\n",
      "remote: Compressing objects: 100% (722/722), done.\u001b[K\n",
      "remote: Total 11839 (delta 1698), reused 2131 (delta 1551), pack-reused 9557\u001b[K\n",
      "Receiving objects: 100% (11839/11839), 12.27 MiB | 1.88 MiB/s, done.\n",
      "Resolving deltas: 100% (8299/8299), done.\n",
      "\u001b[31mERROR: Directory '.' is not installable. Neither 'setup.py' nor 'pyproject.toml' found.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/tweepy/tweepy.git\n",
    "!cd tweepy\n",
    "!pip install ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import the twitter credentials stored in a separate file\n",
    "#%run ../src/credentials/twitter_credentials\n",
    "%run ../src/credentials/alt_twitter_credentials\n",
    "\n",
    "#Create the authentication object\n",
    "auth = tweepy.OAuthHandler(api_key,api_secret_key)\n",
    "\n",
    "#Set the access token and access token secret\n",
    "auth.set_access_token(access_token,access_token_secret)\n",
    "\n",
    "#Create the API object\n",
    "api = tweepy.API(auth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tweepy in /Users/koredeakande/opt/anaconda3/lib/python3.7/site-packages (3.10.0)\n",
      "Requirement already satisfied: six>=1.10.0 in /Users/koredeakande/opt/anaconda3/lib/python3.7/site-packages (from tweepy) (1.15.0)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /Users/koredeakande/opt/anaconda3/lib/python3.7/site-packages (from tweepy) (1.3.0)\n",
      "Requirement already satisfied: requests[socks]>=2.11.1 in /Users/koredeakande/opt/anaconda3/lib/python3.7/site-packages (from tweepy) (2.26.0)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /Users/koredeakande/opt/anaconda3/lib/python3.7/site-packages (from requests-oauthlib>=0.7.0->tweepy) (3.1.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/koredeakande/opt/anaconda3/lib/python3.7/site-packages (from requests[socks]>=2.11.1->tweepy) (2.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /Users/koredeakande/opt/anaconda3/lib/python3.7/site-packages (from requests[socks]>=2.11.1->tweepy) (2.0.5)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/koredeakande/opt/anaconda3/lib/python3.7/site-packages (from requests[socks]>=2.11.1->tweepy) (2019.11.28)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/koredeakande/opt/anaconda3/lib/python3.7/site-packages (from requests[socks]>=2.11.1->tweepy) (1.25.8)\n",
      "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /Users/koredeakande/opt/anaconda3/lib/python3.7/site-packages (from requests[socks]>=2.11.1->tweepy) (1.7.1)\n"
     ]
    }
   ],
   "source": [
    "tweepy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'tweepy' has no attribute 'Client'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-8cd56a96aafe>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtweepy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mClient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: module 'tweepy' has no attribute 'Client'"
     ]
    }
   ],
   "source": [
    "tweepy.Client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. SETTING UP & CONNECTING TO THE API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def authenticate():\n",
    "    \n",
    "    \"\"\"\n",
    "    Function to handle API connection, setup and authentication\n",
    "    \"\"\"\n",
    "    \n",
    "    #Import the twitter credentials stored in a separate file\n",
    "    %run ../src/credentials/alt_twitter_credentials\n",
    "    \n",
    "    #Create the authentication object\n",
    "    auth = tweepy.OAuthHandler(api_key,api_secret_key)\n",
    "\n",
    "    #Set the access token and access token secret\n",
    "    auth.set_access_token(access_token,access_token_secret)\n",
    "\n",
    "    #Create the API object\n",
    "    api = tweepy.API(auth)  \n",
    "    \n",
    "    return api"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. SPECIFYING VARIABLES FOR THE DATA EXTRACTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Dev environment for the full archive endpoint (allows access to all tweets overtime)\n",
    "dev_env = 'prod'\n",
    "\n",
    "#THE BELOW SPECIFY HANDLES MANAGED BY THE ISPs or HANDLES THAT APPEAR TO TWEET BRAND PROMOTIONAL CONTENT\n",
    "#TWEETS FROM THESE HANDLES WILL BE AVOIDED WHEN EXTRACTING\n",
    "#Note: It is infeasible to address all cases. However, we would expect such tweets to be in the minority\n",
    "\n",
    "#Spectranet ISP\n",
    "spectranet_handles = ['-from:spectranet_NG','Spectr_net','SPECTRANETLTE','spectranet__NG']\n",
    "\n",
    "#IPNX ISP\n",
    "ipnx_handles = ['-from:ipNXTweet','IpnxSupport','iRecruite']\n",
    "\n",
    "#Tizeti (Wifi.ng) ISP\n",
    "tizeti_handles = ['-from:tizeti','wifisupport1']\n",
    "\n",
    "#Cobranet ISP\n",
    "cobranet_handles = ['-from:Cobranetisp']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Extracting the Tweets\n",
    "\n",
    "#### Splitting the yearly quarters from which data will be extracted into subintervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def date_range(start, end, intv):\n",
    "    \n",
    "    \"\"\"\n",
    "    Split Date Range into Roughly Equal Sub Intervals. Adapted from StackOverflow answer by Abhijit(2015)\n",
    "    Retrieved from https://stackoverflow.com/questions/29721228\n",
    "    \n",
    "    Inputs\n",
    "        - start (str): The start date of the time period\n",
    "        - end (str): The end date of the time period\n",
    "        - intv (int): Interval size (i.e. split the duration into roughly 'intv' equal subintervals)\n",
    "        \n",
    "    Outputs\n",
    "        - Generator object containing the subinterval dates\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    #Convert start date to datetime object\n",
    "    start = datetime.strptime(start,\"%Y%m%d\")\n",
    "    \n",
    "    #Convert end date to datetime object\n",
    "    end = datetime.strptime(end,\"%Y%m%d\")\n",
    "    \n",
    "    #Find the roughly equal subinterval length\n",
    "    diff = (end  - start ) / intv\n",
    "    \n",
    "    #Compute the subinterval dates and yield as string\n",
    "    for i in range(intv):\n",
    "        \n",
    "        #After the first sub interval, start intervals from the day after the last interval's end day\n",
    "        if i > 1:\n",
    "            yield (start + diff * (i-1) + timedelta(1)).strftime(\"%Y%m%d\")\n",
    "        yield (start + diff * i).strftime(\"%Y%m%d\")\n",
    "        \n",
    "    #Compute the last interval\n",
    "    yield (start + diff * (intv-1) + timedelta(1)).strftime(\"%Y%m%d\")\n",
    "    yield end.strftime(\"%Y%m%d\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Specifying the query & pulling from the API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def ISP_Tweet_Extractor(api,isp_name, from_date, to_date):\n",
    "    \n",
    "    \"\"\"\n",
    "    Function to extract tweets for a specified ISP during a specified time frame\n",
    "    \n",
    "    Inputs:\n",
    "     - isp_name (str): Name of the ISP to extract tweets for\n",
    "     - from_date (str): Earliest date (and time) of posting for any extracted tweet\n",
    "     - to_date (str): Latest date (and time) of posting for any extracted tweet \n",
    "     \n",
    "    Output:\n",
    "     - subintv_ISP_tweets (list): List containing API results for yearly quarter subintervals\n",
    "     \n",
    "    \"\"\"\n",
    "    \n",
    "    #Connection to api\n",
    "    api = api\n",
    "    \n",
    "    #### ------------------ VARIABLE REFORMATTING ------------------ ####\n",
    "    #Assign ISP name to variable ensuring it is in lower case\n",
    "    isp_name = isp_name.lower()\n",
    "    \n",
    "    #Reformat the fromDate to YYYYMMDD format\n",
    "    from_date = from_date.replace('-','')\n",
    "    \n",
    "    #Reformat the fromDate to YYYYMMDD format\n",
    "    to_date = to_date.replace('-','')\n",
    "    \n",
    "    #Split the quarter (from_date - to_date) to 5 equal subintervals\n",
    "    #*100 tweets will be extracted from each subinterval\n",
    "    intv_dates = [*date_range(from_date, to_date, 5)]\n",
    "    \n",
    "    #Get the subinterval date pairs\n",
    "    date_pairs = [(intv_dates[idx],intv_dates[idx+1]) for idx in range(0,len(intv_dates),2)]\n",
    "    \n",
    "    \n",
    "    #### ------------------ BUILDING THE API QUERY  ------------------ ####\n",
    "    \n",
    "    #Join the different handles to form the exclusion portion of the query\n",
    "    excl_handles = ' -from:'.join(eval(isp_name +'_handles'))\n",
    "    \n",
    "    #Query for tweets in Lagos containing the ISP's name and exclude tweets \n",
    "    #from the official ISP Twitter handles\n",
    "    \n",
    "    #If the ISP is Tizeti, take into account that they are known by multiple names\n",
    "    if isp_name == 'tizeti':\n",
    "        \n",
    "        api_query = f\"\"\" tizeti OR wifi.com.ng OR wifi.ng {excl_handles} place:\"Lagos,Nigeria\" \"\"\"\n",
    "    \n",
    "    else:\n",
    "        api_query = f\"\"\"{isp_name} {excl_handles} place:\"Lagos,Nigeria\" \"\"\"\n",
    "        \n",
    "        \n",
    "    #### ------------------ SEARCHING & EXTRACTING THE DATA ------------------ ####\n",
    "    \n",
    "    #List to store the subinterval API responses\n",
    "    subintv_ISP_tweets = []\n",
    "    \n",
    "    #For each subinterval\n",
    "    for start,end in date_pairs:\n",
    "        \n",
    "        #Add time to the dates to fit with Twitter API format, \n",
    "        start = start + '0000' #midnight\n",
    "        end = end + '2359' #just before crossing into the next day\n",
    "        \n",
    "        #Trying running the query\n",
    "        try:\n",
    "            #Full archive search for ISP tweets\n",
    "            ISP_tweets = api.search_full_archive(dev_env, api_query, fromDate = start, toDate= end)\n",
    "        \n",
    "        #If it fails, print the exception raised and the subinterval in question, but continue\n",
    "        except Exception as e:\n",
    "            \n",
    "            print(e,'\\n')\n",
    "            print(f'Subinterval associated with error: [{start},{end}]')\n",
    "            continue\n",
    "            \n",
    "        #Add the subinterval API response to the list\n",
    "        subintv_ISP_tweets.append(ISP_tweets)\n",
    "    \n",
    "    \n",
    "    return subintv_ISP_tweets\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Storing the tweets in a pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tweets_to_df(api_result_list):\n",
    "    \n",
    "    \"\"\"\n",
    "    Function to extract relevant properties from api results (tweets objects) and store \n",
    "    in a pandas dataframe\n",
    "    \n",
    "    Input(s):\n",
    "        - api_result_list (list): List containing API results for a yearly quarter's subintervals\n",
    "        \n",
    "    Output(s):\n",
    "        - main_df (DataFrame): Pandas DataFrame of tweets (and their properties) from the yearly quarter\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    #Empty dataframe to compile data from all yearly quarter subintervals\n",
    "    main_df = pd.DataFrame()\n",
    "    \n",
    "    #Iterate through all the subinterval api results\n",
    "    for api_result in api_result_list:\n",
    "        \n",
    "        #Getting the relevant properties from the tweets and storing in a dictionary \n",
    "        tweets = [{'Time':tweet.created_at, 'Text':tweet.text, 'Coordinates':tweet.coordinates, \n",
    "                   'Place': tweet.place, 'Source':tweet.source} for tweet in api_result]\n",
    "    \n",
    "        #Convert the dictionary to a pandas dataframe\n",
    "        df = pd.DataFrame.from_dict(tweets)\n",
    "        \n",
    "        #Append the pandas df for the API result to the main df\n",
    "        main_df = main_df.append(df)\n",
    "        \n",
    "    \n",
    "    return main_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Converting pandas df to csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_to_csv(df,isp_name,from_date,yearly_quarter):\n",
    "    \n",
    "    #Alphanumerics to lowercase\n",
    "    isp_name = isp_name.lower()\n",
    "    quarter = yearly_quarter.lower()\n",
    "    \n",
    "    #Extract year from date\n",
    "    year = from_date[:4]\n",
    "    \n",
    "    #Convert to CSV to save current tweets obtained from the API\n",
    "    df.to_csv(f\"../data/raw/{isp_name}/{isp_name}_tweets_{quarter}_{year}.csv\", index= False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(isp_name=None, from_date=None, to_date=None, yearly_quarter=None, interactive=False):\n",
    "    \n",
    "    if interactive:\n",
    "        #Pass in parameters neeeded for API query\n",
    "        isp_name = input('ISP Full Name:')\n",
    "        from_date = input('Start Date (YYYY-MM-DD):')\n",
    "        to_date = input('End Date (YYYY-MM-DD):')\n",
    "        yearly_quarter = input('What quarter of the year? (q_):')\n",
    "        \n",
    "    else:\n",
    "        if any(x is None for x in [isp_name,from_date,to_date,yearly_quarter]):\n",
    "            \n",
    "            raise ValueError('Please ensure a valid value is passed for all the parameters')\n",
    "    \n",
    "    #Connect and authenticate Twitter API\n",
    "    api = authenticate()\n",
    "    \n",
    "    #Pull the data from the API using the query and parameters\n",
    "    api_results = ISP_Tweet_Extractor(api, isp_name, from_date, to_date)\n",
    "    \n",
    "    #Convert the API results into a pandas dataframe\n",
    "    ISP_tweets = tweets_to_df(api_results)\n",
    "    \n",
    "    #Write to csv file\n",
    "    df_to_csv(ISP_tweets,isp_name,from_date,yearly_quarter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "quarterly_dates_2019 = [('2019-01-01','2019-03-31','q1'),('2019-04-01','2019-06-30','q2'),\n",
    "                        ('2019-07-01','2019-09-30','q3'),('2019-10-01','2019-12-31','q4')]\n",
    "\n",
    "quarterly_dates_2020 = [('2020-01-01','2020-03-31','q1'),('2020-04-01','2020-06-30','q2'),\n",
    "                        ('2020-07-01','2020-09-30','q3'),('2020-10-01','2020-12-31','q4')]\n",
    "\n",
    "for start, end, quarter in quarterly_dates_2019:\n",
    "    \n",
    "    if __name__ == \"__main__\":\n",
    "        main('ipnx',start,end,quarter)\n",
    "    time.sleep(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ISP Full Name:tizeti\n",
      "Start Date (YYYY-MM-DD):2019-04-01\n",
      "End Date (YYYY-MM-DD):2019-06-30\n",
      "What quarter of the year? (q_):q2\n",
      "{'message': \"There were errors processing your request: Reference to invalid operator 'is:retweet'. Operator is not available in current product or product packaging. Please refer to complete available operator list at http://t.co/operators. (at position 70)\", 'sent': '2021-09-28T09:21:42+00:00', 'transactionId': '9bbfe9465a88f62f'} \n",
      "\n",
      "Subinterval associated with error: [201904010000,201904192359]\n",
      "{'message': \"There were errors processing your request: Reference to invalid operator 'is:retweet'. Operator is not available in current product or product packaging. Please refer to complete available operator list at http://t.co/operators. (at position 70)\", 'sent': '2021-09-28T09:21:42+00:00', 'transactionId': '798fb2a340ac3f3f'} \n",
      "\n",
      "Subinterval associated with error: [201904200000,201905072359]\n",
      "{'message': \"There were errors processing your request: Reference to invalid operator 'is:retweet'. Operator is not available in current product or product packaging. Please refer to complete available operator list at http://t.co/operators. (at position 70)\", 'sent': '2021-09-28T09:21:42+00:00', 'transactionId': 'd83205babb34c215'} \n",
      "\n",
      "Subinterval associated with error: [201905080000,201905252359]\n",
      "{'message': \"There were errors processing your request: Reference to invalid operator 'is:retweet'. Operator is not available in current product or product packaging. Please refer to complete available operator list at http://t.co/operators. (at position 70)\", 'sent': '2021-09-28T09:21:43+00:00', 'transactionId': '4d94148ef16a31a2'} \n",
      "\n",
      "Subinterval associated with error: [201905260000,201906122359]\n",
      "{'message': \"There were errors processing your request: Reference to invalid operator 'is:retweet'. Operator is not available in current product or product packaging. Please refer to complete available operator list at http://t.co/operators. (at position 70)\", 'sent': '2021-09-28T09:21:43+00:00', 'transactionId': 'd3588390436205e7'} \n",
      "\n",
      "Subinterval associated with error: [201906130000,201906302359]\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    main(interactive=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "k = pd.read_csv('../data/raw/spectranet/spectranet_tweets_q1_2019.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>Text</th>\n",
       "      <th>Coordinates</th>\n",
       "      <th>Place</th>\n",
       "      <th>Source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-01-18 22:22:16</td>\n",
       "      <td>@UMEHoma @Spectranet_NG @CPCNig @SANNigeria @F...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Place(_api=&lt;tweepy.api.API object at 0x7f96f2f...</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2019-01-18 08:53:02</td>\n",
       "      <td>After making me use my last 10k to renew my ac...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Place(_api=&lt;tweepy.api.API object at 0x7f96f2f...</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-01-17 23:09:32</td>\n",
       "      <td>@Spectranet_NG I can see the bonus data on the...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Place(_api=&lt;tweepy.api.API object at 0x7f96f2f...</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-01-17 23:05:19</td>\n",
       "      <td>@Spectranet_NG Renewed and didn't get the bonu...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Place(_api=&lt;tweepy.api.API object at 0x7f96f2f...</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019-01-17 16:36:17</td>\n",
       "      <td>This Spectranet is so shit Iâ€™m gonna so regret...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Place(_api=&lt;tweepy.api.API object at 0x7f96f2f...</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>2019-03-23 14:31:00</td>\n",
       "      <td>@commando_skiipz He might be using spectranet,...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Place(_api=&lt;tweepy.api.API object at 0x7f96f2f...</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>2019-03-21 05:06:54</td>\n",
       "      <td>ðŸ˜‚ðŸ˜‚ðŸ˜‚I used to do that. But I can't kill myself....</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Place(_api=&lt;tweepy.api.API object at 0x7f96f2f...</td>\n",
       "      <td>Twitter for Android</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>2019-03-20 11:37:01</td>\n",
       "      <td>@Spectranet_NG kilo sele gan gan? 24500 naira ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Place(_api=&lt;tweepy.api.API object at 0x7f96f2f...</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>105</th>\n",
       "      <td>2019-03-15 21:29:06</td>\n",
       "      <td>@dejokecarew I donâ€™t think spectranet is trash .</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Place(_api=&lt;tweepy.api.API object at 0x7f96f2f...</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>2019-03-15 05:32:04</td>\n",
       "      <td>Swift or Spectranet???</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Place(_api=&lt;tweepy.api.API object at 0x7f96f2f...</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>107 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Time                                               Text  \\\n",
       "0    2019-01-18 22:22:16  @UMEHoma @Spectranet_NG @CPCNig @SANNigeria @F...   \n",
       "1    2019-01-18 08:53:02  After making me use my last 10k to renew my ac...   \n",
       "2    2019-01-17 23:09:32  @Spectranet_NG I can see the bonus data on the...   \n",
       "3    2019-01-17 23:05:19  @Spectranet_NG Renewed and didn't get the bonu...   \n",
       "4    2019-01-17 16:36:17  This Spectranet is so shit Iâ€™m gonna so regret...   \n",
       "..                   ...                                                ...   \n",
       "102  2019-03-23 14:31:00  @commando_skiipz He might be using spectranet,...   \n",
       "103  2019-03-21 05:06:54  ðŸ˜‚ðŸ˜‚ðŸ˜‚I used to do that. But I can't kill myself....   \n",
       "104  2019-03-20 11:37:01  @Spectranet_NG kilo sele gan gan? 24500 naira ...   \n",
       "105  2019-03-15 21:29:06   @dejokecarew I donâ€™t think spectranet is trash .   \n",
       "106  2019-03-15 05:32:04                             Swift or Spectranet???   \n",
       "\n",
       "    Coordinates                                              Place  \\\n",
       "0           NaN  Place(_api=<tweepy.api.API object at 0x7f96f2f...   \n",
       "1           NaN  Place(_api=<tweepy.api.API object at 0x7f96f2f...   \n",
       "2           NaN  Place(_api=<tweepy.api.API object at 0x7f96f2f...   \n",
       "3           NaN  Place(_api=<tweepy.api.API object at 0x7f96f2f...   \n",
       "4           NaN  Place(_api=<tweepy.api.API object at 0x7f96f2f...   \n",
       "..          ...                                                ...   \n",
       "102         NaN  Place(_api=<tweepy.api.API object at 0x7f96f2f...   \n",
       "103         NaN  Place(_api=<tweepy.api.API object at 0x7f96f2f...   \n",
       "104         NaN  Place(_api=<tweepy.api.API object at 0x7f96f2f...   \n",
       "105         NaN  Place(_api=<tweepy.api.API object at 0x7f96f2f...   \n",
       "106         NaN  Place(_api=<tweepy.api.API object at 0x7f96f2f...   \n",
       "\n",
       "                  Source  \n",
       "0     Twitter for iPhone  \n",
       "1     Twitter for iPhone  \n",
       "2     Twitter for iPhone  \n",
       "3     Twitter for iPhone  \n",
       "4     Twitter for iPhone  \n",
       "..                   ...  \n",
       "102   Twitter for iPhone  \n",
       "103  Twitter for Android  \n",
       "104   Twitter for iPhone  \n",
       "105   Twitter for iPhone  \n",
       "106   Twitter for iPhone  \n",
       "\n",
       "[107 rows x 5 columns]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-01-18 22:22:16 : @UMEHoma @Spectranet_NG @CPCNig @SANNigeria @FCC And those their representatives will be calling somebody using sweet voice ðŸ¤¦â€â™‚ï¸ðŸ¤¦â€â™‚ï¸ \n",
      "\n",
      "2019-01-18 08:53:02 : After making me use my last 10k to renew my account on their network, there's still no @Spectranet_NG service in myâ€¦ https://t.co/OsAvwqmfBO \n",
      "\n",
      "2019-01-17 23:09:32 : @Spectranet_NG I can see the bonus data on the web but not on the mobile app. Why? \n",
      "\n",
      "2019-01-17 23:05:19 : @Spectranet_NG Renewed and didn't get the bonus???? \n",
      "\n",
      "2019-01-17 16:36:17 : This Spectranet is so shit Iâ€™m gonna so regret buying. Very shitty service and I thought Smile was worse ðŸ¤¦ðŸ½â€â™‚ï¸ \n",
      "\n",
      "2019-01-17 15:20:37 : @Spectranet_NG cydm \n",
      "\n",
      "2019-01-17 13:18:28 : Hey guys, Swift 4g vs Spectranet. Which would you rather please? \n",
      "\n",
      "2019-01-14 11:43:00 : @Spectranet_NG Hi, A spectranet Engineer came to my apartment on sat with his laptop and device. He confirmed bad sâ€¦ https://t.co/6hbeKlScNO \n",
      "\n",
      "2019-01-13 15:57:15 : @Spectranet_NG #dontusespectranet https://t.co/I3l2pYNc41 \n",
      "\n",
      "2019-01-13 07:37:46 : A little one for @Spectranet_NG @SPECTRANETLTE \n",
      "Go get yours too\n",
      "\n",
      "Happy Sunday \n",
      "#HappySunday https://t.co/ZnXBtylYu1 \n",
      "\n",
      "2019-01-11 11:17:34 : @Spectranet_NG Hi.\n",
      "A spectranet engineer called me.\n",
      "He would come tomorrow Saturday to help out. I would give feedbâ€¦ https://t.co/0b4gwQXMc5 \n",
      "\n",
      "2019-01-11 10:33:44 : @CACCOT1 Get yorself @Spectranet_NG \n",
      "\n",
      "2019-01-11 07:59:24 : @Spectranet_NG Account was made active yesterday by the agent in yaba. I could only use it in yaba but no signal whâ€¦ https://t.co/zdnmkfv7xV \n",
      "\n",
      "2019-01-10 16:13:29 : @Spectranet_NG hello. I bought your freedom modem from your Sabo office, yaba on Tuesday 8th Jan, but no signal inâ€¦ https://t.co/qXG5fNTBzt \n",
      "\n",
      "2019-01-09 21:13:45 : @ola_akodu Na to just go subscribe for swift or spectranet because this Netflix will ruin us and our data soon ðŸ˜‚ \n",
      "\n",
      "2019-01-08 20:17:00 : @_normah_ Buy mifi @Spectranet_NG \n",
      "\n",
      "2019-01-08 11:33:26 : Thanks @Spectranet_NG for resolving the network problems in my area.  I noticed 4 bars the other day and thought itâ€¦ https://t.co/MiglUQ5stU \n",
      "\n",
      "2019-01-06 10:50:04 : @OluwadamilolaOG @Spectranet_NG My second device , the big one . \n",
      "\n",
      "2019-01-06 10:30:37 : Hello @Spectranet_NG what does the online mean ? https://t.co/SYrGo4kKWW \n",
      "\n",
      "2019-01-05 17:37:37 : Left spectranet at home fml \n",
      "\n",
      "2019-01-05 07:50:32 : @ntelcare @NEXT_BILLIONAIR @ntelng Seems youâ€™ve forgotten that this is Nigeria ,what sort of data plans are these ?â€¦ https://t.co/L6BGGlWncb \n",
      "\n",
      "2019-01-04 16:58:01 : @Aunty_Les I use my spectranet in PH oh. Find out \n",
      "\n",
      "2019-01-04 14:44:03 : Spectranet unlimited. Value for money https://t.co/GPDtuSnelE \n",
      "\n",
      "2019-01-02 08:43:10 : Why is spectranet throttling my internet speed?? ðŸ˜ \n",
      "\n",
      "2019-01-01 16:50:43 : I have 10k I bought in my Spectranet since September.\n",
      "I saved it for January, January is here I still donâ€™t want toâ€¦ https://t.co/ZvimLrMFw0 \n",
      "\n",
      "2019-01-01 16:45:56 : @Spectranet_NG you people did not give me bonus .\n",
      "Itâ€™s been straight 3 years non-stop . https://t.co/qqu9w3wBZU \n",
      "\n",
      "2019-01-01 16:45:01 : How can NGN5000 be just 7gig?\n",
      "Spectranet this is becoming unhealthy.\n",
      "\n",
      "@Spectranet_NG \n",
      "\n",
      "2019-01-01 16:44:02 : MTN &amp; Spectranet really sucked me dry last year . \n",
      "\n",
      "2019-01-01 16:01:23 : @Spectranet_NG\n",
      "\n",
      "What's happening with your network?\n",
      "\n",
      "This is certainly not the way to start the new year.\n",
      "\n",
      "Please look into it.\n",
      "\n",
      "Thanks. \n",
      "\n",
      "2019-02-01 20:26:18 : Leadership with a difference @kamleshexclmind #spectranet https://t.co/HHFC0V4rBm \n",
      "\n",
      "2019-01-28 21:00:34 : @Spectranet_NG why nah? ðŸ˜­ðŸ˜­ðŸ˜­ \n",
      "\n",
      "2019-01-28 20:37:55 : @Spectranet_NG , are we okay at home ? https://t.co/eyb0MZ3YcK \n",
      "\n",
      "2019-01-28 18:44:37 : Looking like Iâ€™ll sleep before 9.\n",
      "Mtn &amp; Spectranet are unfortunate this night . \n",
      "\n",
      "2019-01-27 17:46:35 : Truth be told...I enjoyed my Spectranet unlimited plan for a whole month. Yes, its capped too but I didnt run out oâ€¦ https://t.co/Zjepsh8zhZ \n",
      "\n",
      "2019-01-27 09:54:29 : What's wrong with Spectranet this morning? \n",
      "\n",
      "2019-01-27 07:45:17 : @Riqueza_cakes Get spectranet then . \n",
      "\n",
      "2019-01-24 19:40:04 : To sleep or tune in Netflix? \n",
      "Finally back with my Spectranet ðŸ˜­ \n",
      "\n",
      "2019-01-23 21:07:45 : Dulled myself with this Spectranet double data this month sha, didnâ€™t subscribe on double data date . Now my sub waâ€¦ https://t.co/dM355NsfPo \n",
      "\n",
      "2019-01-23 10:05:03 : @TWEETARRAZZI Chevron-Ikota axis. Between the 4g broadband providers...spectranet, ntel And co \n",
      "\n",
      "2019-01-22 21:54:29 : @lbambieee Try Spectranet \n",
      "\n",
      "2019-01-22 21:48:23 : I have used @Spectranet_NG 4G LTE routers both at home and office I have never had speed up to 1mbps before... Damnâ€¦ https://t.co/jL5d4iQ5wS \n",
      "\n",
      "2019-01-21 20:47:37 : Swift or spectranet? \n",
      "\n",
      "2019-01-20 20:36:12 : @Spectranet_NG = ðŸ’© ðŸ’© ðŸ’© ðŸ’© ðŸ’© \n",
      "\n",
      "2019-01-20 18:40:07 : Someone should renew my spectranet sub for me na ðŸ˜¢ \n",
      "\n",
      "2019-01-20 10:42:10 : Spectranet double double saved me today . Thank God . \n",
      "\n",
      "2019-01-20 03:13:05 : @NonsoBassey @TheLexash @Spectranet_NG Mine isnâ€™t working at all ðŸ˜ª\n",
      "Trash network \n",
      "\n",
      "2019-01-19 22:58:24 : Name a scam:\n",
      "Smile x Spectranet unlimited bundles.\n",
      "Lmaooooooooooo they should just carry gun ðŸ™ƒ \n",
      "\n",
      "2019-01-19 13:40:54 : Iâ€™m so mad that I bought this spectranet. Very very useless \n",
      "\n",
      "2019-01-19 13:13:44 : Spectranet is a really shitty network @Spectranet_NG Iâ€™m so disappointed \n",
      "\n",
      "2019-02-21 21:04:30 : @serahkassim Spectranet is not bad oo \n",
      "\n",
      "2019-02-21 20:32:01 : Iâ€™d have to retire back to Spectranet, ðŸ™ƒ. Iâ€™m ashamed ðŸ˜­ðŸ˜© \n",
      "\n",
      "2019-02-21 20:26:56 : Dear @SmileComsNG you had one job!!!!! Why did I sly Spectranet? Sigh ðŸ™ƒðŸ˜©ðŸ˜©ðŸ˜©ðŸ˜©ðŸ˜© \n",
      "\n",
      "2019-02-21 18:45:10 : Get your spectranet... It legit.. DM for details.. PLSS RT https://t.co/KDRJklXrzM \n",
      "\n",
      "2019-02-20 19:04:14 : Lmaooooooooooo Iâ€™m overflowing data, Spectranet and Smile loves me ðŸ˜­ðŸ˜­ðŸ˜­ðŸ¥° \n",
      "\n",
      "2019-02-20 17:53:37 : @lawaleto @Spectranet_NG I dey bro, you get fast internet ? \n",
      "\n",
      "2019-02-20 14:25:20 : Who has FAST internet and lives in Yaba? Biko help me, @Spectranet_NG is taking a whole fucking piss. \n",
      "\n",
      "2019-02-18 20:19:55 : @Spectranet_NG Shambles. https://t.co/uYDxQddPMR \n",
      "\n",
      "2019-02-18 17:10:19 : Someone should make me happy by paying for my spectranet subscription ðŸ˜­ðŸ˜­ðŸ˜­ \n",
      "\n",
      "2019-02-18 14:14:38 : #TuneIn  if you be @Spectranet_NG user #tunein you fit listen to our radio free at night. With just 20mb you fit liâ€¦ https://t.co/xe7qlLb3C3 \n",
      "\n",
      "2019-02-18 11:06:38 : @Spectranet_NG I canâ€™t log into my account help pls \n",
      "\n",
      "2019-02-16 19:32:00 : @mannimoor Is your spectranet working? \n",
      "\n",
      "2019-02-16 18:11:48 : @Spectranet_NG Can I subscribe via @UBAGroup mobile app and get the 100% bonus? \n",
      "\n",
      "2019-02-16 13:44:07 : @Spectranet_NG I canâ€™t login into my account. Is anybody home? \n",
      "\n",
      "2019-02-12 19:53:07 : @maxpayne_papi Na Spectranet 10k I dey use o â˜ºï¸ \n",
      "\n",
      "2019-02-11 20:05:07 : Spectranet is a criminal organization. \n",
      "\n",
      "2019-02-09 20:33:43 : Please who uses spectranet/Ntel around Chevron/ Ikota axis ?  How good is the internet ? \n",
      "\n",
      "2019-02-06 20:10:53 : People using Spectranet, what has your experience been like? \n",
      "\n",
      "2019-02-06 19:49:59 : Spectranet should drop this promo mail and unleash me biko! \n",
      "\n",
      "2019-03-13 13:31:35 : @modelina The best! Spectranet 12k5 monthly Tizzeti 9k5 \n",
      "\n",
      "2019-03-12 10:16:47 : @Syl_space Smile and spectranet are almost everywhere In lagos now \n",
      "\n",
      "2019-03-12 09:56:55 : @DochthorJack Oh so spectranet is more affordable? \n",
      "\n",
      "2019-03-12 09:54:27 : I have being avoiding this but I have to close my eyes and buy a spectranet or smile WiFi.\n",
      "I canâ€™t be spending this much on data. \n",
      "\n",
      "2019-03-11 09:01:53 : @AirtelNigeria putting an end to our relationship Eni wa Dami pada si Village I need Spectranet!! \n",
      "\n",
      "2019-03-08 18:11:49 : @Kevwekofi @denikeoyetunde @Spectranet_NG @efosaaigbe @aikmamah Una wan try?\n",
      "People be don dear leave una network iâ€¦ https://t.co/wZhrJYpAMc \n",
      "\n",
      "2019-03-08 12:37:23 : @Spectranet_NG I am having issues with my spectranet pebble mini... \n",
      "\n",
      "2019-03-08 07:12:03 : Will @Spectranet_NG not give us bonus data to celebrate women on International Women's Day today?\n",
      "\n",
      "Do something oooâ€¦ https://t.co/Clg3IKzzNk \n",
      "\n",
      "2019-03-07 11:32:58 : @ITSDJPRETTIBOI @No_Guile That's not an unlimited plan.\n",
      "\n",
      "Spectranet has something similar, in a 100GB data cap, theâ€¦ https://t.co/KAC3xWXJBu \n",
      "\n",
      "2019-03-05 11:57:20 : Coming soon ðŸ™ŒðŸ™Œ\n",
      "Spectranet advertisement video \n",
      "\n",
      "#akolademj @ Lagos, Nigeria https://t.co/nciwBq2Wns \n",
      "\n",
      "2019-03-02 18:34:18 : @fozadoza Spectranet is very good oh , aliens 4th roundabout \n",
      "\n",
      "2019-03-02 15:08:26 : I canâ€™t find my @Spectranet_NG mifi and I still have data loaded on it. Whatâ€™s going to happen ðŸ˜­ðŸ˜­ is there a recoveâ€¦ https://t.co/KVlpWjxuPR \n",
      "\n",
      "2019-03-02 09:51:30 : Who uses Spectranet on the TL? I need to ask a few questions cos @AirtelNigeria wan finish me!!! \n",
      "\n",
      "2019-03-02 06:59:40 : @Spectranet_NG Hello, do you guys offer unlimited data package? \n",
      "\n",
      "2019-03-01 18:35:20 : @ZeusUbani @Spectranet_NG Nope. I didnâ€™t. Hoping spectranet pities me still \n",
      "\n",
      "2019-03-01 11:11:43 : I went for this was because I found I was using up Spectranet's 100GB fair-usage cap on its \"unlimited\" data plan iâ€¦ https://t.co/kYfY5MXruA \n",
      "\n",
      "2019-02-27 20:39:47 : @Omo_IyaBeji @frankdonga_ Spectranet barh? \n",
      "\n",
      "2019-02-27 18:59:31 : @TheFunkyDee @Spectranet_NG Iâ€™m giving @Spectranet_NG a second thoughts with this, Iâ€™m this thinking of switching fâ€¦ https://t.co/QfBEzd1lCk \n",
      "\n",
      "2019-02-27 05:02:07 : How do i get that pls and how much? Pls note that i av been using @Spectranet_NG but they are not better. https://t.co/5EMpnE7JTz \n",
      "\n",
      "2019-02-25 04:34:37 : @SmileComsNG @Spectranet_NG I hope you can see this? https://t.co/vozWjKm2OF \n",
      "\n",
      "2019-02-24 19:48:48 : @Spectranet_NG in Ikoyi, you people have started again ðŸ™„ðŸ™„ \n",
      "\n",
      "2019-02-24 12:33:56 : @iHoluwatoby Biko jamisi, Iâ€™m using Spectranet 60GB and itâ€™s not bad \n",
      "\n",
      "2019-02-24 12:09:34 : Laslas Spectranet 40G is still bae. Just subscribe on their double promo days ðŸ™ƒ. \n",
      "\n",
      "2019-02-24 09:51:44 : @Spectranet_NG Will your store at ozone open today? \n",
      "\n",
      "2019-03-31 19:13:28 : I didn't once check my spectranet data balance last month.\n",
      "\n",
      "Maybe this on site job thing isn't so bad \n",
      "\n",
      "2019-03-29 11:29:59 : Eriq, i assume?\n",
      "First of all accept my humble apology, i didn't mean to sound rude to you but take me as a case stuâ€¦ https://t.co/DVDHTAo8Vy \n",
      "\n",
      "2019-03-29 07:46:55 : Bought Spectranet mifi on tuesday, today is Friday and it's still yet to be activated, whilst I'm already receivingâ€¦ https://t.co/ZWhvrVtfOc \n",
      "\n",
      "2019-03-28 22:52:09 : Oh boy, @Spectranet_NG won't make me work.  And please don't tell me about resetting network signal BS, your networâ€¦ https://t.co/rssnxdC0f1 \n",
      "\n",
      "2019-03-28 19:13:22 : Please can you help me with the address of any spectranet shop around Oworonshoki or bariga, thank you! https://t.co/MszmXwYQvc \n",
      "\n",
      "2019-03-28 14:36:31 : @Spectranet_NG my Evo mifi wonâ€™t come on ðŸ˜­ðŸ˜­ðŸ˜­ðŸ˜­ I still have subscription on it; please help \n",
      "\n",
      "2019-03-26 17:27:56 : Hay God. Spectranet wonâ€™t kill me. What is going on?? \n",
      "\n",
      "2019-03-26 17:26:14 : Pls oo, @Spectranet_NG my device has been blinking red all day. What is the matter? \n",
      "\n",
      "2019-03-25 19:18:05 : @DigitalTrends @Spectranet_NG how far? are we going to get this in Nigeria? \n",
      "\n",
      "2019-03-25 13:44:43 : @spectranet_limited @heritagebankng @polarisbankltd @keystonebankng\n",
      ".\n",
      ".\n",
      "#rewardsonthego #rewardsattheclickofabuttonâ€¦ https://t.co/pfTaeipmZm \n",
      "\n",
      "2019-03-23 14:31:00 : @commando_skiipz He might be using spectranet, who knows?? ðŸ¤·â€â™‚ï¸ \n",
      "\n",
      "2019-03-21 05:06:54 : ðŸ˜‚ðŸ˜‚ðŸ˜‚I used to do that. But I can't kill myself. If Spectranet fuck up. I'll just go offline. play game or sleep. https://t.co/dHuyXiLHpC \n",
      "\n",
      "2019-03-20 11:37:01 : @Spectranet_NG kilo sele gan gan? 24500 naira in one month gone?? How??? \n",
      "\n",
      "2019-03-15 21:29:06 : @dejokecarew I donâ€™t think spectranet is trash . \n",
      "\n",
      "2019-03-15 05:32:04 : Swift or Spectranet??? \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for time,tweet in k[['Time','Text']].values:\n",
    "    print(time,':',tweet,'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['2019-01-01 16:01:23', '2019-01-01 16:44:02',\n",
       "       '2019-01-01 16:45:01', '2019-01-01 16:45:56',\n",
       "       '2019-01-01 16:50:43', '2019-01-02 08:43:10',\n",
       "       '2019-01-04 14:44:03', '2019-01-04 16:58:01',\n",
       "       '2019-01-05 07:50:32', '2019-01-05 17:37:37',\n",
       "       '2019-01-06 10:30:37', '2019-01-06 10:50:04',\n",
       "       '2019-01-08 11:33:26', '2019-01-08 20:17:00',\n",
       "       '2019-01-09 21:13:45', '2019-01-10 16:13:29',\n",
       "       '2019-01-11 07:59:24', '2019-01-11 10:33:44',\n",
       "       '2019-01-11 11:17:34', '2019-01-13 07:37:46',\n",
       "       '2019-01-13 15:57:15', '2019-01-14 11:43:00',\n",
       "       '2019-01-17 13:18:28', '2019-01-17 15:20:37',\n",
       "       '2019-01-17 16:36:17', '2019-01-17 23:05:19',\n",
       "       '2019-01-17 23:09:32', '2019-01-18 08:53:02',\n",
       "       '2019-01-18 22:22:16', '2019-01-19 13:13:44',\n",
       "       '2019-01-19 13:40:54', '2019-01-19 22:58:24',\n",
       "       '2019-01-20 03:13:05', '2019-01-20 10:42:10',\n",
       "       '2019-01-20 18:40:07', '2019-01-20 20:36:12',\n",
       "       '2019-01-21 20:47:37', '2019-01-22 21:48:23',\n",
       "       '2019-01-22 21:54:29', '2019-01-23 10:05:03',\n",
       "       '2019-01-23 21:07:45', '2019-01-24 19:40:04',\n",
       "       '2019-01-27 07:45:17', '2019-01-27 09:54:29',\n",
       "       '2019-01-27 17:46:35', '2019-01-28 18:44:37',\n",
       "       '2019-01-28 20:37:55', '2019-01-28 21:00:34',\n",
       "       '2019-02-01 20:26:18', '2019-02-06 19:49:59',\n",
       "       '2019-02-06 20:10:53', '2019-02-09 20:33:43',\n",
       "       '2019-02-11 20:05:07', '2019-02-12 19:53:07',\n",
       "       '2019-02-16 13:44:07', '2019-02-16 18:11:48',\n",
       "       '2019-02-16 19:32:00', '2019-02-18 11:06:38',\n",
       "       '2019-02-18 14:14:38', '2019-02-18 17:10:19',\n",
       "       '2019-02-18 20:19:55', '2019-02-20 14:25:20',\n",
       "       '2019-02-20 17:53:37', '2019-02-20 19:04:14',\n",
       "       '2019-02-21 18:45:10', '2019-02-21 20:26:56',\n",
       "       '2019-02-21 20:32:01', '2019-02-21 21:04:30',\n",
       "       '2019-02-24 09:51:44', '2019-02-24 12:09:34',\n",
       "       '2019-02-24 12:33:56', '2019-02-24 19:48:48',\n",
       "       '2019-02-25 04:34:37', '2019-02-27 05:02:07',\n",
       "       '2019-02-27 18:59:31', '2019-02-27 20:39:47',\n",
       "       '2019-03-01 11:11:43', '2019-03-01 18:35:20',\n",
       "       '2019-03-02 06:59:40', '2019-03-02 09:51:30',\n",
       "       '2019-03-02 15:08:26', '2019-03-02 18:34:18',\n",
       "       '2019-03-05 11:57:20', '2019-03-07 11:32:58',\n",
       "       '2019-03-08 07:12:03', '2019-03-08 12:37:23',\n",
       "       '2019-03-08 18:11:49', '2019-03-11 09:01:53',\n",
       "       '2019-03-12 09:54:27', '2019-03-12 09:56:55',\n",
       "       '2019-03-12 10:16:47', '2019-03-13 13:31:35',\n",
       "       '2019-03-15 05:32:04', '2019-03-15 21:29:06',\n",
       "       '2019-03-20 11:37:01', '2019-03-21 05:06:54',\n",
       "       '2019-03-23 14:31:00', '2019-03-25 13:44:43',\n",
       "       '2019-03-25 19:18:05', '2019-03-26 17:26:14',\n",
       "       '2019-03-26 17:27:56', '2019-03-28 14:36:31',\n",
       "       '2019-03-28 19:13:22', '2019-03-28 22:52:09',\n",
       "       '2019-03-29 07:46:55', '2019-03-29 11:29:59',\n",
       "       '2019-03-31 19:13:28'], dtype=object)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k.Time.sort_values().unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>Subject</th>\n",
       "      <th>Text</th>\n",
       "      <th>Coordinates</th>\n",
       "      <th>Place</th>\n",
       "      <th>Source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2019-03-05 11:57:20</td>\n",
       "      <td>spectranet</td>\n",
       "      <td>Coming soon ðŸ™ŒðŸ™Œ\\nSpectranet advertisement video...</td>\n",
       "      <td>{'type': 'Point', 'coordinates': [3.39583, 6.4...</td>\n",
       "      <td>Place(_api=&lt;tweepy.api.API object at 0x7fb97f4...</td>\n",
       "      <td>Instagram</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>2019-02-18 14:14:38</td>\n",
       "      <td>spectranet</td>\n",
       "      <td>#TuneIn  if you be @Spectranet_NG user #tunein...</td>\n",
       "      <td>{'type': 'Point', 'coordinates': [3.39583, 6.4...</td>\n",
       "      <td>Place(_api=&lt;tweepy.api.API object at 0x7fb97f4...</td>\n",
       "      <td>Instagram</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Time     Subject  \\\n",
       "24  2019-03-05 11:57:20  spectranet   \n",
       "48  2019-02-18 14:14:38  spectranet   \n",
       "\n",
       "                                                 Text  \\\n",
       "24  Coming soon ðŸ™ŒðŸ™Œ\\nSpectranet advertisement video...   \n",
       "48  #TuneIn  if you be @Spectranet_NG user #tunein...   \n",
       "\n",
       "                                          Coordinates  \\\n",
       "24  {'type': 'Point', 'coordinates': [3.39583, 6.4...   \n",
       "48  {'type': 'Point', 'coordinates': [3.39583, 6.4...   \n",
       "\n",
       "                                                Place     Source  \n",
       "24  Place(_api=<tweepy.api.API object at 0x7fb97f4...  Instagram  \n",
       "48  Place(_api=<tweepy.api.API object at 0x7fb97f4...  Instagram  "
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Only two tweets with tagged coordinates \n",
    "k[k.Coordinates.isna() == False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#The two tweets report being from the same location\n",
    "k[k.Coordinates.isna() == False].iloc[0,3]  == k[k.Coordinates.isna() == False].iloc[1,3] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunately I might have to expand and look at ISPs across the entire Lagos :("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14 days, 0:00:00\n",
      "14 days, 0:00:00\n",
      "14 days, 0:00:00\n",
      "14 days, 0:00:00\n",
      "14 days, 0:00:00\n",
      "14 days, 0:00:00\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "for a,b in date_pairs:\n",
    "    print(datetime.strptime(b,\"%Y%m%d\") - datetime.strptime(a,\"%Y%m%d\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "2\n",
      "4\n",
      "6\n",
      "8\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "for idx in range(0,len(k),2):\n",
    "    print(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "['20190101', '20190118', '20190205', '20190222', '20190312', '20190330']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "['20190101','20190118']\n",
    "['20190119','20190205']\n",
    "['20190206','20190222']\n",
    "['20190223','20190312']\n",
    "['20190313','20190330']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for +: 'datetime.datetime' and 'int'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-c33c4c6d4356>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdatetime\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrptime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'20190331'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"%Y%m%d\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrptime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'20190314'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"%Y%m%d\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for +: 'datetime.datetime' and 'int'"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "datetime.strptime('20190331',\"%Y%m%d\") - datetime.strptime('20190314',\"%Y%m%d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__new__() got an unexpected keyword argument 'start'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-43-185ee101fce2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mfinish\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrptime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'%Y%m%d'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mdates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDatetimeIndex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfinish\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfreq\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'D'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0mquarters\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_period\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Q'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdates\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mquarters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdates\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Quarter'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Date'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: __new__() got an unexpected keyword argument 'start'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import datetime as dt\n",
    "\n",
    "begin = '20100101'\n",
    "end = '2010331'\n",
    "\n",
    "start = dt.datetime.strptime(begin, '%Y%m%d')\n",
    "finish = dt.datetime.strptime(end, '%Y%m%d')\n",
    "\n",
    "dates = pd.DatetimeIndex(start=start, end=finish, freq='D').tolist()\n",
    "quarters = [d.to_period('Q') for d in dates]\n",
    "df = pd.DataFrame([quarters, dates], index=['Quarter', 'Date']).T\n",
    "\n",
    "quarterly_dates = {str(q): [ts.strftime('%Y%m%d') \n",
    "                            for ts in df[df.Quarter == q].Date.values.tolist()]\n",
    "                           for q in quarters}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for tweet in tweets:\n",
    "    if tweet.truncated:\n",
    "        print(tweet.extended_tweet['full_text'])\n",
    "    else:\n",
    "        print(tweet.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/tweepy/tweepy/issues/1461"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
