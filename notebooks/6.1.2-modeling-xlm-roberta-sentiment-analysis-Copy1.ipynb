{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2d5cb306-d351-46cb-8843-1153eb1a9f55",
   "metadata": {},
   "source": [
    "# Modeling: Multilingual Twitter XLM-roBERTa-base For Sentiment Analysis\n",
    "Fine-tuning an M-BERT model for ISP Sentiment Prediction\n",
    "\n",
    "**`Goal:`**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0455f045-6b06-45b1-8ce6-7d1be8bf9098",
   "metadata": {},
   "source": [
    "### 1. Library Importation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "20d13a43-c94b-47e3-a9d6-09edb2aae52a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Visualization packages\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "#sns.set()\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#Modeling and evaluation packages\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support,classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a22b394c-6489-4367-a86d-6269547f412b",
   "metadata": {},
   "source": [
    "### 2. Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c9f04655-bbc0-4e77-b73f-70ee37acdad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/processed/sample_encoded_and_cleaned.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "31fec72a-43ed-4738-a329-55b79dd829a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ISP_Name</th>\n",
       "      <th>Time</th>\n",
       "      <th>Text</th>\n",
       "      <th>Source</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sprectranet</td>\n",
       "      <td>2020-02-04 18:30:35+00:00</td>\n",
       "      <td>my family used my spectranet and they don't wa...</td>\n",
       "      <td>Twitter for Android</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sprectranet</td>\n",
       "      <td>2019-06-19 04:59:49</td>\n",
       "      <td>spectranet_ng how can i get the freedom mifi i...</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sprectranet</td>\n",
       "      <td>2020-03-30 07:57:38+00:00</td>\n",
       "      <td>drolufunmilayo iconic_remi spectranet_ng</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sprectranet</td>\n",
       "      <td>2020-12-31 21:07:52+00:00</td>\n",
       "      <td>spectranet_ng your response just proves how ho...</td>\n",
       "      <td>Twitter for Android</td>\n",
       "      <td>Negative</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sprectranet</td>\n",
       "      <td>2020-09-03 23:09:09+00:00</td>\n",
       "      <td>spectranet is just the worse tbh, i can't even...</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>Negative</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>372</th>\n",
       "      <td>sprectranet</td>\n",
       "      <td>2019-01-04 14:44:03</td>\n",
       "      <td>spectranet unlimited. value for money</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>Positive</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>373</th>\n",
       "      <td>sprectranet</td>\n",
       "      <td>2020-06-17 13:32:28+00:00</td>\n",
       "      <td>from 30th may to date mtn mifi - 10k spectrane...</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>Negative</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>374</th>\n",
       "      <td>sprectranet</td>\n",
       "      <td>2020-05-12 16:51:44+00:00</td>\n",
       "      <td>spectranet_ng fritzthejanitor will they help m...</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>375</th>\n",
       "      <td>sprectranet</td>\n",
       "      <td>2019-02-27 18:59:31</td>\n",
       "      <td>thefunkydee spectranet_ng i'm giving spectrane...</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>Negative</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>376</th>\n",
       "      <td>sprectranet</td>\n",
       "      <td>2020-04-03 12:55:27+00:00</td>\n",
       "      <td>50gb gone in one week, spectranet_ng na so? i ...</td>\n",
       "      <td>Twitter for Android</td>\n",
       "      <td>Negative</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>377 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        ISP_Name                       Time  \\\n",
       "0    sprectranet  2020-02-04 18:30:35+00:00   \n",
       "1    sprectranet        2019-06-19 04:59:49   \n",
       "2    sprectranet  2020-03-30 07:57:38+00:00   \n",
       "3    sprectranet  2020-12-31 21:07:52+00:00   \n",
       "4    sprectranet  2020-09-03 23:09:09+00:00   \n",
       "..           ...                        ...   \n",
       "372  sprectranet        2019-01-04 14:44:03   \n",
       "373  sprectranet  2020-06-17 13:32:28+00:00   \n",
       "374  sprectranet  2020-05-12 16:51:44+00:00   \n",
       "375  sprectranet        2019-02-27 18:59:31   \n",
       "376  sprectranet  2020-04-03 12:55:27+00:00   \n",
       "\n",
       "                                                  Text               Source  \\\n",
       "0    my family used my spectranet and they don't wa...  Twitter for Android   \n",
       "1    spectranet_ng how can i get the freedom mifi i...   Twitter for iPhone   \n",
       "2             drolufunmilayo iconic_remi spectranet_ng   Twitter for iPhone   \n",
       "3    spectranet_ng your response just proves how ho...  Twitter for Android   \n",
       "4    spectranet is just the worse tbh, i can't even...   Twitter for iPhone   \n",
       "..                                                 ...                  ...   \n",
       "372              spectranet unlimited. value for money   Twitter for iPhone   \n",
       "373  from 30th may to date mtn mifi - 10k spectrane...   Twitter for iPhone   \n",
       "374  spectranet_ng fritzthejanitor will they help m...   Twitter for iPhone   \n",
       "375  thefunkydee spectranet_ng i'm giving spectrane...   Twitter for iPhone   \n",
       "376  50gb gone in one week, spectranet_ng na so? i ...  Twitter for Android   \n",
       "\n",
       "    sentiment  label  \n",
       "0     Neutral      1  \n",
       "1     Neutral      1  \n",
       "2     Neutral      1  \n",
       "3    Negative      0  \n",
       "4    Negative      0  \n",
       "..        ...    ...  \n",
       "372  Positive      2  \n",
       "373  Negative      0  \n",
       "374   Neutral      1  \n",
       "375  Negative      0  \n",
       "376  Negative      0  \n",
       "\n",
       "[377 rows x 6 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf6a719f-17f7-4274-bafa-10dfb1b30028",
   "metadata": {},
   "source": [
    "### 3. Split data into training & test set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55142912-e3e6-4b3f-a2f6-5bf68f9a7518",
   "metadata": {},
   "source": [
    "**Observing the true distribution of the data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "63b0d4b5-9d55-4de4-babc-a7b498e42775",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.572944\n",
       "1    0.347480\n",
       "2    0.079576\n",
       "Name: label, dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.label.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84c09a05-6f32-4c75-a22e-59c138e81c0f",
   "metadata": {},
   "source": [
    "Seeing as the dataset is highly imbalanced, I perform a **stratified train-test split**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c7230e82-7f6c-47f0-beac-1c91da47ba8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split the data 80:20 and ensure same proportion of classes as original data \n",
    "#Note: The below gets the indices of the tweets for the training and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(df.index.values, \n",
    "                                                    df.label.values, \n",
    "                                                    test_size=0.2, \n",
    "                                                    random_state=42, \n",
    "                                                    stratify=df.label.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0b92cd70-941e-4c1d-8a91-842ef4d4f1ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Note which tweets were split into the training and test sets so we can see the division\n",
    "df.loc[X_train, 'split_group'] = 'training_set'\n",
    "df.loc[X_test, 'split_group'] = 'test_set'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "559d7a0e-b32a-48e7-9f67-2b467679470b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sentiment</th>\n",
       "      <th>label</th>\n",
       "      <th>split_group</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">Negative</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">0</th>\n",
       "      <th>test_set</th>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>training_set</th>\n",
       "      <td>172</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">Neutral</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">1</th>\n",
       "      <th>test_set</th>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>training_set</th>\n",
       "      <td>105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">Positive</th>\n",
       "      <th rowspan=\"2\" valign=\"top\">2</th>\n",
       "      <th>test_set</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>training_set</th>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              Text\n",
       "sentiment label split_group       \n",
       "Negative  0     test_set        44\n",
       "                training_set   172\n",
       "Neutral   1     test_set        26\n",
       "                training_set   105\n",
       "Positive  2     test_set         6\n",
       "                training_set    24"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(['sentiment', 'label', 'split_group'])[['Text']].count().sort_values('label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7ca98aad-a93d-4773-9f1a-e3716667c069",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAgIAAAGECAYAAABEREiUAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAA6VklEQVR4nO3deXxU1f3/8ddHAmFPAFkFJAiy2YIWFFAWUQEFQUvVVkTFghbUVrQWFYwTtF9FKtZd6tIIIiIWFCqKViUqghX9uaCAIiBIZV/CEpCE8/vjTuJkn0kmk+W+n4/HPMLce8+5nxkI8557zz3XnHOIiIiIPx1X3gWIiIhI+VEQEBER8TEFARERER9TEBAREfExBQEREREfUxAQERHxsZgHATNrZWYvm9k+M0s3s/lm1jqC9p3MbJ6Z7TSzDDNba2Z/KsuaRUREqqq4WO7MzGoD7wBHgKsAB9wDvGtmv3TOHSymffdg+6XAGGAf0B6oW4Zli4iIVFkWywmFgt/cpwMdnHPrgsuSgG+BvzjnphfR9jhgFbDWOXdxKevQLEoiIuI7zjnLuyzWQeBtoKZz7sw8y9MAnHP9img7AHgb6Ouce7+UdTjNqCgiIn5iZgUGgViPEeiC960+r6+AzsW0PSv4s6aZrTCzo2a23cweNrNaUa1SRETEJ2IdBBoCewpYvhtoUEzbFsGfc4E3gfOA+/HGCrwQrQJFRET8JKaDBUspO7Q875xLDv55qZlVA+4zs07OudWhDcwsANwVwxpFREQqlVgfEdhDwd/8CztSEGpX8OdbeZa/Gfx5at4GzrmAc87yPiKqWEREpAqLdRD4Cm+cQF6dga/DaFuUYyWqSERExMdiHQQWAj3NrG32AjNrA5wZXFeU1/HmHxiUZ/ng4M+VUapRRETEN2J9+WAd4HMgA5iMN6HQ3UA94JfOuQPB7U4EvgOmOOemhLS/C7gTb5DgO0B3vDEAc51zV0dQhy4fFJEqJT09ne3bt3P06NHyLkViKC4ujpo1a9K4cWNq1qxZ5LaFXT4Y08GCzrmDwfkAHgRmAYY3N8BN2SEgyIBq5D9iMQXYD4wH/gz8CEzDCxMiIr6Unp7Otm3bOOGEE6hVqxZmGgrlB845MjMzOXDgAJs2baJp06YkJCRE3E9MjwhUFDoiICJVybp162jRogW1a9cu71KknBw6dIitW7fStm3bQrepKBMKiYhIlB09epRatTSvmp/VqlWLI0eOlKitgoCISBWg0wH+Vpq/fwUBERERH1MQEBGRCmfjxo0EAgHWr1+fb12bNm24+uqrY19UmFJTU3n22WfLu4ywVaYphiuFtL6F3kCxyun3Xlp5lyAiVdTGjRtJSUnhrLPOyjcAbsGCBdSvX7+cKiteamoqmZmZXHPNNeVdSlgUBEREpFI59dR8M8pLKejUgIiIhOWbb77h4osvpkmTJtSsWZPWrVtzySWXkJmZCcCOHTv4wx/+wAknnEB8fDwdO3bkH//4R64+UlNTMTNWrFjByJEjqV+/Pi1atOCPf/wjhw8fBmDp0qWcffbZAJx33nmYGWbG0qVLgfynBrL7/PDDD7n00kupV68eTZs25d577wXgjTfe4NRTT6VOnTr06NGDTz75JN9rmz9/Pj179qR27dokJiZyySWXsGnTplzbtGnThiuuuIIXX3yRTp06UadOHbp3784HH3yQs03//v1JS0tj2bJlOXX379+/VO97WdMRARERCcuQIUNo0KABTzzxBMcffzxbtmxh8eLFHDt2jPT0dM466ywyMjIIBAIkJSWxZMkSxo0bx5EjR7jxxhtz9TVq1Ch+97vfMX/+fJYvX04gEKBBgwakpKRw2mmn8dhjj3H99dfz8MMP06NHDwA6d+5cZH1XXXUVV155Jddeey3z5s3jjjvuYO/evSxevJhJkyZRt25d/vKXv3DRRRfx3XffUaNGDQCefPJJxo0bx+jRo0lOTmb//v0EAgH69evHF198Qb169XL28f7777N27VruvvtuatasyZ133snQoUPZuHEjiYmJPP7441xxxRVkZWUxY8YMgAp9GgMUBESkitD4nLK1c+dO1q1bx6uvvsqwYcNyll9++eUATJ06le+//54vv/yS9u3bA3Duueeyd+9eUlJSGDduHHFxcbnapaSk5Gz30UcfMWfOHFJSUqhfv37Oh36nTp3o2bNnWDWOGjWKO++8E/C+mS9YsIDp06fzzTffkJSUBMCxY8cYPnw4y5cvp1+/fhw4cICJEycyevToXAP8Tj/9dDp06MAzzzzDTTfdlLM8PT2dzz77jAYNvBvpNmvWjB49erB48WIuv/xyOnfuTP369cnMzAy77vKmUwMiIlKsRo0a0bZtW2677Taeeuopvv3221zr33jjDc444wySkpLIzMzMeQwaNIhdu3bx9de5bzA7ZMiQXM9/8Ytf5DsUH6nzzz8/589xcXG0a9eOk08+OScEAHTs2BGAzZs3A7B8+XLS09MZOXJkrrpbtWpFx44dee+993Lto1evXjkhILtuoNS1lycdERARkWKZGW+99RaBQIDbb7+dXbt2kZSUxK233sq4cePYvn0769ato3r16gW237VrV67nDRs2zPU8Pj6+xDPjZQv9gAaoUaNGgcuAnPEI27dvB7yjEuH0WVDdof1VRgoCIiISlrZt2zJz5kycc3z++ec8+uijjB8/njZt2tCoUSOaNGnCQw89VGDbDh06xLja8DRq1AjwBhx26dIl3/rQ8QFVlYKAiIhExMzo1q0b06dP55lnnmHVqlUMHjyYRx55hNatW9OkSZNS7yP7m3ZGRkap+ypK7969qVevHuvWreOqq66KSp/x8fHs378/Kn3FgoKAiIgU64svvuBPf/oTl112Ge3atSMrK4vU1FTi4uIYMGAA7dq1Y+7cufTp04cJEybQoUMHDh48yJo1a3j//fd59dVXI9rfySefTFxcHM8++ywNGzYkPj6eDh06RP0bev369Zk2bRrXX389O3bs4PzzzychIYEtW7aQlpZG//79cwZEhqtz5848/vjjzJ07l5NOOol69epV2CMioCAgIiJhaNasGa1bt2b69On88MMP1KxZk1/84hf8+9//5le/+hUAH374IVOmTGHq1Kls2bKFxMREOnTowIgRIyLeX6NGjXj00UeZOnUq/fr1Iysri3fffbdMrsm/7rrraNWqFdOmTeOFF14gMzOTE044gT59+tCtW7eI+5s4cSJr165lzJgxHDhwgH79+uXMgVARmXOuvGuIOTNzZfW6dQmTSPnw8+/e6tWr6dSpUzlVIxVFcf8OzAznXL7bFOryQRERER9TEBAREfExBQEREREfUxAQERHxMQUBERERH1MQEBER8TEFARERER9TEBAREfExBQEREREfUxAQERHxMQUBERGpcFJTUzEzEhMT2bNnT651mZmZmBmBQKB8igtaunQpgUCAY8eO5Vq+ceNGzIzU1NTyKSxCuumQiEgVVd73X4jG/Uj27dvH1KlTue+++6JQUXQtXbqUlJQUJk+ezHHH/fy9unnz5ixfvpyTTjqpHKsLn44IiIhIhTVw4EAeeeQRtm3bVt6lhC0+Pp6ePXvSuHHj8i4lLAoCIiJSYU2ePBmAe+65p8jtNmzYwMiRI2ncuDHx8fF069aNBQsW5Ntuzpw5dOzYMec2ygsXLqR///65bm98+PBhJkyYwCmnnELdunVp1qwZF154IWvWrMnZJhAIkJKSAkD16tUxM8y8G/vlPTUwbdo0atSowa5du/LV07lzZ4YPH57z/NChQ0ycOJGkpCRq1KhBUlISf/3rX/OdfogmBQEREamwmjdvzg033MA//vEPvv/++wK32bx5M2eccQaff/45Dz74IAsXLuS0005jxIgRLFy4MGe7t956i5EjR9KxY0fmz5/Pn//8Z2666Sa++eabXP0dOXKE/fv3M3nyZF577TWeeOIJDh8+TK9evdi6dSsAY8aM4fe//z0AH3zwAcuXL2f58uUF1nf55ZeTlZXF3Llzcy3/5JNPWL16NVdeeSXgjX0YNGgQTz/9NH/60594/fXXGTNmDHfffTe33npryd7AMGiMgIiIVGgTJ05kxowZpKSk8Oyzz+ZbHwgEcM6RlpZGo0aNABg0aBCbN28mOTmZYcOGAXDXXXfRuXNnFixYkPPt/ZRTTqF79+6cfPLJOf0lJCTw9NNP5zzPyspi0KBBNG3alDlz5jBhwgRatmxJy5YtATjjjDOIiyv84/SEE05gwIABzJo1i/Hjx+csnzVrFomJiQwdOhTwjlZ88MEHpKWl0bdvXwDOOeccAFJSUpg4cSJNmjSJ/A0sho4IiIhIhdawYUNuueUWZs6cydq1a/Otf+ONN7jgggtISEggMzMz5zFo0CA+//xz0tPTycrKYuXKlYwYMSInBAD86le/IikpKV+fL730EmeccQaJiYnExcVRp04dDhw4UOD+w3HllVeyYsUK1q1bB3jf/ufMmcOll15KfHx8zus48cQT6d27d67XMXDgQI4ePcqKFStKtO/iKAiIiEiFN2HCBBo2bEhycnK+ddu3b2fmzJlUr1491yP7cPquXbvYuXMnR48eLfAbddOmTXM9X7RoEZdddhmdOnXihRde4KOPPuLjjz+mcePGHD58uET1//rXv6ZOnTrMmjULgDfffJPt27fnnBbIfh3ff/99vtdx+umn57yOsqBTAyIiUuHVrVuX22+/nVtuuSXf+fJGjRrRp08fJk6cWGDbFi1aEBcXR/Xq1dm+fXu+9du2baN169Y5z1988UXatWuXax6Ao0ePsnv37hLXX6dOHS6++GJmz55NSkoKzz//PG3btuXMM8/M9TqSkpJ46aWXCuyjTZs2Jd5/URQERESkUhg/fjzTp0/PuZIg2+DBg1m+fDldunShVq1ahbbv3r07//rXvwgEAjmnBz755BM2bNiQKwgcOnQo3zn/WbNmkZWVlWtZ9iH9jIwM6tWrV2z9V155Jc8//zxLlizhlVdeyRdoBg8ezL/+9S/q1q1Lx44di+0vWhQERESkUoiPjyc5OZlrr7021/IpU6Zw+umn07dvX2644QbatGnDnj17WLVqFevXr88ZYJiSksLAgQO5+OKLufbaa9m5cyeBQIBmzZrlmhBo8ODBvPLKK0yYMIGhQ4eycuVKHnnkERITE3Ptt3PnzgA88MADnH/++VSrVo3u3bsXWv8555xDixYt+P3vf09GRgajRo3KtX7kyJH885//5JxzzuGWW26ha9eu/PTTT3z33XcsXLiQV155hdq1a5fmLSyQxgiIiEilMXr0aNq3b59rWevWrVm5ciVdu3bljjvu4LzzzmPcuHGkpaUxYMCAnO3OO+88Zs+ezerVq7n44ouZOnUqDzzwAM2aNSMhISFnu7FjxzJp0iTmzp3LhRdeyOLFi1m0aFGubQCGDh3K+PHjefzxx+nVqxc9evQosvbjjjuOyy+/nC1bttCrVy/atWuXa3316tVZsmQJY8eO5R//+AcXXHABI0eO5LnnnqN3797UqFGjpG9bkcw5VyYdV2Rm5srqdZf3lJ6xFI3pQ0Wixc+/e6tXr6ZTp07lVE3l9sMPP9CuXTsmTZrEnXfeWd7llEpx/w7MDOec5V2uUwMiIuILGRkZ3HzzzZx77rkcf/zxrF+/nvvvv5/atWszZsyY8i6v3CgIiIiIL1SrVo2tW7dyww03sGvXLurUqUOfPn2YN28ezZs3L+/yyk3Mg4CZtQIeBM4DDPgPcJNzblMYbQs7nn+qc+6zqBUpIiJVTo0aNQq8/4DfxTQImFlt4B3gCHAV4IB7gHfN7JfOuYNhdJMKzMiz7JsCthMREZFixPqIwFigLdDBObcOwMy+AL4FrgOmh9HHFudc2cyzKCIi4jOxvnxwGLAiOwQAOOc2AMuA4YW2EhERkTIR6yDQBVhVwPKvgM5h9jHOzI6Y2SEze8fM+kSvPBEREX+JdRBoCOwpYPluoEEY7Z8HxgPnAtcCjYB3zKx/lOoTERHxlUo1s6BzbpRzbq5z7n3n3PPAWcD/8AYc5mNmATNzeR8xLVpERKQCi3UQ2EPB3/wLO1JQJOfcfuA1oMB5HZ1zAeec5X1Euh8REZGqKtZB4Cu8cQJ5dQa+LkW/+pYvIlKFpKamYmYkJiayZ0/u74mZmZmYGYFAoEz2/dlnnxEIBEp12+HCZL+ujRs3Rr3vkor15YMLgb+ZWVvn3HoAM2sDnAncFmlnZlYfGAr8N5pFiohUBRmb3y3X/ddqdXap+9i3bx9Tp07lvvvui0JF4fnss89ISUnhiiuuoGHDhjHbb3mJ9RGBp4CNwKtmNtzMhgGvApsJmSTIzE40s0wzSw5Z9mcze8rMLjez/mZ2Fd5lh82ASTF9FSIiEhMDBw7kkUceYdu2beVdSoGysrLIzMws7zJKJaZBIDhz4AC8mQBnAbOBDcAA59yBkE0NqJanvrV4pxAeBt7Cm3xoA3CWc+79sq9eRERibfLkyQDcc0+BY8JzbNiwgZEjR9K4cWPi4+Pp1q1bvumEr776atq0aZOvbf/+/enfvz/gHbofPXo0AO3bt8fMch3KNzMmTZrEfffdR1JSEjVq1ODLL7/k8OHDTJgwgVNOOYW6devSrFkzLrzwQtasWVO6NyAGYn6vgeA9BUYUs81GvDAQumwRsKjsKhMRkYqmefPm3HDDDfz973/nz3/+MyeeeGK+bTZv3swZZ5xBkyZNePDBB2ncuDFz585lxIgRvPLKKwwbNizs/Q0ZMoTJkydzzz33MG/ePFq2bJlTR7bU1FTatm3L3/72N+rUqUOLFi04cuQI+/fvZ/LkyTRv3pzdu3fz+OOP06tXL1avXk2zZs1K/2aUEd19UEREKrSJEycyY8YMUlJSePbZZ/OtDwQCOOdIS0ujUaNGAAwaNIjNmzeTnJwcURBo3LgxJ510EgDdunWjXbt2+bZxzvHmm29Sq1atXMuffvrpnD9nZWUxaNAgmjZtypw5c5gwYULYNcRapZpHQERE/Kdhw4bccsstzJw5k7Vr1+Zb/8Ybb3DBBReQkJBAZmZmzmPQoEF8/vnnpKenR7WewYMH5wsBAC+99BJnnHEGiYmJxMXFUadOHQ4cOFBgzRWJgoCIiFR4EyZMoGHDhiQnJ+dbt337dmbOnEn16tVzPW699VYAdu3aFdVaQk8TZFu0aBGXXXYZnTp14oUXXuCjjz7i448/pnHjxhw+fDiq+482nRoQEZEKr27dutx+++3ccsstOR/w2Ro1akSfPn2YOHFigW1btGgBQM2aNfnpp5/yrd+1a1fOKYVwmOWfl+7FF1+kXbt2pKam5iw7evRomcxFEG0KAiIiUimMHz+e6dOn51xJkG3w4MEsX76cLl26FHjIPtuJJ57Itm3b2LFjB40bNwbgu+++Y+3atfTu3Ttnu/j4eAAyMjLCru3QoUPExeX+SJ01axZZWVlh91FedGpAREQqhfj4eJKTk1myZEmu5VOmTGHfvn307duX5557jrS0NF555RXuuecerrnmmpztLrnkEsyMK664giVLljB79myGDx/O8ccfn6u/zp29m+E+9thjLF++nJUrVxZ4JCHU4MGDWbNmDRMmTODtt99m6tSpJCcnk5iYGJ0XX4YUBEREpNIYPXo07du3z7WsdevWrFy5kq5du3LHHXdw3nnnMW7cONLS0hgwYEDOdu3atePll19my5YtXHTRRdx///1Mnz6dk08+OVd/Xbt2JRAIsGjRIs466yx69OjB//73vyLrGjt2LJMmTWLu3LlceOGFLF68mEWLFpGQkBC9F19GzDn/TdNvZq6sXnda335l0m9F1O+9tPIuQSSHn3/3Vq9eTadOncqpGqkoivt3YGYUdOM9HREQERHxMQUBERERH1MQEBER8TEFARERER9TEBAREfExBQEREREfUxAQERHxMQUBERERH1MQEBER8TEFARERER9TEBARkQonNTUVM8t51KtXj65du/Loo4+SmZkZtf0EAoFctxXeu3cvgUCATz/9NN+2/fv3p3///lHbd0Wh2xCLiFRRZz5yZrnuf9mNy0rdx7x582jZsiXp6enMmzePG2+8ke3btzNlypQoVAhjxoxh8ODBOc/37t1LSkoKLVu25LTTTsu17eOPPx6VfVY0CgIiIlJhdevWjXbt2gEwcOBA1q1bx0MPPRS1INCyZUtatmwZ1rbZtyeuanRqQEREKo0ePXqQnp7O9u3beeONN+jVqxe1atUiISGBiy66iLVr1+bafsmSJfTu3ZuEhATq1q1Lhw4dcoWI0FMDGzduJCkpCfBuK5x9WiI1NRXIfWpg69atxMXF8fDDD+er8f7776d69ers2LEjZ9n8+fPp2bMntWvXJjExkUsuuYRNmzZF860pMQUBERGpNDZs2EC1atVYuXIlQ4YMoW7dusydO5cnnniCVatWcdZZZ7FlyxYA1q9fz7Bhw0hKSmLu3LksXLiQm2++mYMHDxbYd/PmzZk/fz4At99+O8uXL2f58uUMGTIk37bNmjXj3HPP5fnnn8+3btasWQwePJjGjRsD8OSTTzJixAg6d+7Myy+/zIwZM1i1ahX9+vVj//790XprSkynBkREpMLKysoiMzOT/fv389JLLzF//nwuvPBCkpOTadu2La+//jpxcd5HWa9evTj55JN54IEHmD59Op9++ik//fQTTzzxBPXr1wdgwIABhe4rPj6eU089FYC2bdvSs2fPImsbNWoUV1xxBWvXrqVDhw4AfPbZZ6xatYo777wTgAMHDjBx4kRGjx7Ns88+m9P29NNPp0OHDjzzzDPcdNNNJX5/okFHBEREpMLq2LEj1atXp2HDhowfP56RI0fy2GOP8emnn3LZZZflhACApKQkzjzzTNLS0gBvfEH16tX57W9/y8svv8z27dujWtvFF19M3bp1mTVrVs6yWbNmkZCQwLBhwwBYvnw56enpjBw5kszMzJxHq1at6NixI++9915UayoJBQEREamwFixYwMcff8yaNWs4ePAgM2fOxDmHc47mzZvn275Zs2bs3r0bgHbt2rFkyRKOHTvGqFGjaNasGT179swJCqVVu3ZtRowYwezZs3HOkZWVxZw5c7jkkkuoWbMmQE74OPfcc6levXqux5dffsmuXbuiUktp6NSAiIhUWKecckrOVQPZGjRogJmxdevWfNtv3bqVhg0b5jw/++yzOfvsszly5AjLli0jOTmZIUOGsHHjRo4//vhS1zdq1Ciee+45PvjgAzIyMvjxxx8ZNWpUzvpGjRoB3rwIXbp0yde+Xr16pa6htBQERESkUqlTpw6/+tWvmDdvHoFAgGrVqgHw/fff8+GHH3LjjTfmaxMfH8+AAQM4cOAAw4cPZ8OGDQUGgfj4eAAyMjLCquXss8+mZcuWzJo1i4yMDNq0aUOfPn1y1vfu3Zt69eqxbt06rrrqqpK83DKnICAiIpXO3XffzZAhQxg6dCjjx4/nwIED3HXXXSQkJHDLLbcA3mj99957jwsuuIBWrVqxc+dO7r33Xlq0aMEpp5xSYL9NmzalUaNGvPjii/zyl7+kTp06JCUl5Xyzz+u4445j5MiRzJgxg6NHjzJhwoRcMxXWr1+fadOmcf3117Njxw7OP/98EhIS2LJlC2lpafTv35/LL788+m9QBDRGQEREKp3Bgwfz2muvsXfvXi699FL+8Ic/0KlTJz744ANatGgBQNeuXTl48CC33347AwcO5IYbbiApKYl33nmHWrVqFdjvcccdx9NPP82ePXs499xz6dGjB4sWLSqyllGjRrF3714OHjyY67RAtuuuu46FCxeydu1aRo0axQUXXEAgECAzM5Nu3bqV+r0oLXPOlXcNMWdmrqxed1rffmXSb0XU773oDLgRiQY//+6tXr2aTp06lVM1UlEU9+/AzHDOWd7lOiIgIiLiYwoCIiIiPqYgICIi4mMKAiIiIj6mICAiIuJjCgIiIlWAH68Ak5+V5u9fQUBEpJKLi4sjMzOzvMuQcnT06NGcGRYjpSAgIlLJ1axZkwMHDpR3GVKO0tPTS3zfAgUBEZFKrnHjxuzYsYNDhw7pFIGPOOf46aef2LlzJ3v27Ml1s6VI6F4DIiKVXM2aNWnatClbt27lyJEj5V2OxFC1atWoV68erVu3zrlhUqRiHgTMrBXwIHAeYMB/gJucc5si7Oc24F5gmXPurKgXKiJSiSQkJJCQkFDeZUglFNNTA2ZWG3gH6AhcBYwC2gPvmlmdCPppC0wGtpdFnSIiIn4R6yMCY4G2QAfn3DoAM/sC+Ba4DpgeZj9PALOBDuj0hoiISInFerDgMGBFdggAcM5tAJYBw8PpwMwuB04Dbi+TCkVERHwk1kGgC7CqgOVfAZ2La2xmDfDGF/zFObc7yrWJiIj4TqyDQENgTwHLdwMNwmg/DfgGSA1nZ2YWMDOX9xF2tSIiIlVcpZlHwMz6AFcC41yYF8o65wLOOcv7KNtKRUREKo9YD7TbQ8Hf/As7UhBqBvAM8IOZJQaXxQHVgs8znHO6gFZERCQCsQ4CX+GNE8irM/B1MW07BR9/KGDdHmAC8PfSFCciIuI3sQ4CC4G/mVlb59x6ADNrA5wJ3FZM27MLWPZ3oBpwI7CugPUiIiJShFgHgaeAG4BXzWwy4IC7gc14h/4BMLMTge+AKc65KQDOuaV5OzOzvUBcQetERESkeDEdLOicOwgMwBv5PwtvUqANwADnXOitswzvm36lGcwoIiJSGcV8Vr7gPQVGFLPNRrwwUFxf/aNTlYiIiD/pG7eIiIiPKQiIiIj4mIKAiIiIjykIiIiI+JiCgIiIiI8pCIiIiPiYgoCIiIiPKQiIiIj4mIKAiIiIjykIiIiI+JiCgIiIiI8pCIiIiPiYgoCIiIiPKQiIiIj4mIKAiIiIjykIiIiI+FhEQcDM+ppZ3ULW1TWzvtEpS0RERGIh0iMC7wKdC1nXIbheREREKolIg4AVsS4eyCpFLSIiIhJjccVtYGZtgLYhi7oXcHqgFnANsCl6pYmIiEhZKzYIAFcBdwEu+HiE3EcGXPB5JnB9tAsUEZHcMjb76yxsrVZnl3cJVVo4QSAVWIr3Yf8O3of913m2OQJ845zbHc3iREREpGwVGwScc98D3wOY2dnAp865/WVdmIiIiJS9cI4I5HDOpZVVIVL56PCkiEjlF+k8AjXM7C4zW2Nmh8wsK88js6wKFRERkeiL6IgAMA1vjMDrwHy8sQEiIiJSSUUaBH4D3OWc+2tZFCMiIiKxFemEQnWB5WVRiIiIiMRepEFgEaD7CYiIiFQRkZ4aeASYaWbHgMVAvnkDnHPro1GYiIiIlL1Ig0D2aYEA3myDBalW4mpEREQkpiINAtfgTSksIiIiVUCkEwqlllEdIiIiUg4iHSwIgJkdZ2anmFk/M6sT7aJEREQkNiIOAmZ2PbAV+ALvJkQdgstfMbM/Rrc8ERERKUuRTjE8FngIeAW4lNy3I34fGBG1ykRERKTMRXpE4GbgAefctcCCPOvWEDw6ICIiIpVDpEEgCVhSyLqDQGKpqhEREZGYijQI7ATaFLKuA7ClVNWIiIhITEUaBP4NJJtZ25BlzsyOBybgjR0QERGRSiLSIDAZ79bDq4D/4E0u9DCwGsgCphTXgZm1MrOXzWyfmaWb2Xwzax1GuxPN7FUz+97MMsxsp5mlmdkFEb4GERERCYooCDjndgLdgXuB6sB3eJMSPQr0cs7tK6q9mdXGu+SwI3AVMApoD7wbxnwEdfFOTUwGLgB+D+wHXjOzX0fyOkRERMQT6RTDOOf2A3cHH5EaC7QFOjjn1gGY2RfAt8B1wPQi9vsV3od/DjN7DdgAjAbml6AeERERX4t0HoGTzaxfIev6mln7YroYBqzIDgEAzrkNwDJgeCS1BNtmAvuAzEjbioiISORjBP4OXFjIuqHAg8W074I3viCvr4DO4RQQnN44zsyamVkycDLeqQkRERGJUKRBoDvwXiHr3gN6FNO+IbCngOW7gQZh1nA/cBT4EbgV+K1z7u0w24qIiEiISINAPeBwIeuOAgmlKycsf8cLHBcCrwMvmNnQgjY0s4CZubyPGNQoIiJSKUQaBNYD5xSybgCwsZj2eyj4m39hRwrycc794Jxb6Zz7t3PuUmAF8LdCtg045yzvI5z9iIiI+EGkQWAmMMHMrjezeAAziw/ekfAm4Lli2n+FN04gr87A1xHWkm0l0K6EbUVERHwt0iDwN2Ah8Ahw0My2491j4JHg8qnFtF8I9AydmdDM2gBnBtdFxMyOA87Cm89AREREIhTRPALOuSzgN2Y2ADgPaIQ3yc+bzrmlYXTxFHAD8KqZTcabmfBuYDMwI3sjMzsR78N9inNuSnBZAO8UwjJgK9AMb16B04HLI3kdIiIi4gk7CJhZDbzz8bc5597EmyEwIs65g8EQ8SAwCzDgbeAm59yB0N0B1ch9xOJTvNMPv8UblLgV+Bzo45xbFmktIiIiEkEQcM79ZGZJlHLyHufcJmBEMdtsxAsDocsWUoLTByIiIlK4SMcIvAUMLItCREREJPYivdfAI8DzZhaHd8vhH/HO8+dwzq2PTmkiIiJS1iINAmnBnzcDEwrZplrJyxEREZFYijQIjC6TKkRERKRcRHr5YHETBomIiEglEulgQSDnDoCnmFk/M6sT7aJEREQkNiIOAsHphLcCX+DNJdAhuPwVM/tjdMsTERGRshRREDCzscBDeFcMXErua/3fp5j5AURERKRiifSIwM3AA865a4EFedatIXh0QERERCqHSINAErCkkHUHgcRSVSMiIiIxFWkQ2Am0KWRdB2BLqaoRERGRmIo0CPwbSA69jTDgzOx4vAmGXolWYSIiIlL2Ig0Ck4EjwCrgP8FlDwOrgSxgSvRKExERkbIWURBwzu0EugP3AtWBdXiTEj0K9HLO7Yt6hSIiIlJmIp1iGOfcfjN7CHgbOAFvXMCXzrn90S5OREREylbEQcDMkoFbgLohiw+Y2TTn3D1Rq0xERETKXERBwMxSgDuBp4EXgW1AU+B3QIqZxTnnAtEuUkRERMpGpEcExuJNKHRryLKvgHfMbB9wLRCIUm0iIiJSxiK9aiCBwicUeiO4XkRERCqJSIPAR0CPQtb1CK4XERGRSiLSUwN/BBaYWSYwj5/HCFwKXAMMN7OccOGcOxatQkVERCT6Ig0CXwR/3hd8hDLgy5DnrgT9i4iISAxF+kE9Be8DXkRERKqAiIKALg0UERGpWiIdLCgiIiJViIKAiIiIjykIiIiI+JiCgIiIiI8pCIiIiPiYgoCIiIiPKQiIiIj4mIKAiIiIjykIiIiI+JiCgIiIiI8pCIiIiPiYgoCIiIiPKQiIiIj4mIKAiIiIjykIiIiI+JiCgIiIiI8pCIiIiPhYzIOAmbUys5fNbJ+ZpZvZfDNrHUa77mb2DzNbY2aHzGyTmc02s6RY1C0iIlIVxTQImFlt4B2gI3AVMApoD7xrZnWKaf5boAvwMHA+cBtwGrDSzFqVWdEiIiJVWFyM9zcWaAt0cM6tAzCzL4BvgeuA6UW0neqc2xG6wMyWARuC/SaXScUiIiJVWKxPDQwDVmSHAADn3AZgGTC8qIZ5Q0Bw2ffADuCEKNcpIiLiC7EOAl2AVQUs/wroHGlnZtYJaAKsLmVdIiIivhTrINAQ2FPA8t1Ag0g6MrM44Em8IwLPlL40ERER/6nMlw8+CvQGrnDOFRQuMLOAmbm8j9iWKSIiUnHFOgjsoeBv/oUdKSiQmd0HXAtc45x7s7DtnHMB55zlfURctYiISBUV66sGvsIbJ5BXZ+DrcDows0nAROBG59ysKNYmIiLiO7E+IrAQ6GlmbbMXmFkb4MzguiKZ2R+Be4BJzrlHy6pIERERv4h1EHgK2Ai8ambDzWwY8CqwGZiRvZGZnWhmmWaWHLLst8DfgTeAd8ysZ8gj4isOREREJManBpxzB81sAPAgMAsw4G3gJufcgZBNDahG7qAyOLh8cPARKg3oX0Zli4iIVFmxHiOAc24TMKKYbTbifeiHLrsauLqs6hIREfGjynz5oIiIiJSSgoCIiIiPKQiIiIj4mIKAiIiIjykIiIiI+JiCgIiIiI8pCIiIiPiYgoCIiIiPKQiIiIj4mIKAiIiIjykIiIiI+JiCgIiIiI8pCIiIiPiYgoCIiIiPKQiIiIj4mIKAiIiIjykIiIiI+JiCgIiIiI8pCIiIiPiYgoCIiIiPKQiIiIj4mIKAiIiIjykIiIiI+JiCgIiIiI8pCIiIiPiYgoCIiIiPKQiIiIj4mIKAiIiIjykIiIiI+JiCgIiIiI8pCIiIiPiYgoCIiIiPKQiIiIj4mIKAiIiIjykIiIiI+JiCgIiIiI8pCIiIiPiYgoCIiIiPKQiIiIj4mIKAiIiIj8U8CJhZKzN72cz2mVm6mc03s9Zhtv0/M3vTzHaZmTOzq8u4XBERkSotpkHAzGoD7wAdgauAUUB74F0zqxNGFzcCtYB/l1mRIiIiPhIX4/2NBdoCHZxz6wDM7AvgW+A6YHox7ROcc8fMrB1wZZlWKiIi4gOxPjUwDFiRHQIAnHMbgGXA8OIaO+eOlWFtIiIivhPrINAFWFXA8q+AzjGuRURExPdiHQQaAnsKWL4baBDjWkRERHyvSl8+aGaB4NUFuR7lXZeIiEhFEesgsIeCv/kXdqSgVJxzAeec5X1Eez8iIiKVVayDwFd44wTy6gx8HeNaREREfC/WQWAh0NPM2mYvMLM2wJnBdSIiIhJDsQ4CTwEbgVfNbLiZDQNeBTYDM7I3MrMTzSzTzJJDG5tZPzP7DTA4uKi7mf0muExEREQiFNMJhZxzB81sAPAgMAsw4G3gJufcgZBNDahG/qCSAvQLeX598JHdRkRERCIQ65kFcc5tAkYUs81GCvhgd871L5uqRERE/KlKXz4oIiIiRVMQEBER8TEFARERER9TEBAREfGxmA8WFBERicSZj5xZ3iXEzLIbl8V8nwoCImHSf0YiUhXp1ICIiIiPKQiIiIj4mIKAiIiIjykIiIiI+JiCgIiIiI8pCIiIiPiYgoCIiIiPKQiIiIj4mIKAiIiIjykIiIiI+JiCgIiIiI8pCIiIiPiYgoCIiIiPKQiIiIj4mIKAiIiIjykIiIiI+JiCgIiIiI8pCIiIiPiYgoCIiIiPKQiIiIj4mIKAiIiIjykIiIiI+JiCgIiIiI8pCIiIiPiYgoCIiIiPKQiIiIj4mIKAiIiIjykIiIiI+JiCgIiIiI8pCIiIiPiYgoCIiIiPKQiIiIj4mIKAiIiIjykIiIiI+JiCgIiIiI/FPAiYWSsze9nM9plZupnNN7PWYbataWbTzOxHM8sws+Vm1resaxYREamqYhoEzKw28A7QEbgKGAW0B941szphdPEMMBZIBoYCPwJLzKxbmRQsIiJSxcXFeH9jgbZAB+fcOgAz+wL4FrgOmF5YQzPrClwOXOOc+2dwWRrwFTAFGFa2pYuIiFQ9sT41MAxYkR0CAJxzG4BlwPAw2h4F5oa0zQReBAaZWXz0yxUREanaYh0EugCrClj+FdA5jLYbnHOHCmhbA2hX+vJERET8JdZBoCGwp4Dlu4EGpWibvV5EREQiEOsxAjFlZgHgrkLWxbaYqqj1gPKuQMqI/VG/HxWafveqrPL43Yt1ENhDwd/8C/u2n7ftiYW0hZ+PDORwzgWAQPjlSWVgZs45p08qkRjT717VFOtTA1/hnevPqzPwdRhtk4KXIOZt+xOwLn8TERERKUqsg8BCoKeZtc1eYGZtgDOD64qyCKgOXBLSNg64DHjTOXck6tWKiIhUceaci93OvEmDPgcygMmAA+4G6gG/dM4dCG53IvAdMMU5NyWk/YvAIOBWYAMwDm9iod7OuU9j9kKkXOnwpEj50O9e1RTTIwLOuYPAAOAbYBYwG+8DfUB2CAgyoFoB9Y0G/gncA7wGtAIGKwSIiIiUTEyPCIhEg5kFggNBRSSG9LtXNSkIiIiI+JhuQywiIuJjCgJSYmZ2kZndXEZ9tzGzQOgVJrFmZleb2TXltX8RkVhQEJDSuAgokyAAtMGbFbLcggBwNaAgIFFXViHazFLNbGMJ2240s9ToVlQ+FOIjU6WnGBYRqaAuAs6liFuvl9DdwEMlbHsxkB7FWsrT1Xifb8+Wcx2Vgo4ISIkEvzlcBZxgZi742Bhc19jMnjSzLWZ2xMzWmNm1edo3M7PnzOx/wW1+NLN/m1kTM+sPvBvc9K2Q/vuHWdsgM/vQzPaZ2QEzW2tmyXm26WpmC81sj5llmNkyM+sTsn4p0A84M2T/SyN/p0RKLtLbqzvnvnPO/b+S7Ms59/+cc9+VpK1UbgoCUlJ3A4uBHUCv4ONiM6sPfABcgHefhyF4s0I+YWY3hrSfFWxzK3Ae8EfgB6A28ClwfXC7P4b0X+x8EcExBQvx5qe4DBiG962rTsg2pwEf4t2nYiwwAtgF/MfMfhXcbDzw/4AvQvY/Poz3RaRIhYVoM+sf/POvzewpM9sBbAu2aWdms8xsQzC4rjezJ8ysQd6+Q08NBMfaODO7zsymBAP3XjNbZGYt87TNdWogeHjdmVlPM5ttZunB4P6wmdXM07atmS02s0Nmtt3MHjCza4Pt20Tw3ijElwOdGpAScc59F/yP6ifn3Irs5WZ2J97NoX7hnPs2uPg/ZpYI3GVmTzjnMvE+WO9wzs0O6XZeSD/Z955YHdp/GE4DagDjnHPZhznfybPNNGAT3kRWPwX3twRYBdwJXOSc+9rM0oG4CPcvUpy7gcZAD7ygCnAESAj++RHgdWAUkP2B2wLYDNyEdwO2tsAdeGG8Vxj7vB0v/F4DNAEeAJ4H+ofRdhYwB/h1cF+BYA13AZhZDeAtIB5vttcdwBjgN2H0nSMkxL8MTMG7h0x7QsYJBUP8+3ghfSxwCPgD3v8xvZ1zn+AF9ufxJqW7Lti0qpzyKBMKAhJtg4GPgA3m3Qsi2xK8/xw6433L/hi41cwM74N6lYvOpBafAUeBF83sWeA959z27JVmVgvv28L/Acfy1PgfYGQUahApVBEhun/wj/91zo3J0+Y94L2QbT/Eu9Ha+2Z2ahinAzY65y4Pad8YmGZmLZxz/yum7QvOuezbuf/HzM4AfsfPt3i/Gu/D+gzn3H+D/b+O97vYupi+QynElxOdGpBoawL0xfswDn1kf9tvFPx5GV76/wteMNhiZslmVqp/k865dXj3ozgO75vMVjNbYWb9gps0xPumcGcBNd4ANChtDSKltCDvAjOrYWZ3mDfeJgPv3+v7wdUdwuhzcZ7nXwZ/hvNB/VoBbUPb9QQ2ZYcAgGCo/1cYfYf6jJ9D/G/MrEnoypAQP49giA8GecML8X0j3J8E6YiARNsuYDvwp0LWrwUIfku/HrjezDrgnTNNwTus+ERpCnDOvQu8GxxodSbeYcbXgucq9wLHgMeAmYW0P1aa/YuU0o8FLLsXuBHv3/KHwH6gJTCfn08fFGV3nufZd2stadvQQYzN8X7n89oWRt85nHPrzGwQMBEvxMeb2X+Bic65NHKH+DsL6sPMjtPvb+QUBKQ0jgC18ix7A+8/rE2hh+SL4pxbC9xhZn8ATgnpmwL6D1vw1tTvmFld4FUgyTn3sZm9D3QFPi3mP40jeHfGFImlgk6R/RaY6Zy7J3tB8N91RfAj3im/vJpG2pFCfPlQEJDS+BpoaGbjgJXAYeBBvMP+75vZg3hHAOoAHYE+zrnhZpaAdyhvNrAG73DgcKAB8Gaw72+ATOAaM9uN96G81jm3v6iCgmGiL96h0M3A8XgDpf6Hdx4RvEmQ3gOWmNkzeP+RHY93jrKac+62kNc33swuw7st9v5gaBEprYJCdFFq4/2ehBodvXJKZQUw2sxODxkjYHhX45SIQnxsKQhIaTyNd37w/4BE4HvnXBsz6w0k4x3iOwEvya/l53OGh/EuBRyLd4XBseD6kc65VwGcc7vM7IZgH2l4hwTPBpYWU9PnwPl4h1Kb4B3W/CDYd0aw70/NrAfeYKeH8UZr7wjW9GRIX1Pxzr8+DdQN1tE/7HdHpHAFheiivAFcZWZf4g0S/DXQu2xLDFsq3u/pfDObxM9XDWRf2hjWt3SF+PKjICAl5pw7iDd6OO/yPcCE4KOgdkf4+bKeovqfAcyIsKbleEcXittuNd7h1qK22Yo3H4JItOUL0Xij7wtzI96guL8Gny/G+937b6EtYsQ595OZDcS77PFJ4ADwAt7VQ/cB+8LsSiG+nOg2xCIiEnVm9m+gk3PupPKuRYqmIwJSaQQv6yvq0j7nnMuKVT0i4jHvBkoHgG/xzs1fgjer6LjyrEvCoyAglUkyP09iUpDv8e5aKCKxdQTvVGBrvPE8a4ExzrlnQCG+otOpAak0zKwF3lSrhTninPuyiPUiUg7MLEAxId451yY21UheCgIiIlKmFOIrNgUBERERH9Oc6iIiIj6mICAiIuJjCgIiksPMXHBgV/bzgJm5kOeJwWWnlUuBIhJ1CgIiUpSngV4hzxPxRn8rCIhUEZpHQEQK5Zz7AfihvOsws/jg1NQiEmU6IiBSBZjZyWa2wMy2m9lhM9tkZvPMLM7M+gcP+Y8ws1Qz22Nm6WY228waFdNvzqmB4K1gNwRXPRXs05nZ1RHUeZOZbQzW+F8z6x18nhqyzdXBfvsGX8NevHnrMbP6Zvaomf3PzI6Y2VozmxC8213e9m0Key0hy5yZ/dXMJpnZD2aWYWbvmVm3cF+TSGWnIwIiVcNrwB68KV134t318QJyh/2/493++XdAe7wb3rTAu6tjOH7Eu+vdfLwbwywMLv8unMZmNgbvNtXPAPOAk/BuTpNYSJPZwBzgN0BccHa61/BOSyQDX+JNYzsdaAzcEebryOtKYBNwAxAPTAHeNrP2zrndJexTpNJQEBCp5MzseKAdMNw5tzBk1QvB9dnPv3LOZd/D/g0z2w08b2bnOOfeLm4/zrkjZvb/gk/XO+dWRFDjcXhjC153zo0JWb6Vn29PndfLzrm/hGw7FDgLGO2cSw0uftPM6gC3mNl059zOcGsKUQsYGLybJmb2Ed6c+ROAO0vQn0ilolMDIpXfLmA9cJ+ZjTWz9oVs91Ke5/Pw7hXfq4Bto61l8DEvz/JXgcxC2izI87wvXr0v5Fn+PFCDkr+OxdkhAMA5txFYUYr+RCoVBQGRSs5504OeB6zEO2T/jZmtN7O8d37blqfdT3inE06IQZnNgz+356khC+9URkF+zPO8IbA7WHeorSHrS2JbIcti8b6IlDudGhCpApxz64Erg4PmuuKd737czDYCGcHNmoa2MbMaQANgSwxKzP5Qb5KnhmrA8YW0yTv/+W6goZnVyBMGmoWsBzgc/FkjT/vCBkY2LWRZLN4XkXKnIwIiVYjzfAbcHFx0SsjqS/Nsfgne/wHLI9hF9iV8tSIsLfsyxEvyLL+I8L+QpOHVm7ePkcBP/Pw6vg/+zHntZhYHDCyk3wuC4wyyt20D9CSy90Wk0tIRAZFKzsx+CTwEzAXW4d0P/mq8c+/vAPWCm3Yxs38CLwInA38FloYzUDDENrwxCb81sy+Ag8AG59yuoho5546ZWQreZYdP440VaAvcBuzDO/dfnNeBD4Anzawx8BXelRFjgHtDBgp+jHclw7TgIMUjwHi8KwIKkoE36HBacJsUIB3vCgeRKk9HBEQqv614l7/djHdJ3xy8ywKHOuc+CdnuT4DhBYb/A/5N/m/XRXLOHcP74G2Adynix8CFYbZ9Gm8k/nl4gwR/D1yBdwpgX5j7HgI8B0zEu5RwCN7rnhSyXSYwHNgMpAKPAW8F/1yQmcG+Hg32vQM4R5cOil/oNsQiVZyZ9QfeBc5zzv2nfKvJzcy644WJK51zs8ph/w74q3Nucqz3LVJR6NSAiMSEmSUB1wPv4x1674Q3CdAGCp9LQETKmIKAiJRK8EqFakVtEzxcn4E3gO9KvFMLe/BOL9zmnDtU1nWKSMF0akBESiV4r4F/FrWNc86KWi8i5UdBQERKJXjjoqSitnHOrYxROSISIQUBERERH9PlgyIiIj6mICAiIuJjCgIiIiI+piAgIiLiYwoCIiIiPvb/AQTZEEYx+bvcAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Plot the proportion of each sentiment class in the training and test sets\n",
    "#-to confirm the distribution is the same in both sets\n",
    "with plt.style.context(['notebook','no-latex']):\n",
    "    sns.barplot(x='split_group', \n",
    "                y='percent', \n",
    "                hue='sentiment', \n",
    "                palette = ['tab:red','moccasin','tab:green'],\n",
    "                data=df.groupby(['split_group'])['sentiment'].value_counts(normalize=True).\\\n",
    "                                                                         rename('percent').\\\n",
    "                                                                         reset_index())\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e529780-7636-4163-8c83-ca1ba3669430",
   "metadata": {},
   "source": [
    "### 4. Split training set into training set and validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5af10822-2ca3-4d99-b778-d8492594f0dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split the training set 75:25 using stratified sampling \n",
    "#Note: The below gets the indices of the tweets for the training and validation set\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, \n",
    "                                                  y_train, \n",
    "                                                  test_size=0.25, \n",
    "                                                  random_state=1, \n",
    "                                                  stratify=y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bd7183b4-31a6-469f-bb69-91530b6d5d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Note which tweets were split into the training and validation sets so we can see the division\n",
    "df.loc[X_train, 'split_group'] = 'training_set'\n",
    "df.loc[X_val, 'split_group'] = 'validation_set'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e8c1ba10-85b5-4180-ab5d-2518064ebd28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sentiment</th>\n",
       "      <th>label</th>\n",
       "      <th>split_group</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">Negative</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">0</th>\n",
       "      <th>test_set</th>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>training_set</th>\n",
       "      <td>129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>validation_set</th>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">Neutral</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">1</th>\n",
       "      <th>test_set</th>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>training_set</th>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>validation_set</th>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">Positive</th>\n",
       "      <th rowspan=\"3\" valign=\"top\">2</th>\n",
       "      <th>test_set</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>training_set</th>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>validation_set</th>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                Text\n",
       "sentiment label split_group         \n",
       "Negative  0     test_set          44\n",
       "                training_set     129\n",
       "                validation_set    43\n",
       "Neutral   1     test_set          26\n",
       "                training_set      78\n",
       "                validation_set    27\n",
       "Positive  2     test_set           6\n",
       "                training_set      18\n",
       "                validation_set     6"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby(['sentiment', 'label', 'split_group'])[['Text']].count().sort_values('label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "99e6f3a3-bd4a-408f-adbc-75ce839b2e9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Plot the proportion of each sentiment class in the training and test sets\n",
    "#-to confirm the distribution is the same in both sets\n",
    "with plt.style.context(['notebook','no-latex']):\n",
    "    sns.barplot(x='split_group', \n",
    "                y='percent', \n",
    "                hue='sentiment', \n",
    "                palette = ['tab:red','moccasin','tab:green'],\n",
    "                data=df.groupby(['split_group'])['sentiment'].value_counts(normalize=True).\\\n",
    "                                                                         rename('percent').\\\n",
    "                                                                         reset_index())\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d923354b-881f-41b4-986f-aa458bf71908",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "split_group\n",
       "test_set           76\n",
       "training_set      225\n",
       "validation_set     76\n",
       "Name: Text, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.groupby('split_group')['Text'].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5bd8143-533b-4e19-a54d-5beddaaec841",
   "metadata": {},
   "source": [
    "### 5. Modeling: XLM roBERTa\n",
    "`Baseline model` | `Default training configuration`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "298172c3-6ba2-43bc-8f4c-2616eb200aff",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Could not locate the tokenizer configuration file, will try to use the model config instead.\n",
      "loading configuration file https://huggingface.co/cardiffnlp/twitter-xlm-roberta-base-sentiment/resolve/main/config.json from cache at /Users/koredeakande/.cache/huggingface/transformers/9628a03bf91a381b0f93e02e13ed34077a805ede6a568ad868817f87437a55ea.ea50decabb7db740257ca1cdefd63c25ffafb958ec595a0ff0c8dbac3f4b1ae6\n",
      "Model config XLMRobertaConfig {\n",
      "  \"_name_or_path\": \"/home/jupyter/misc/tweeteval/TweetEval_models/xlm-twitter/local-twitter-xlm-roberta-base-sentiment/\",\n",
      "  \"architectures\": [\n",
      "    \"XLMRobertaForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"Negative\",\n",
      "    \"1\": \"Neutral\",\n",
      "    \"2\": \"Positive\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"Negative\": 0,\n",
      "    \"Neutral\": 1,\n",
      "    \"Positive\": 2\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"xlm-roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.8.0\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 250002\n",
      "}\n",
      "\n",
      "loading file https://huggingface.co/cardiffnlp/twitter-xlm-roberta-base-sentiment/resolve/main/sentencepiece.bpe.model from cache at /Users/koredeakande/.cache/huggingface/transformers/fa0936a0eed8b226fb1679d5c7062921e8e84e3d1536ff26b5ed08bdcd444d93.71e50b08dbe7e5375398e165096cacc3d2086119d6a449364490da6908de655e\n",
      "loading file https://huggingface.co/cardiffnlp/twitter-xlm-roberta-base-sentiment/resolve/main/tokenizer.json from cache at None\n",
      "loading file https://huggingface.co/cardiffnlp/twitter-xlm-roberta-base-sentiment/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/cardiffnlp/twitter-xlm-roberta-base-sentiment/resolve/main/special_tokens_map.json from cache at /Users/koredeakande/.cache/huggingface/transformers/6654a835c284613a15c3b583fce96f417606b95fab5ef47cc3da33de8ac237b6.0dc5b1041f62041ebbd23b1297f2f573769d5c97d8b7c28180ec86b8f6185aa8\n",
      "loading file https://huggingface.co/cardiffnlp/twitter-xlm-roberta-base-sentiment/resolve/main/tokenizer_config.json from cache at None\n"
     ]
    }
   ],
   "source": [
    "#Load the M-BERT tokenizer\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"cardiffnlp/twitter-xlm-roberta-base-sentiment\")\n",
    "\n",
    "class Generate_PyTorch_Dataset(torch.utils.data.Dataset):\n",
    "    \n",
    "    \"\"\"\n",
    "    Code adapted from NLPiation. (2021). \n",
    "    Is it possible to do Sentiment Analysis on unlabeled data using BERT? (Feat. Vader) [Experiment]. \n",
    "    https://nlpiation.medium.com/is-it-possible-to-do-sentiment-analysis-on-unlabeled-data-using-bert-feat-vader-experiment-357bba53768c\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, texts, labels, tokenizer):\n",
    "        self.texts    = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer  = tokenizer\n",
    "        self.max_len    = 128 #tokenizer.model_max_length\n",
    "  \n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "  \n",
    "    def __getitem__(self, idx):\n",
    "        text = str(self.texts[idx])\n",
    "        labels = self.labels[idx]\n",
    "\n",
    "        encoded_text = self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            add_special_tokens    = True,\n",
    "            truncation            = True,\n",
    "            return_attention_mask = True,\n",
    "            return_token_type_ids = False,\n",
    "            max_length            = self.max_len,\n",
    "            return_tensors        = 'pt',\n",
    "            padding               = \"max_length\"\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            'input_ids': encoded_text['input_ids'][0],\n",
    "            'attention_mask': encoded_text['attention_mask'][0],\n",
    "            'labels': torch.tensor(labels, dtype=torch.long)\n",
    "        }\n",
    " \n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    \n",
    "    \"\"\"\n",
    "    Function to compute accuracy metrics\n",
    "    \n",
    "    Input:\n",
    "        - eval_pred (tuple): Tuple containing the model predictions and targets to be matched \n",
    "                             in the form: (predictions,targets)]\n",
    "                             \n",
    "    Output:\n",
    "        - (dict): Dictionary containing different accuracy-related metrics\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    #Get the predicted labels and the true labels\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    \n",
    "    #Compute, precision, recall, f1 and accuracy score\n",
    "    #We use macro so we can better see the effect of the class imbalance i.e. treat all classes as equal\n",
    "    precision, recall, f1, _ = precision_recall_fscore_support(labels, predictions, average='macro')\n",
    "    accuracy = accuracy_score(labels, predictions)\n",
    "    \n",
    "    return {\n",
    "        'f1': f1,\n",
    "        'precision': precision,\n",
    "        'recall': recall,\n",
    "        'accuracy': accuracy,}\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56686777-ed69-49f7-86af-70cfd5b7c4ef",
   "metadata": {},
   "source": [
    "#### a. Encode the training and validation sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e276435b-69ac-48e8-89da-858f8e3c57ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prepare the Training and validation sets\n",
    "train_set_dataset = Generate_PyTorch_Dataset(\n",
    "    texts    = df.query(\"split_group == 'training_set' \").Text.tolist(),\n",
    "    labels = df.query(\"split_group == 'training_set' \").label.tolist(),\n",
    "    tokenizer  = tokenizer\n",
    ")\n",
    "\n",
    "val_set_dataset = Generate_PyTorch_Dataset(\n",
    "    texts    = df.query(\"split_group == 'validation_set' \").Text.tolist(),\n",
    "    labels = df.query(\"split_group == 'validation_set' \").label.tolist(),\n",
    "    tokenizer  = tokenizer\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2e95dd3-e884-49c8-960e-8052bd2e7c19",
   "metadata": {},
   "source": [
    "#### b. Load the XLM roBERTa model and fine-tune using Huggingface Trainer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c8eadfd-95b9-4a8f-b00e-6cd3dd6e5972",
   "metadata": {},
   "source": [
    "**Load the RoBERTa model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "76699c90-e517-4778-a12a-9d47bb0c9fe1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/cardiffnlp/twitter-xlm-roberta-base-sentiment/resolve/main/config.json from cache at /Users/koredeakande/.cache/huggingface/transformers/9628a03bf91a381b0f93e02e13ed34077a805ede6a568ad868817f87437a55ea.ea50decabb7db740257ca1cdefd63c25ffafb958ec595a0ff0c8dbac3f4b1ae6\n",
      "Model config XLMRobertaConfig {\n",
      "  \"_name_or_path\": \"/home/jupyter/misc/tweeteval/TweetEval_models/xlm-twitter/local-twitter-xlm-roberta-base-sentiment/\",\n",
      "  \"architectures\": [\n",
      "    \"XLMRobertaForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"Negative\",\n",
      "    \"1\": \"Neutral\",\n",
      "    \"2\": \"Positive\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"Negative\": 0,\n",
      "    \"Neutral\": 1,\n",
      "    \"Positive\": 2\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"xlm-roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"output_past\": true,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.8.0\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 250002\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/cardiffnlp/twitter-xlm-roberta-base-sentiment/resolve/main/pytorch_model.bin from cache at /Users/koredeakande/.cache/huggingface/transformers/4356cbb44d246494fb9361d024371aee59c2fc67b648f4f964f1dbb2ba53e5b5.a22545cd79d055b2220db85f4707145de60be10ed4b5cdebfe0bd19b5a8c3a43\n",
      "All model checkpoint weights were used when initializing XLMRobertaForSequenceClassification.\n",
      "\n",
      "All the weights of XLMRobertaForSequenceClassification were initialized from the model checkpoint at cardiffnlp/twitter-xlm-roberta-base-sentiment.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use XLMRobertaForSequenceClassification for predictions without further training.\n"
     ]
    }
   ],
   "source": [
    "#Load the M-BERT model\n",
    "xlmr_model = AutoModelForSequenceClassification.from_pretrained(\"cardiffnlp/twitter-xlm-roberta-base-sentiment\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8472a3bb-106b-4780-a895-a037770fdc5e",
   "metadata": {},
   "source": [
    "#### â€¢ Evaluating the model: How well does it classify tweets?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ea96740-f9ea-4c47-907e-7581eba39d07",
   "metadata": {},
   "source": [
    "**Training set (Note: The model was never exposed to these tweets!)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e157d2c1-2ee2-46fa-923f-31bb3997cf92",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "***** Running Prediction *****\n",
      "  Num examples = 225\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='39' max='29' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [29/29 01:20]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "xlmr_training_args = TrainingArguments(\n",
    "    output_dir = \"../model_predictions\",\n",
    "    do_predict = True\n",
    ")\n",
    "\n",
    "xlmr_trainer = Trainer(\n",
    "    model           = xlmr_model,\n",
    "    args            = xlmr_training_args,\n",
    "    compute_metrics = compute_metrics,\n",
    ")\n",
    "\n",
    "xlmr_train_preds = xlmr_trainer.predict(train_set_dataset, metric_key_prefix='train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "7a8cb76f-8bc6-4ce0-87d8-53aedd42294a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_loss</th>\n",
       "      <th>train_f1</th>\n",
       "      <th>train_precision</th>\n",
       "      <th>train_recall</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>train_runtime</th>\n",
       "      <th>train_samples_per_second</th>\n",
       "      <th>train_steps_per_second</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.58935</td>\n",
       "      <td>0.698938</td>\n",
       "      <td>0.689209</td>\n",
       "      <td>0.710959</td>\n",
       "      <td>0.764444</td>\n",
       "      <td>61.5466</td>\n",
       "      <td>3.656</td>\n",
       "      <td>0.471</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   train_loss  train_f1  train_precision  train_recall  train_accuracy  \\\n",
       "0     0.58935  0.698938         0.689209      0.710959        0.764444   \n",
       "\n",
       "   train_runtime  train_samples_per_second  train_steps_per_second  \n",
       "0        61.5466                     3.656                   0.471  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame([xlmr_train_preds[-1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "790550e4-b30a-42d0-9b75-cfdf4e321740",
   "metadata": {},
   "source": [
    "**Validation set (Note: The model was never exposed to these tweets!)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9fe3681a-745f-4200-930b-d75119bb4ee7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Prediction *****\n",
      "  Num examples = 76\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>validation_loss</th>\n",
       "      <th>validation_f1</th>\n",
       "      <th>validation_precision</th>\n",
       "      <th>validation_recall</th>\n",
       "      <th>validation_accuracy</th>\n",
       "      <th>validation_runtime</th>\n",
       "      <th>validation_samples_per_second</th>\n",
       "      <th>validation_steps_per_second</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.552696</td>\n",
       "      <td>0.721598</td>\n",
       "      <td>0.726449</td>\n",
       "      <td>0.71892</td>\n",
       "      <td>0.763158</td>\n",
       "      <td>20.8673</td>\n",
       "      <td>3.642</td>\n",
       "      <td>0.479</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   validation_loss  validation_f1  validation_precision  validation_recall  \\\n",
       "0         0.552696       0.721598              0.726449            0.71892   \n",
       "\n",
       "   validation_accuracy  validation_runtime  validation_samples_per_second  \\\n",
       "0             0.763158             20.8673                          3.642   \n",
       "\n",
       "   validation_steps_per_second  \n",
       "0                        0.479  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xlmr_val_preds = xlmr_trainer.predict(val_set_dataset, metric_key_prefix='validation')\n",
    "pd.DataFrame([xlmr_val_preds[-1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac3313fb-1d27-491b-a10d-0d3e102ac3dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a6c6a57-7df0-4199-8a3a-705041176df9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3cc9c22-78ac-455f-a1c4-604ca2f05c63",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "130908bc-cc0d-4245-b32d-5512d79d83c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2d58a32f-2c7e-49df-a2a9-32dbf96277a8",
   "metadata": {},
   "source": [
    "**Setup Trainer and train**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d8d0b390-2802-4361-90fe-e18735fcc556",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "***** Running training *****\n",
      "  Num examples = 225\n",
      "  Num Epochs = 10\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 290\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='146' max='290' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [146/290 33:42 < 33:42, 0.07 it/s, Epoch 5/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.731400</td>\n",
       "      <td>0.584165</td>\n",
       "      <td>0.524136</td>\n",
       "      <td>0.506353</td>\n",
       "      <td>0.555268</td>\n",
       "      <td>0.763158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.377600</td>\n",
       "      <td>1.014708</td>\n",
       "      <td>0.577986</td>\n",
       "      <td>0.843475</td>\n",
       "      <td>0.546225</td>\n",
       "      <td>0.736842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.166500</td>\n",
       "      <td>1.108933</td>\n",
       "      <td>0.589080</td>\n",
       "      <td>0.658081</td>\n",
       "      <td>0.576945</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.088500</td>\n",
       "      <td>1.257645</td>\n",
       "      <td>0.691191</td>\n",
       "      <td>0.705260</td>\n",
       "      <td>0.680304</td>\n",
       "      <td>0.763158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.011000</td>\n",
       "      <td>1.169710</td>\n",
       "      <td>0.690918</td>\n",
       "      <td>0.769459</td>\n",
       "      <td>0.658915</td>\n",
       "      <td>0.815789</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 76\n",
      "  Batch size = 8\n",
      "/Users/koredeakande/opt/anaconda3/envs/capstone/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "Saving model checkpoint to ../models/checkpoint-29\n",
      "Configuration saved in ../models/checkpoint-29/config.json\n",
      "Model weights saved in ../models/checkpoint-29/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 76\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ../models/checkpoint-58\n",
      "Configuration saved in ../models/checkpoint-58/config.json\n",
      "Model weights saved in ../models/checkpoint-58/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 76\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ../models/checkpoint-87\n",
      "Configuration saved in ../models/checkpoint-87/config.json\n",
      "Model weights saved in ../models/checkpoint-87/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 76\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ../models/checkpoint-116\n",
      "Configuration saved in ../models/checkpoint-116/config.json\n",
      "Model weights saved in ../models/checkpoint-116/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 76\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ../models/checkpoint-145\n",
      "Configuration saved in ../models/checkpoint-145/config.json\n",
      "Model weights saved in ../models/checkpoint-145/pytorch_model.bin\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "[enforce fail at inline_container.cc:300] . unexpected pos 34752 vs 34702",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m~/opt/anaconda3/envs/capstone/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization)\u001b[0m\n\u001b[1;32m    378\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0m_open_zipfile_writer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_zipfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 379\u001b[0;31m                 \u001b[0m_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopened_zipfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_protocol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    380\u001b[0m                 \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/capstone/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_save\u001b[0;34m(obj, zip_file, pickle_module, pickle_protocol)\u001b[0m\n\u001b[1;32m    498\u001b[0m         \u001b[0mnum_bytes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstorage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mstorage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0melement_size\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 499\u001b[0;31m         \u001b[0mzip_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite_record\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstorage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata_ptr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_bytes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    500\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: [Errno 28] No space left on device",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/j5/540q0bw12gx3g56qg4llbmlh0000gn/T/ipykernel_49589/3347766774.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     17\u001b[0m )\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0mxlmr_trainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/envs/capstone/lib/python3.7/site-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, **kwargs)\u001b[0m\n\u001b[1;32m   1329\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallback_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_epoch_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1331\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_log_save_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtr_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1332\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1333\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mDebugOption\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTPU_METRICS_DEBUG\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/capstone/lib/python3.7/site-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_maybe_log_save_evaluate\u001b[0;34m(self, tr_loss, model, trial, epoch)\u001b[0m\n\u001b[1;32m   1420\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1421\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_save\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1422\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_save_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1423\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallback_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1424\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/capstone/lib/python3.7/site-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_save_checkpoint\u001b[0;34m(self, model, trial, metrics)\u001b[0m\n\u001b[1;32m   1510\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_world_process_zero\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeepspeed\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1511\u001b[0m             \u001b[0;31m# deepspeed.save_checkpoint above saves model/optim/sched\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1512\u001b[0;31m             \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"optimizer.pt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1513\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcatch_warnings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecord\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcaught_warnings\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1514\u001b[0m                 \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlr_scheduler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"scheduler.pt\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/capstone/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization)\u001b[0m\n\u001b[1;32m    378\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0m_open_zipfile_writer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_zipfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    379\u001b[0m                 \u001b[0m_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopened_zipfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_protocol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 380\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    381\u001b[0m         \u001b[0m_legacy_save\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_protocol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    382\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/capstone/lib/python3.7/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 259\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfile_like\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite_end_of_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    260\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflush\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: [enforce fail at inline_container.cc:300] . unexpected pos 34752 vs 34702"
     ]
    }
   ],
   "source": [
    "#Define the training parameters\n",
    "xlmr_training_args = TrainingArguments(\n",
    "    output_dir                  = \"../models\",\n",
    "    num_train_epochs            = 10,\n",
    "    save_strategy               = \"epoch\",\n",
    "    logging_strategy            = \"epoch\",\n",
    "    evaluation_strategy         = \"epoch\"\n",
    ")\n",
    "\n",
    "#Define Trainer object\n",
    "xlmr_trainer = Trainer(\n",
    "    model           = xlmr_model,\n",
    "    args            = xlmr_training_args,\n",
    "    train_dataset   = train_set_dataset,\n",
    "    eval_dataset    = val_set_dataset,\n",
    "    compute_metrics = compute_metrics\n",
    ")\n",
    "\n",
    "xlmr_trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afda9ce2-c6c4-4c94-872d-1f7d3b40a6ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading model from ../models/checkpoint-145).\n",
      "***** Running training *****\n",
      "  Num examples = 225\n",
      "  Num Epochs = 10\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 290\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='117' max='290' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [117/290 29:12 < 43:55, 0.07 it/s, Epoch 4/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>1.202486</td>\n",
       "      <td>0.693616</td>\n",
       "      <td>0.765023</td>\n",
       "      <td>0.663508</td>\n",
       "      <td>0.815789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.000900</td>\n",
       "      <td>1.262526</td>\n",
       "      <td>0.770091</td>\n",
       "      <td>0.873432</td>\n",
       "      <td>0.723658</td>\n",
       "      <td>0.828947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.000600</td>\n",
       "      <td>1.353332</td>\n",
       "      <td>0.752525</td>\n",
       "      <td>0.852910</td>\n",
       "      <td>0.708154</td>\n",
       "      <td>0.802632</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "    <div>\n",
       "      \n",
       "      <progress value='8' max='10' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 8/10 00:16 < 00:04, 0.43 it/s]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 76\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ../models/checkpoint-29\n",
      "Configuration saved in ../models/checkpoint-29/config.json\n",
      "Model weights saved in ../models/checkpoint-29/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 76\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ../models/checkpoint-58\n",
      "Configuration saved in ../models/checkpoint-58/config.json\n",
      "Model weights saved in ../models/checkpoint-58/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 76\n",
      "  Batch size = 8\n",
      "Saving model checkpoint to ../models/checkpoint-87\n",
      "Configuration saved in ../models/checkpoint-87/config.json\n",
      "Model weights saved in ../models/checkpoint-87/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 76\n",
      "  Batch size = 8\n"
     ]
    }
   ],
   "source": [
    "xlmr_trainer.train(\"../models/checkpoint-145\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79c8029c-aa97-41b9-9cfa-b86d7ea424b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58518511-8343-4025-b9c7-41a7b00eb0d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b642e3a3-4f68-462f-aadd-d9c0e57fd220",
   "metadata": {},
   "source": [
    "#### Validation Results Discussion\n",
    "\n",
    "We see that the best model is the model from epoch 5 (checkpoint-145), which clearly outperforms the other models across all metrics. However, its classification performance is still pretty low: \n",
    "- **Validation Loss:** 0.820938\n",
    "- **F1:** 0.657895\n",
    "- **Precision:** 0.657895\n",
    "- **Recall:** 0.657895\n",
    "- **Accuracy:** 0.657895\n",
    "\n",
    "We load the model and predict on the test to diagnose what areas it is flawed in:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebd880a7-8375-4bb2-9532-b94343bdcdaf",
   "metadata": {},
   "source": [
    "### 6. Test set Prediction with the Fine-tuned M-BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7abcbeb3-544c-418e-84d2-906a136d47ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file ../models/checkpoint-145/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"bert-base-multilingual-cased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"transformers_version\": \"4.8.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 119547\n",
      "}\n",
      "\n",
      "loading weights file ../models/checkpoint-145/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing BertForSequenceClassification.\n",
      "\n",
      "All the weights of BertForSequenceClassification were initialized from the model checkpoint at ../models/checkpoint-145.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForSequenceClassification for predictions without further training.\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "***** Running Prediction *****\n",
      "  Num examples = 76\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='10' max='10' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [10/10 01:40]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Load the best checkpoint\n",
    "model = BertForSequenceClassification.from_pretrained(\"../models/checkpoint-145\")\n",
    "\n",
    "# Make the test set ready\n",
    "test_set_dataset = Generate_PyTorch_Dataset(\n",
    "    texts    = df.query(\"split_group == 'test_set' \").Text.tolist(),\n",
    "    labels = df.query(\"split_group == 'test_set' \").label.tolist(),\n",
    "    tokenizer  = tokenizer\n",
    ")\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir = \"../model_predictions\",\n",
    "    do_predict = True\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model           = model,\n",
    "    args            = training_args,\n",
    "    compute_metrics = compute_metrics,\n",
    ")\n",
    "\n",
    "test_preds = trainer.predict(test_set_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4ad4e1d-ae42-411b-ab43-2b5016a7db1f",
   "metadata": {},
   "source": [
    "### 7. Evaluating the model: How well does it classify tweets?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "33e99eb7-e1de-4834-8e5e-edf812a874d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>test_loss</th>\n",
       "      <th>test_f1</th>\n",
       "      <th>test_precision</th>\n",
       "      <th>test_recall</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>test_runtime</th>\n",
       "      <th>test_samples_per_second</th>\n",
       "      <th>test_steps_per_second</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.769877</td>\n",
       "      <td>0.697368</td>\n",
       "      <td>0.697368</td>\n",
       "      <td>0.697368</td>\n",
       "      <td>0.697368</td>\n",
       "      <td>112.782</td>\n",
       "      <td>0.674</td>\n",
       "      <td>0.089</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   test_loss   test_f1  test_precision  test_recall  test_accuracy  \\\n",
       "0   0.769877  0.697368        0.697368     0.697368       0.697368   \n",
       "\n",
       "   test_runtime  test_samples_per_second  test_steps_per_second  \n",
       "0       112.782                    0.674                  0.089  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame([test_preds[-1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b5ca4246-74eb-4a8b-9245-6048cbdf2925",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.84      0.77        43\n",
      "           1       0.68      0.63      0.65        27\n",
      "           2       0.00      0.00      0.00         6\n",
      "\n",
      "    accuracy                           0.70        76\n",
      "   macro avg       0.46      0.49      0.47        76\n",
      "weighted avg       0.64      0.70      0.67        76\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/koredeakande/opt/anaconda3/envs/capstone/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/koredeakande/opt/anaconda3/envs/capstone/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/koredeakande/opt/anaconda3/envs/capstone/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "y_true = df.query(\"split_group == 'test_set' \").label.tolist()\n",
    "preds = np.argmax(test_preds[0], axis=1).flatten()\n",
    "\n",
    "print(classification_report(y_true, preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bde0bf56-2806-4182-a952-6687ad825cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(y_true, preds)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels = ['Negative', 'Neutral', 'Positive'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "074f1b69-2e23-4532-b49a-4cba348af55e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "disp.plot(cmap='Blues',ax=None)\n",
    "plt.grid(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee0d16cf-2790-42f9-8ce8-b2a979096618",
   "metadata": {},
   "source": [
    "#### Pros\n",
    "- Does pretty well identifying negative predictions\n",
    "- Does okay identifying neutral predictions\n",
    "- Over-predicts negative\n",
    "\n",
    "#### Cons\n",
    "- Does not predict any positive sample\n",
    "- Overfits on the training data (see Appendix) -> Maybe try weight decay?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d2fe1d1-de38-46e9-a8f8-41322ea7a799",
   "metadata": {},
   "source": [
    "### 8. Brainstorming"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03b81717-16f7-4fd6-80d7-a448a3674982",
   "metadata": {},
   "source": [
    "#### Why might the model predict no positive sample\n",
    "- Trained on very few positive samples\n",
    "    - **Solution 1:** Try increasing batch size as the default is 8. With the current batch size, the model likely sees more and more negative and neutral samples in the iterations and this reinforces only these classes during its learning `[Choice 1]`\n",
    "    - **Solution 2:** Oversample positive class so we have more positive samples to train on `[Choice 2, as we are essentially tampering with the true class distribution]`\n",
    "\n",
    "#### Why does the model predict negative alot?\n",
    "- Trained on lots of negative samples (even relative to neutral)\n",
    "    - **Potential solution:** Class/loss function weighting. Essentially consider Positive, Neutral then Negative as more valuable\n",
    "- Overfitting?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed121f27-3d13-44cd-92c0-ad00da2b52cd",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "216bc3c2-717f-4103-8420-4329fd3c9b41",
   "metadata": {},
   "source": [
    "### 9. Modifying the M-BERT\n",
    "`Increased batch size` | `Loss function class reweighting`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9a730850-6045-434d-b21d-c4c604d68b42",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading file https://huggingface.co/bert-base-multilingual-cased/resolve/main/vocab.txt from cache at /Users/koredeakande/.cache/huggingface/transformers/eff018e45de5364a8368df1f2df3461d506e2a111e9dd50af1fae061cd460ead.6c5b6600e968f4b5e08c86d8891ea99e51537fc2bf251435fb46922e8f7a7b29\n",
      "loading file https://huggingface.co/bert-base-multilingual-cased/resolve/main/added_tokens.json from cache at None\n",
      "loading file https://huggingface.co/bert-base-multilingual-cased/resolve/main/special_tokens_map.json from cache at None\n",
      "loading file https://huggingface.co/bert-base-multilingual-cased/resolve/main/tokenizer_config.json from cache at /Users/koredeakande/.cache/huggingface/transformers/f55e7a2ad4f8d0fff2733b3f79777e1e99247f2e4583703e92ce74453af8c235.ec5c189f89475aac7d8cbd243960a0655cfadc3d0474da8ff2ed0bf1699c2a5f\n",
      "loading file https://huggingface.co/bert-base-multilingual-cased/resolve/main/tokenizer.json from cache at /Users/koredeakande/.cache/huggingface/transformers/46880f3b0081fda494a4e15b05787692aa4c1e21e0ff2428ba8b14d4eda0784d.b33e51591f94f17c238ee9b1fac75b96ff2678cbaed6e108feadb3449d18dc24\n"
     ]
    }
   ],
   "source": [
    "#Load the M-BERT tokenizer\n",
    "mb_tokenizer = BertTokenizer.from_pretrained('bert-base-multilingual-cased', do_lower_case= False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5271900-39d9-4501-ba92-858954bd0f6f",
   "metadata": {},
   "source": [
    "**Load the M-BERT model and fine-tune using Huggingface Trainer**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0c9dbcbc-2685-4579-95cb-f4680588b2a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/bert-base-multilingual-cased/resolve/main/config.json from cache at /Users/koredeakande/.cache/huggingface/transformers/6c4a5d81a58c9791cdf76a09bce1b5abfb9cf958aebada51200f4515403e5d08.0fe59f3f4f1335dadeb4bce8b8146199d9083512b50d07323c1c319f96df450c\n",
      "Model config BertConfig {\n",
      "  \"architectures\": [\n",
      "    \"BertForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.8.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 119547\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/bert-base-multilingual-cased/resolve/main/pytorch_model.bin from cache at /Users/koredeakande/.cache/huggingface/transformers/0a3fd51713dcbb4def175c7f85bddc995d5976ce1dde327f99104e4d33069f17.aa7be4c79d76f4066d9b354496ea477c9ee39c5d889156dd1efb680643c2b052\n",
      "Some weights of the model checkpoint at bert-base-multilingual-cased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.bias', 'cls.predictions.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "#Load the M-BERT model\n",
    "mb_model = BertForSequenceClassification.from_pretrained('bert-base-multilingual-cased',\n",
    "                                                         num_labels=len(df.label.unique()),\n",
    "                                                         output_attentions=False,\n",
    "                                                         output_hidden_states=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fdbebf3-9d26-40fb-b500-9ab6d340ec9f",
   "metadata": {},
   "source": [
    "**Setup Trainer and train**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "df630ee7-22e9-48a7-99f0-720b6d8918de",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "***** Running training *****\n",
      "  Num examples = 226\n",
      "  Num Epochs = 20\n",
      "  Instantaneous batch size per device = 32\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 32\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 160\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='160' max='160' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [160/160 1:23:34, Epoch 20/20]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.051113</td>\n",
       "      <td>0.565789</td>\n",
       "      <td>0.565789</td>\n",
       "      <td>0.565789</td>\n",
       "      <td>0.565789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.041448</td>\n",
       "      <td>0.565789</td>\n",
       "      <td>0.565789</td>\n",
       "      <td>0.565789</td>\n",
       "      <td>0.565789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.032430</td>\n",
       "      <td>0.565789</td>\n",
       "      <td>0.565789</td>\n",
       "      <td>0.565789</td>\n",
       "      <td>0.565789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.019221</td>\n",
       "      <td>0.565789</td>\n",
       "      <td>0.565789</td>\n",
       "      <td>0.565789</td>\n",
       "      <td>0.565789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.002962</td>\n",
       "      <td>0.565789</td>\n",
       "      <td>0.565789</td>\n",
       "      <td>0.565789</td>\n",
       "      <td>0.565789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.993876</td>\n",
       "      <td>0.565789</td>\n",
       "      <td>0.565789</td>\n",
       "      <td>0.565789</td>\n",
       "      <td>0.565789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.989401</td>\n",
       "      <td>0.565789</td>\n",
       "      <td>0.565789</td>\n",
       "      <td>0.565789</td>\n",
       "      <td>0.565789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.994158</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.631579</td>\n",
       "      <td>0.631579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.997211</td>\n",
       "      <td>0.592105</td>\n",
       "      <td>0.592105</td>\n",
       "      <td>0.592105</td>\n",
       "      <td>0.592105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.996090</td>\n",
       "      <td>0.592105</td>\n",
       "      <td>0.592105</td>\n",
       "      <td>0.592105</td>\n",
       "      <td>0.592105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.988920</td>\n",
       "      <td>0.644737</td>\n",
       "      <td>0.644737</td>\n",
       "      <td>0.644737</td>\n",
       "      <td>0.644737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.997571</td>\n",
       "      <td>0.644737</td>\n",
       "      <td>0.644737</td>\n",
       "      <td>0.644737</td>\n",
       "      <td>0.644737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.035216</td>\n",
       "      <td>0.592105</td>\n",
       "      <td>0.592105</td>\n",
       "      <td>0.592105</td>\n",
       "      <td>0.592105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.140046</td>\n",
       "      <td>0.578947</td>\n",
       "      <td>0.578947</td>\n",
       "      <td>0.578947</td>\n",
       "      <td>0.578947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.051062</td>\n",
       "      <td>0.644737</td>\n",
       "      <td>0.644737</td>\n",
       "      <td>0.644737</td>\n",
       "      <td>0.644737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.935632</td>\n",
       "      <td>0.578947</td>\n",
       "      <td>0.578947</td>\n",
       "      <td>0.578947</td>\n",
       "      <td>0.578947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.932084</td>\n",
       "      <td>0.605263</td>\n",
       "      <td>0.605263</td>\n",
       "      <td>0.605263</td>\n",
       "      <td>0.605263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.022057</td>\n",
       "      <td>0.657895</td>\n",
       "      <td>0.657895</td>\n",
       "      <td>0.657895</td>\n",
       "      <td>0.657895</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.113995</td>\n",
       "      <td>0.552632</td>\n",
       "      <td>0.552632</td>\n",
       "      <td>0.552632</td>\n",
       "      <td>0.552632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>No log</td>\n",
       "      <td>1.184374</td>\n",
       "      <td>0.618421</td>\n",
       "      <td>0.618421</td>\n",
       "      <td>0.618421</td>\n",
       "      <td>0.618421</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 76\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 76\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ../models/baseline-mbert/checkpoint-20\n",
      "Configuration saved in ../models/baseline-mbert/checkpoint-20/config.json\n",
      "Model weights saved in ../models/baseline-mbert/checkpoint-20/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 76\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 76\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ../models/baseline-mbert/checkpoint-40\n",
      "Configuration saved in ../models/baseline-mbert/checkpoint-40/config.json\n",
      "Model weights saved in ../models/baseline-mbert/checkpoint-40/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 76\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 76\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 76\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ../models/baseline-mbert/checkpoint-60\n",
      "Configuration saved in ../models/baseline-mbert/checkpoint-60/config.json\n",
      "Model weights saved in ../models/baseline-mbert/checkpoint-60/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 76\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 76\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ../models/baseline-mbert/checkpoint-80\n",
      "Configuration saved in ../models/baseline-mbert/checkpoint-80/config.json\n",
      "Model weights saved in ../models/baseline-mbert/checkpoint-80/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 76\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 76\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 76\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ../models/baseline-mbert/checkpoint-100\n",
      "Configuration saved in ../models/baseline-mbert/checkpoint-100/config.json\n",
      "Model weights saved in ../models/baseline-mbert/checkpoint-100/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 76\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 76\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ../models/baseline-mbert/checkpoint-120\n",
      "Configuration saved in ../models/baseline-mbert/checkpoint-120/config.json\n",
      "Model weights saved in ../models/baseline-mbert/checkpoint-120/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 76\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 76\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 76\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ../models/baseline-mbert/checkpoint-140\n",
      "Configuration saved in ../models/baseline-mbert/checkpoint-140/config.json\n",
      "Model weights saved in ../models/baseline-mbert/checkpoint-140/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 76\n",
      "  Batch size = 16\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 76\n",
      "  Batch size = 16\n",
      "Saving model checkpoint to ../models/baseline-mbert/checkpoint-160\n",
      "Configuration saved in ../models/baseline-mbert/checkpoint-160/config.json\n",
      "Model weights saved in ../models/baseline-mbert/checkpoint-160/pytorch_model.bin\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 76\n",
      "  Batch size = 16\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=160, training_loss=0.8776093482971191, metrics={'train_runtime': 5070.2923, 'train_samples_per_second': 0.891, 'train_steps_per_second': 0.032, 'total_flos': 617401325905920.0, 'train_loss': 0.8776093482971191, 'epoch': 20.0})"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class CustomTrainer(Trainer):\n",
    "    \n",
    "    \"\"\"\n",
    "    Class weighted trainer to account for imbalance\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, no_of_classes, samples_per_cls, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.class_weights = self.get_ens_weights(no_of_classes, samples_per_cls)\n",
    "        \n",
    "    def get_ens_weights(self, no_of_classes,samples_per_cls,beta=0.99):\n",
    "    \n",
    "        \"\"\"\n",
    "        Compute class weights using effective number of samples strategy\n",
    "        \"\"\"\n",
    "\n",
    "        effective_num = 1.0 - np.power(beta, samples_per_cls)\n",
    "        weights = (1.0 - beta) / np.array(effective_num)\n",
    "        weights = weights / np.sum(weights) * no_of_classes\n",
    "        weights = torch.tensor(weights.astype(np.float32))\n",
    "        \n",
    "        return weights\n",
    "    \n",
    "    def compute_loss(self, model, inputs, return_outputs=False):\n",
    "        \n",
    "        labels = inputs.get(\"labels\")\n",
    "        #Forward pass\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.get('logits')\n",
    "        #Compute custom loss\n",
    "        loss_fct = torch.nn.CrossEntropyLoss(weight= self.class_weights)\n",
    "        loss = loss_fct(logits.view(-1, self.model.config.num_labels), labels.view(-1))\n",
    "        return (loss, outputs) if return_outputs else loss\n",
    " \n",
    "\n",
    "# Define the training parameters\n",
    "training_args = TrainingArguments(\n",
    "    output_dir                  = \"../models/baseline-mbert\",\n",
    "    num_train_epochs            = 20,\n",
    "    per_device_train_batch_size = 32, #Increase training batch size to ensure that each batch has a decent chance of containing a few positive samples.\n",
    "    per_device_eval_batch_size  = 16,\n",
    "    warmup_steps                = 500, #Add warmup steps since this is an entirely new problem domain for this pretrained model\n",
    "    save_steps                  = 20, \n",
    "    evaluation_strategy         = \"epoch\"\n",
    ")\n",
    "\n",
    "#Define Trainer object\n",
    "trainer = CustomTrainer(\n",
    "    no_of_classes   = len(df.label.unique()),\n",
    "    samples_per_cls = df.label.value_counts(sort=False).to_list(),\n",
    "    model           = mb_model,\n",
    "    args            = training_args,\n",
    "    train_dataset   = train_set_dataset,\n",
    "    eval_dataset    = val_set_dataset,\n",
    "    compute_metrics = compute_metrics\n",
    ")\n",
    "\n",
    "\n",
    "#Start pre-training!\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d62d600-8b33-4cd6-977c-e352eb0f6d0a",
   "metadata": {},
   "source": [
    "#### Validation Results Discussion\n",
    "\n",
    "No real improvement in performance despite increasing batch size and reweighting the loss function. The best model (one around epoch 18) performs pretty much the same as the previous run without the modifications"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aca897a-0a03-417e-b1e3-3dcccc6650d9",
   "metadata": {},
   "source": [
    "### 10. Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "730e4200-d322-4872-b969-e80d1b100599",
   "metadata": {},
   "source": [
    "Comparing the M-BERT models, to BerTweet models of the same training configuration, we see that the BerTweet models perform significantly better despite being a monolingual model (i.e. trained on English tweets). This might make sense because pidgin English represents a relatively small proportion of the Nigerian tweets and even the pidgin English tweets involved very light use of pidgin â€“ hence, the tweets closely mirrored English tweets. Moreover, the BerTweet was trained on tweets, conversely to the M-BERT which was trained on Wikipedia texts. Hence, the BerTweet likely more closely mirrors tweet informalities.\n",
    "\n",
    "Based on this, I choose to continue my modeling efforts with the BerTweet model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bee07b47-0dcc-4ff6-b9c6-4999507973f6",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d19d130f-86ab-4653-8b72-e525895ed895",
   "metadata": {},
   "source": [
    "# Appendix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8047f1be-feec-4f26-b239-f32c49510dc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file ../models/checkpoint-145/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"bert-base-multilingual-cased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"transformers_version\": \"4.8.0\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 119547\n",
      "}\n",
      "\n",
      "loading weights file ../models/checkpoint-145/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing BertForSequenceClassification.\n",
      "\n",
      "All the weights of BertForSequenceClassification were initialized from the model checkpoint at ../models/checkpoint-145.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForSequenceClassification for predictions without further training.\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "***** Running Prediction *****\n",
      "  Num examples = 226\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='29' max='29' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [29/29 04:42]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Load the best checkpoint\n",
    "model = BertForSequenceClassification.from_pretrained(\"../models/checkpoint-145\")\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir = \"../model_predictions\",\n",
    "    do_predict = True\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model           = model,\n",
    "    args            = training_args,\n",
    "    compute_metrics = compute_metrics,\n",
    ")\n",
    "\n",
    "train_set_preds = trainer.predict(train_set_dataset, metric_key_prefix = 'train')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "14fe763c-4d4b-4c63-879a-e180584dd58d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train_loss</th>\n",
       "      <th>train_f1</th>\n",
       "      <th>train_precision</th>\n",
       "      <th>train_recall</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>train_runtime</th>\n",
       "      <th>train_samples_per_second</th>\n",
       "      <th>train_steps_per_second</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.335659</td>\n",
       "      <td>0.90708</td>\n",
       "      <td>0.90708</td>\n",
       "      <td>0.90708</td>\n",
       "      <td>0.90708</td>\n",
       "      <td>293.3439</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.099</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   train_loss  train_f1  train_precision  train_recall  train_accuracy  \\\n",
       "0    0.335659   0.90708          0.90708       0.90708         0.90708   \n",
       "\n",
       "   train_runtime  train_samples_per_second  train_steps_per_second  \n",
       "0       293.3439                      0.77                   0.099  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame([train_set_preds[-1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b694b3f1-84de-4144-a3ee-3e0db1bae9bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.98      0.94       130\n",
      "           1       0.91      0.97      0.94        79\n",
      "           2       0.00      0.00      0.00        17\n",
      "\n",
      "    accuracy                           0.91       226\n",
      "   macro avg       0.60      0.65      0.63       226\n",
      "weighted avg       0.84      0.91      0.87       226\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/koredeakande/opt/anaconda3/envs/capstone/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/koredeakande/opt/anaconda3/envs/capstone/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/Users/koredeakande/opt/anaconda3/envs/capstone/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "train_y_true = df.query(\"split_group == 'training_set' \").label.tolist()\n",
    "train_preds = np.argmax(train_set_preds[0], axis=1).flatten()\n",
    "\n",
    "print(classification_report(train_y_true, train_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "49d51a46-e9a9-4e05-9031-91f44f5c1909",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm2 = confusion_matrix(train_y_true, train_preds)\n",
    "disp2 = ConfusionMatrixDisplay(confusion_matrix=cm2, display_labels = ['Negative', 'Neutral', 'Positive'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "41f4664c-18e8-46b9-a4c0-1d0cd72a8088",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWIAAAEJCAYAAACuby3jAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjQuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/MnkTPAAAACXBIWXMAAAsTAAALEwEAmpwYAAAx3UlEQVR4nO3deVxVZf7A8c9hVUPEBdxSmjRxX8bKFdwmCQGRRZPc09FKGNOGERW0X7hrPyrNGR2XfhlWLiymhlY2hktmNia4TZmgIHJVVBYV5HJ+f5h3IuVexAvncvu+fZ3Xy3POvef5nvu6fHl4zrMoqqqqCCGE0IyN1gEIIcTvnSRiIYTQmCRiIYTQmCRiIYTQmCRiIYTQmCRiIYTQmCRiIYRVyb1RqHUID02RfsQVN3D8/5Klu651GBbp+4Q3tA7B4tnZSr3HFEc781xn0Etvk5lzvdzzjzd24cv1r5mnMDMw023/PmTprnM+O1frMCyS/DY3TT4j4xQzXivzch7nc26U/wIby/qlKIlYCGF9FOXuZuy8BZFELISwPorN3c3YeQsiiVgIYX2kRiyEEBqTGrEQQmhMsQEbW+PnLYgkYiGE9ZGmCSGE0FgNa5qwrGiEEMIc7tWIjW0PqaCgAD8/PzIzMwH45JNP8PPzw9/fn1mzZlFcXAzAqVOnCA4Oxtvbmzlz5lBSUmLy2pKIhRDW516N2Nj2EH744QdCQ0NJT08H4Ny5c6xbt46PP/6Y7du3U1payqZNmwCIiIggOjqa3bt3o6oqmzdvNnl9ScRCCOujKCYS8d0acXZ2NpmZmWW2vLy8+y63efNm5s2bh5ubGwAODg688cYbODk5oSgKbdq04eLFi2RlZXH79m26du0KQFBQEMnJySbDlTZiIYT1sbEFWyO9Jn7pUTFq1CiysrLKnAoLCyM8PLzMsQULFpTZb968Oc2bNwcgNzeXuLg4Fi1ahE6nw9XV1fA6V1dXcnJyTIYriVgIYX0q2GsiLi4OvV5f5pSzs3OFi8nJyWHSpEkEBwfTo0cPvv/++wcUZbo9WhKxEML6VLDXRNOmTStdxNmzZ/nzn//M6NGjeemllwBo3LgxV65cMbzm8uXLhuYMY6SNWAhhfRRM9Jp4tMsXFBQwceJEpk2bZkjCcLfJwtHRkaNHjwKQmJiIl5eXyetJjVgIYX2quB/x1q1buXLlCuvXr2f9+vUADBw4kGnTprF8+XKioqIoLCykffv2jB071nS4MjF8xXkMmSvzEZfj8jfvah2CxZOJ4Y1TMN/E8B7j1nI+5/7eD/e0bOzMmf+bZJ7CzEBqxEIIK2Rq0IYMcRZCiKp1rx+xsfMWRBKxEML6yKQ/QgihsRo26Y8kYiGE9ZFELIQQGrMxMTG8rOIshBBVTNqIhRBCa6amupQasRBCVC2pEQshhLYURTE661lFZkSrTpKIhRBWRxKxEEJoTLFRUGyMJGIj57QgidjCvTdvNKfOZrPywy+p5WjPsr+N4I/t3VFsFI6mpROxdDO3i+7QpFE9Vs4dTeOGdbGxseGdDz5n82dHtA5fE1s+O8J7cV+ColCnlj0LZ4TQtV1LrcOyKLv3p/Hme9spLi6hw1PNeTfqRZydamsdltncbSI2ViOuxmAqoMoeHWZmZuLh4cGBAwfKHB84cKBhFVRzePfdd/nuu+8AmDNnDqmpqWa7tpbaPNGYpFXhDPvTHw3HXp/gjZ2tDX1fXETf0IXUdrRn+vjBAERP9efoiXQ8Ry0m5C/vsXzmC7g1rKtV+Jr5KSOHN1Ym8fHbr/CvjTOZPsGb8ZHrtA7Loly5lk/Ymx/ywZJJHNk2F/fmDfmfldu1Dsus7jVNGNssSZX24bC3tyc6OpqCgoIqK+PIkSOGpU4WLFhAp06dqqys6jRpuBebPv2GxC/+u/TKwX//xPL1d1eGLS1VOX4mkxZNGgBga2ODs1MtAGrXckCvL6W09Pc3w6mDvR2xs0Np0qgeAF3btkR3NY/iO6aXNP+92PvNabq1d6dVy7srR0wM9mRL8hGsaUZcBROJ2MJmX6vSROzm5kbv3r1ZsmTJfefWrFlDYGAgQ4cOZenSpYYvwQcffMDgwYMJDg4mIiKCFStWAPDhhx8yfPhw/Pz88Pf35+zZsyQmJpKWlkZUVBRnzpxhzJgxHD58mLCwsDIrpwYFBXHixAkyMjKYMGECgYGBhIaGcvLkyaq8/Ufyt2Vb+OQ3TQtfHT7N2fM6AFo0qc/LoQNI+vLfALz53nZ8PDtxctcCvtkcxaI1O7lyrep+AVqqls0aMrhPBwBUVWXuOwl4e3bEwV5a4e7JyrlG88Yuhv1mbi7kF94mv/C2dkGZm1KBzYJUea/myMhI9u/fX6aJIiUlhbS0NLZu3UpiYiI5OTls376d06dPExcXR3x8PJs2bSIjIwO4uyzJF198wcaNG9mxYwd/+tOf2LRpE8OGDaNjx47Mnz8fDw8Pw/UDAgLYtWsXAOnp6RQVFdGhQwdmzpxJREQECQkJxMTEMH369Kq+/SrRpW0Ldv1zOms372P3/jQA1sSM492NX9B+yBx6jpjPtLHP8cf27hpHqp3CW0VMnLOBc5mXeXt2qNbhWJTScmq+tlY0cb1iY4ONkU35vQ1xdnJyIiYmhujoaLZvv9sOdejQIY4fP05QUBAAt2/fplmzZuTm5jJgwACcnJwA8PX1JS8vDycnJ9566y127txJeno6KSkptGvXrtwy+/XrR0xMDAUFBezYsQN/f38KCwtJS0tj1qxZhtfdvHmTa9euUb9+/Sr8BMwr6LnuLJ85gr8t28LW3XfbxhvUe4yeXVoR8Ordvx5+vnCZf317mt5/bM33JzO0DFcTmZdyGf3XNTz1RBMS3gundi0HrUOyKI83rs/RtHTD/sXLN3BxrsNjtR21C8rMpPvaA/Tt27dME4Ver2fcuHFMmDABgLy8PGxtbdm6dSulpaX3vT87O5sxY8YwevRovLy8aNSoEadOnSq3PAcHB/r378/evXtJTk5m9erVlJaW4uDgQFJSkuF1ly5dwsXFxbw3W4WGDuzK4r+GEBT+HsdOnTccz71RyEXddQIGdiP+86M0qPcYvbu15sOkQxpGq41rNwoJeOVdRvr2IGKSj9bhWKSBPdsR/U4CZ8/raNXSjQ3bUhjiZR3PVu6paYm42urn95oodDodPXv2JCkpicLCQkpKSpg6dSq7d++mV69e7Nu3j4KCAoqLi9mzZw+KopCamoq7uzvjx4+nS5cufP3114YHdLa2tob//1pAQAAbNmygXr16NG/enLp16/LEE08YEvGBAwcYNWpUdd2+WcydOhRFgXejXuTruEi+jotk2d9GAPDi66uZGOLJwU/m8Ok/phH7/h4OHTurccTVb0P8fjJzrrFz33H6j1li2HJvFGodmsVwbVCXlXNHMy5yHT2Gx3Dy7EXmvxakdVjmVcPaiKvtCca9JoqJEycyYMAA8vPzGTFiBHq9Hk9PTwIDA1EUhbFjx/LCCy9Qp04d6tevj6OjI3369OGjjz5iyJAhODg40LlzZ3788UcAPD09mTdv3n0PBLt3705+fj4jR440HFu2bBlvvPEGa9euxd7entjYWIv7zfhbU//nQ8P/nw5+s9zXpf2Yhe+Ut6shIss2Y4I3MyZ4ax2GxRvcp4PhoaY1qmk1YotaxfncuXPs27eP8ePHA/DKK68wfPhwBg4cqG1gv5BVnMsnqzibJqs4G2fOVZz/+NdPuXD1ZrnnWzSsw/fL/c1TmBlYVJ+e5s2bk5qaip+fH4qi0LdvXwYMGKB1WEKIGkaGOD8CBwcH3nrrLa3DEELUcDWtacKiErEQQphDTUvE0mglhLA+puaZqEQiLigowM/PzzBXzsGDB/H392fw4MHExsYaXnfq1CmCg4Px9vZmzpw5lJSYHl4viVgIYXXMPenPDz/8QGhoKOnp6cDdQWizZ89m1apV7Nq1i7S0NPbt2wdAREQE0dHR7N59d16YzZs3m7y+JGIhhPWpYD/i7OxsMjMzy2x5eXn3XW7z5s3MmzcPN7e7EyUdP34cd3d3WrRogZ2dHf7+/iQnJ5OVlcXt27fp2rUrcHeem1/Pe1MeaSMWQlgdG+XunBLGzgOMGjWKrKysMufCwsIIDw8vc2zBggVl9nU6Ha6uroZ9Nzc3cnJy7jvu6upKTk6OyXglEQshrE5FJ4aPi4u7b2Sus7Ozyes/aPiFoijlHjdFErEQwvqYGsb8y7mmTZtW6vKNGzfmypUrhn2dToebm9t9xy9fvmxozjBG2oiFEFanqlfo6NKlC+fOnSMjIwO9Xs+OHTvw8vKiefPmODo6cvToUQASExPx8vIyeT2pEQshrE5V9yN2dHRk8eLFhIeHU1RURL9+/Xj++ecBWL58OVFRURQWFtK+fXvGjh1r8nqSiIUQVufexPDGzlfG3r17Df/v1auXYY71X2vbti1bt259qOtKIhZCWCfLGjxnlCRiIYTVqWlDnCURCyGsjiRiIYTQmKnpJCwsD0siFkJYH6kRCyGExmxswMbI5O+V7DRRZSQRCyGsjjRNCCGExhRFMVojlqYJIYSoYlIjFkIIjcnDOiGE0JjUiIUQQmM2JuaaMHZOC5KIhRBWR2rEQgihOVNzDltWJpZELISwOlIjFkIIjUmvCSGE0JiNjfEBHcbOaUESsRDC6kjThBBCaOxuIjbWNFGNwVSAJOKH8H3CG6haB2Ghhq8/onUIFi/hzz20DuF3Q2rEQgihOem+JoQQmpIasRBCaEx6TQghhMakH7EQQmispiViy5qCSAghzOBeG7Gx7WEkJSXh6+uLr68vS5YsAeDUqVMEBwfj7e3NnDlzKCkpqXS8koiFEFbnXo3Y2FZRt27dYsGCBWzcuJGkpCS+++47Dh48SEREBNHR0ezevRtVVdm8eXOl45VELISwShWpDWdnZ5OZmVlmy8vLK3MdvV5PaWkpt27doqSkhJKSEuzs7Lh9+zZdu3YFICgoiOTk5ErHKm3EQgirU9FeE6NGjSIrK6vMubCwMMLDww37Tk5OTJs2DR8fH2rVqsWzzz6Lvb09rq6uhte4urqSk5NT6XglEQshrI6NomBjpPnh3rm4uDj0en2Zc87OzmX2T58+zbZt2/jqq6+oW7cuf/3rXzlw4MB913yUB4DlJuLr168bfaOLi0ulCxVCiKpU0QEdTZs2NXmt/fv306tXLxo2bAjcbYZYt24dV65cMbzm8uXLuLm5VTrechNxz549URQFVb1/dgVFUTh16lSlCxVCiKpkzkl/2rZty7Jly7h58ya1a9dm7969PPvss+zevZujR4/SvXt3EhMT8fLyqnS85Sbi06dPV/qiQgihJUUBY4PnHiYR9+3bl5MnTxIUFIS9vT2dOnVi8uTJPPfcc0RFRVFYWEj79u0ZO3ZspeM12UZcWlrKhg0b+PHHH4mKiiIuLo5JkyZha2tb6UKFEKIq2SgmHtY9ZHvu5MmTmTx5cpljbdu2ZevWrZWK77dMJuKlS5eSm5tLamoqqqqSkpLC5cuXiYqKMksAQghhbsov/4ydtyQm+xEfOnSIxYsX4+joSN26dVm/fv0DnxgKIYSlsFFMb5bEZI3Yzs4OG5v/5msHBwfs7KTXmxDCctW0uSZMZtQ2bdoY+tr9/PPPvP/++7Rt27Y6YhNCiEqpafMRm2yamDNnDidOnODq1auEhoZSWFjI7NmzqyM2IYSoFOWXAR3lbTWuRuzk5MTChQurIxYhhDCLmjYxvMka8dWrV5kxYwY9evSgb9++zJ49+75JMYQQwpKYexrMqmYyEUdFRdGiRQu2bt1KXFwc9erVY+7cudURmxBCVIoNxpsmbCys+5rJpomsrCz+/ve/G/ZnzpyJv79/lQYlhBCPQsH4Os2WlYYrUCN2c3PjwoULhv1Lly6Vmf5NCCEsjqlJ4S2sbaLcGvHLL78MQG5uLsOGDaN3797Y2Nhw+PBhPDw8qi1AIYR4WLY2YGvkgZythS2JUW4i9vb2fuDx/v37V1UsQghhFjWtH3G5iTgwMPCBx1VVJSMjo8oCEkKIR2V1I+s+/vhjli5dyq1btwzHGjRoIPNNCCEslqn5JCysG7HpRLxmzRo2bNjA3//+d1577TW++uorLl26VB2xCSFE5ZgaPWdhNWKTTdYuLi506dKFdu3acfXqVV555RVSU1OrIzYhhKgUpQKbJTGZiO3s7Lhx4wbu7u4cP34cgMLCwioPTAghKstWUbC1MbJZWI3YZNPEiBEjmDJlCv/4xz8YNmwYn3/+OU8++WR1xCbKseWzI7wX9yUoCnVq2bNwRghd27XUOizN9H+qEUM7NTHs13GwpeFjDpy6VICT439XknGr68iJ7HwW7fmPFmFalN3703jzve0UF5fQ4anmvBv1Is5OtbUOy2xq2sM6RX3Q6qC/cfPmTerUqUNOTg6pqal4enri6Oj4SAVnZmYyaNAg1q9fT58+fQzHBw4cyAcffMDjjz/+UNebNWsWYWFhNG/evMLv8fDw4MyZMxV+fWFRKSY/rCr2U0YOAa+u4Mv/i6BJo3p8fvAEEUs2cyzpfzSNa/j6I5qWf4+torDAvx17/3OFPad1huOtGz1GxJ+eYvanJ7laWKxJbAl/7qFJub915Vo+vV5YQPLaGbRq6ca8FYkUFBbxVuQLmsalAI5mmup89q7/cPXmnXLPN6xjz8IhbcxTmBmUe9sbNmwo902bNm1iwoQJj1y4vb090dHRbN++HScnp0e61uHDh5k6deojx2TpHOztiJ0dSpNG9QDo2rYluqt5FN8pwcFeJuwP7NqUG7dKyiRhOxuFv/RvxfpvMjRLwpZk7zen6dbenVYt7y7/PjHYk74vLmL5zBEWV1OsrHvTYBo7b0nK/cn9z3+q/s83Nzc3evfuzZIlS4iJiSlzbs2aNXz22Wfo9Xr69u1LREQEWVlZjB07lr179wKwYsUKABwdHdHpdEyePJm4uDiCg4Pp3Lkzp06dYtOmTXzwwQccOnSIGzduUL9+fVasWFFjh2m3bNaQls0aAnf7dM99JwFvz46ShIG6jnYEdGrK6wlpZY4P8nAl92Yxh9OvaRSZZcnKuUbzxi6G/WZuLuQX3ia/8LbVNE9YzYCORYsWVUsAkZGR+Pv7c+DAAUMTRUpKCmlpaWzduhVFUYiIiGD79u107979gdeYPHkyH3/8MWvWrKF+/foAeHl58fbbb5ORkcHPP//Mxx9/jI2NDX/729/49NNPeemll6rl/qpK4a0iwmPiuJhzjU/efkXrcCzC4HZufJtxDV1+UZnjQzs1YVXKOY2isjyl5bRG2lrauN9HUNPaiDWvRjk5ORETE2NoooC7C5YeP36coKAgAG7fvk2zZs3KTcQP0qVLFwDc3d2ZOXMmW7Zs4dy5cxw7doyWLWv2g63MS7mM/usannqiCQnvhVO7loPWIVmEPk82YN3BsqM+/9CwDjaKwonsfI2isjyPN67P0bR0w/7Fyzdwca7DY7Uf7bmPJbFVjPeMqHG9JqpD3759DU0UAHq9nnHjxhnaofPy8rC1teX69ev8+tliSUlJuQuZ3nuYmJaWxuuvv8748ePx9vbGxsaGCjyftFjXbhQS8Mq7jPTtQcQkH63DsRiPOdjS1LkWp3MKyhzv0NSZ1IuykMGvDezZjuh3Ejh7Xkerlm5s2JbCEK9OWodlVjaYGFlXbZFUjMXEExkZyf79+9HpdPTs2ZOkpCQKCwspKSlh6tSp7N69G2dnZ27cuEFubi7FxcWkpKQY3m9ra4ter7/vukeOHOHZZ58lNDSU1q1bc+DAgQe+rqbYEL+fzJxr7Nx3nP5jlhi23Bu/777dTZ1rce3mHfS/+SXbzLkWuoKict71++TaoC4r545mXOQ6egyP4eTZi8x/LUjrsMxKUf47zPlBm4VViE3XiEtLS1m/fj0//vgj0dHRxMXFMWnSJGxtbU299aHca6KYOHEiAwYMID8/nxEjRqDX6/H09CQwMBBFUZg4cSIhISE0adKETp3++1u8f//+TJ48mbVr15a57pAhQwgLC8Pf3x97e3s8PDzIzMw0a+zVacYEb2ZMePDMeL9nP10p5NXNP9x3fM3B9OoPpgYY3KcDg/t00DqMKnP3YZ2xNuKHu97evXtZuXIlN2/epG/fvkRFRXHw4EEWLVpEUVERPj4+TJ8+vfLxmupHvHjxYnJzc0lNTWXLli28/PLLtG3blqioqEoXWlNZQj9iS2Up/YgtmaX0I7ZU5uxHvPDLs1y7VVLu+fq17Zg9qFWFrnXhwgVefPFFtmzZQsOGDRk3bhxTpkxh3rx5bNy4kaZNmzJlyhTGjh1Lv379KhWvyaaJQ4cOsXjxYhwdHXFycmL9+vUy85oQwqIZHd78ywaQnZ1NZmZmme23iyN//vnnDBkyhCZNmmBvb09sbCy1a9fG3d2dFi1aYGdnh7+/P8nJyZWO1+TvHzs7O2xs/puvHRwcyn1AJoQQlkDBeC3zXsvEqFGjyMrKKnMuLCyM8PBww35GRgb29vZMnDiRy5cvM2DAAJ566qkyYxHc3NzIycmpdLwmM2qbNm2Ii4tDr9fz888/8/7779O2bdtKFyiEEFWtogM67uW2X3N2di6zr9fr+e6779i4cSN16tTh1VdfpXbt+we+PErfZJOJeM6cOSxcuJCrV68SGhpqaKgWQghLZWNiiPO9c02bNjV5rUaNGtGrVy8aNGgAwKBBg0hOTi7TYUGn0+Hm5lbpeE0mYicnJxYuXFjpAoQQoropmKgRP8S1BgwYwMyZM8nLy+Oxxx4jJSWF559/njVr1pCRkcHjjz/Ojh07CA4OrnS8JhPx/PnzH3hcasVCCEtlzqWSunTpwqRJk3jxxRe5c+cOffr0ITQ0lCeffJLw8HCKioro168fzz//fKXjNZmIXVxcDP+/c+cO+/fvp1u3bpUuUAghqprNr3pGlHf+YYSEhBASElLmWK9evQzTMjwqk4k4LCyszP6UKVOYMmWKWQoXQoiqYHWLh/5WnTp10Ol0pl8ohBAaUX75Z+y8JTGZiGNiYgzdMlRV5cSJE7JUkhDColldjfje/L73DB06lKFDh1ZZQEII8agUE4m4xk36c/78eZYuXVodsQghhFlY3cTwZ86cQVVViwtcCCHKY6uAsQVHbC0snZlMxI0aNcLX15cuXbrw2GOPGY5LP2IhhKWq6Mg6S1FuIi4uLsbBwYFu3bpJv2EhRI1iNW3EL7zwAgkJCff1IxZCCEtnNas41+R13YQQv282KNgY6Sts7JwWyk3ERUVFnDx5styE3KGD9S6zIoSo2WxtTDyss5jVOu8qNxFfuHCB8PDwByZiRVH48ssvqzQwIYSorLttxOZbs66qlZuIW7duTWJiYjWGIoQQ5mHOaTCrg6x5JISwOlbTfe3pp5+uzjiEEMJsrKbXhAzYEELUVDYYXzzUwp7VSdOEEML6KCaaJixtygZJxEIIq2M1bcRCCFFTKRjvGWFZaVgSsRDCClnNwzohhKiprG4+YiGEqGkUjPeMsKw0LIlYCGGF5GGdFSsoKkFfqnUUlilubHetQxDCQMFE04SF1YklEQshrE5NG9BhafEIIcQju/ewzthWGUuWLCEyMhKAU6dOERwcjLe3N3PmzKGkpKTS8UoiFkJYHaUC28M6dOgQCQkJhv2IiAiio6PZvXs3qqqyefPmSscriVgIYXVsFLBVlHK3e+vZZWdnk5mZWWbLy8u773rXr18nNjaWl19+GYCsrCxu375N165dAQgKCiI5ObnS8UobsRDC6lR0QMeoUaPIysoqcy4sLIzw8PAyx+bOncv06dPJzs4GQKfT4erqajjv6upKTk5OpeOVRCyEsDrKL/+MnQeIi4tDr9eXOefs7Fxmf8uWLTRt2pRevXoRHx8PPHhNz0cZJCKJWAhhdSpaI27atKnJa+3atYvLly8TEBDAjRs3uHnzJoqicOXKFcNrLl++jJubW6XjlUQshLA65lzFecOGDYb/x8fH8+2337Jo0SL8/Pw4evQo3bt3JzExES8vr0rHK4lYCGF9TNSIzTGeY/ny5URFRVFYWEj79u0ZO3Zspa+lqA9q7BAPlJNXLCPrylHLXjrgmFLHUeo9xiiAuT6ilJ9yuX2n/B/WWvY2eLZuYJ7CzEC+GUIIq2OjYOiiVt55SyKJWAhhdSraa8JSSCIWQlgdBRO9JqotkoqRRCyEsDpSIxZCCI3Z/DKU2dh5SyKJWAhhdWTNOiGE0Jis4iyEEBqTpZKEEEJjUiMWQgit1bBMLIlYCGF1FMV484OFtUxIIhZCWJ8aViGWRCyEsEI1LBNLIhZCWB3j4+pkZJ0QQlQ5GdAhhBAaq2EtE5KIhRDWR0ExMfuaZaViScRCCKsjTRNCCGEBLCzXGiWJWAhhfWpYI7EkYiGE1alp3ddk6d0aRFVVIhZ/xD8/+cpwLK/gFkMmLuP4mQsaRmZZTp29SEjYCgZPWIbPxLc4flo+m9/avT+NPqELeSb4TcZHriOv4JbWIZnVvcVDjW2WpFoTcWZmJh07diQgIIBhw4bh6+vLhAkTuHTp0kNd58svv+Sdd94B4N133+W7774DYM6cOaSmppo9bkvwU0YOo1//O7v+dcxw7KtvThL4ytv8fF6nXWAW5tbtYl6c8Q9eGTWIPRsieG38YMLe3Kh1WBblyrV8wt78kA+WTOLItrm4N2/I/6zcrnVY5qVUYLMg1V4jdnNzIykpicTERHbu3EnHjh2JiYl5qGsMGjSIadOmAXDkyBH0ej0ACxYsoFOnTmaP2RJ8mLifkOefZUj/roZj/xefwrLIUNwaOmsXmIXZ9+1p3Js1ZFCv9gAM7tuRf7w5XtugLMzeb07Trb07rVq6ATAx2JMtyUdQVVXjyMxHqcA/S6J508TTTz9Neno6x44dY/jw4QwdOpRx48aRkZEBwIYNGxg6dCjDhg1j7ty5AMTHxxMZGUliYiJpaWlERUVx5swZxowZw+HDhwkLCyM5OdlQRlBQECdOnCAjI4MJEyYQGBhIaGgoJ0+e1OSeK+ONacEEDn66zLH3l07hjx2e0CYgC/Xzhcu4NnTm9UUf4TPxLUa+9nfDL2pxV1bONZo3djHsN3NzIb/wNvmFt7ULyszudV8ztlkSTRPxnTt3+Oyzz+jcuTMzZswgOjqa7du3M3LkSGbMmEFJSQmrV69m27ZtxMfHoygKOTk5hvcPGzaMjh07Mn/+fDw8PAzHAwIC2LVrFwDp6ekUFRXRoUMHZs6cSUREBAkJCcTExDB9+vRqv2dRte6U6Nl76CSjhvbis3Wv81KIJ2Mi1lBUXKJ1aBajtJyar62t5vUyszF3y8TKlSvx9fXF19eXpUuXAnDw4EH8/f0ZPHgwsbGxjxRvtX/yOp2OgIAAAgICGDp0KKqqEhQUhLOzM507dwbAx8eH8+fPc+vWLbp160ZISAgrV65k1KhRNG7c2GQZ/fr149ixYxQUFLBjxw78/f0pLCwkLS2NWbNmERAQwOuvv87Nmze5du1aVd+yqEZNGtWjtXtjw18K3p6d0JeWcv7iFW0DsyCPN65PzpU8w/7Fyzdwca7DY7UdNYzKzMyYiQ8ePMj+/ftJSEggMTGREydOsGPHDmbPns2qVavYtWsXaWlp7Nu3r9LhVnv3tXttxL92+vTp+16nqip6vZ5Vq1Zx7Ngxvv76ayZNmsTy5ctNluHg4ED//v3Zu3cvycnJrF69mtLSUhwcHMqUfenSJVxcXB75noTlGNCzHW+uTOL46Qt0btuCb46dRUGhRdOGWodmMQb2bEf0OwmcPa+jVUs3NmxLYYiXdT1bURTFaM8I5Ze2iezs7PuarpydnXF2/u9zF1dXVyIjI3FwcACgVatWpKen4+7uTosWLQDw9/cnOTmZfv36VSpei+hH/OSTT3L9+nWOHz9O586d2bVrF82aNaO0tBQfHx+2bdtGt27duHTpEmfOnOGxxx4zvNfW1vaBbYABAQHMnz+fevXq0bx5cwCeeOIJkpKSCAgI4MCBA8ydO5cvvvii2u5TVD23hs6sWzSR2W9t4ebtYhzs7Vi74CVqOdprHZrFcG1Ql5VzRzMuch137pTwxOON+McbY7UOy6wqOp5j1KhRZGVllTkXFhZGeHi4Yf+pp54y/D89PZ1du3YxZswYXF1dDcfd3NzKNJs+LItIxA4ODsTGxhITE8OtW7eoV68esbGxNGjQgJEjRxISEkLt2rVp2rQpgYGB7Nmzx/BeT09P5s2bx5IlS8pcs3v37uTn5zNy5EjDsWXLlvHGG2+wdu1a7O3tiY2NNfxmrCmWRYbed+zrj6M1iMRy9ezaih3/nKF1GBZtcJ8ODO7TQeswqlYFfrTj4uIeWCN+kB9//JEpU6Ywc+ZM7OzsOHfuXNniHiGXKKo19VmpYjl5xehLtY7CMtWyt54HPVWljqNF1HsslgKY6yM6d/k2JaXlpzY7G4U/uNaq8PWOHj3KX/7yF2bPno2vry/ffvstq1at4v333wcgMTGRw4cPs2jRokrFKz89QgirY87ua9nZ2UydOpXly5fj6+sLQJcuXTh37hwZGRno9Xp27NiBl5dXpeOVX9FCCKtjzjl/1q1bR1FREYsXLzYcGzlyJIsXLyY8PJyioiL69evH888/X9lwpWniYUjTRPmkacI0aZowzpxNE+evFplsmmjZ0HK668k3QwhhdWRieCGE0FgNm45YErEQwgrVsEwsiVgIYZUsbYY1YyQRCyGsjo0CqpE8bGkTw0siFkJYHXlYJ4QQmrOwTGuCJGIhhNWRGrEQQmishnWakEQshLA+CiZqxNUWScVIIhZCWB1FMd55TZomhBCiGlhYrjVKErEQwuooiok2YgvL0pKIhRBWRzExrs7C8rAkYiGEFTKVaS0sE0siFkJYHem+JoQQGrMx0Qgsc00IIUQVq2kP62R9GyGE0JjUiIUQVqem1YglEQshrFBNmhZeErEQwgrZKGBseXqpEQshRHWwsGRrjCRiIYTVMdUwYWk5WhKxEMLqmGp6sLRELN3XhBBWR6nA9jA+/fRThgwZwnPPPUdcXJxZYwWpEQshrJEZq7w5OTnExsYSHx+Pg4MDI0eOpEePHrRu3dpsZUgifgg2CvI3RDksbcioJZKPqPqYGuJ8T3Z2Nnq9vswxZ2dnnJ2dDfsHDx6kZ8+euLi4AODt7U1ycjJhYWFmi1cS8UNwreugdQhCiApwrEBmu337NgEBAdy4caPM8bCwMMLDww37Op0OV1dXw76bmxvHjx83W6wgiVgI8TtVXFxMfHz8fcd/XRsGUNX7eyQrZu6ILIlYCPG79NsmiPI0btyY7777zrCv0+lwc3MzayzS4imEEEb07t2bQ4cOkZuby61bt9izZw9eXl5mLUNqxEIIYUTjxo2ZPn06Y8eO5c6dO4SEhNC5c2ezlqGoD2oAEUIIUW2kaUIIITQmiVgIITQmiVgIITQmiVgIITQmibiaZGZm4uHhwYEDB8ocHzhwIJmZmWYr59133zX0eZwzZw6pqalmu3Z1MvfnNWvWLLKysh7qPR4eHg9dTnXIzMykY8eOBAQEMGzYMHx9fZkwYQKXLl16qOt8+eWXvPPOO4D1fG9qKknE1cje3p7o6GgKCgqqrIwjR44Yxs4vWLCATp06VVlZVc2cn9fhw4cfOEKqpnJzcyMpKYnExER27txJx44diYmJeahrDBo0iGnTpgHW9b2piSQRVyM3Nzd69+7NkiVL7ju3Zs0aAgMDGTp0KEuXLjUkjQ8++IDBgwcTHBxMREQEK1asAODDDz9k+PDh+Pn54e/vz9mzZ0lMTCQtLY2oqCjOnDnDmDFjOHz4MGFhYSQnJxvKCgoK4sSJE2RkZDBhwgQCAwMJDQ3l5MmT1fNBVNDDfl6ZmZkMHDjQ8JoVK1awYsUK1qxZg06nY/LkyVy7do2BAwfy2muv4e3tzdWrV4mNjWXEiBF4e3szcuRILl++XJ23aRZPP/006enpHDt2jOHDhzN06FDGjRtHRkYGABs2bGDo0KEMGzaMuXPnAhAfH09kZKTVfW9qIknE1SwyMpL9+/eX+ZM7JSWFtLQ0tm7dSmJiIjk5OWzfvp3Tp08TFxdHfHw8mzZtMvxQFRQU8MUXX7Bx40Z27NjBn/70JzZt2sSwYcPo2LEj8+fPL/NndUBAALt27QIgPT2doqIiOnTowMyZM4mIiCAhIYGYmBimT59evR9GBTzM51WeyZMn4+bmxpo1a6hfvz4AXl5e7N69m4KCAn7++Wc+/vhjdu/eTcuWLfn000+r/L7M6c6dO3z22Wd07tyZGTNmEB0dzfbt2xk5ciQzZsygpKSE1atXs23bNuLj41EUhZycHMP7rfF7U9PIyLpq5uTkRExMjOGHBeDQoUMcP36coKAg4O6sUM2aNSM3N5cBAwbg5OQEgK+vL3l5eTg5OfHWW2+xc+dO0tPTSUlJoV27duWW2a9fP2JiYigoKGDHjh34+/tTWFhIWloas2bNMrzu5s2bXLt2zZCsLMHDfF7du3ev8HW7dOkCgLu7OzNnzmTLli2cO3eOY8eO0bJlS/PfiJnpdDoCAgKAu5PXdO7cmeDgYE6dOmUY9eXj48PcuXO5desW3bp1IyQkhEGDBjFq1CgaN25ssoya/L2paSQRa6Bv375l/uTW6/WMGzeOCRMmAJCXl4etrS1bt26ltLT0vvdnZ2czZswYRo8ejZeXF40aNeLUqVPllufg4ED//v3Zu3cvycnJrF69mtLSUhwcHEhKSjK87tKlS4Y5Vy1JRT+v69evl2kHLikpwc7uwV9xR0dHANLS0nj99dcZP3483t7e2NjY1Ii25HttxL92+vTp+16nqip6vZ5Vq1Zx7Ngxvv76ayZNmsTy5ctNllHTvzc1iTRNaOTen9w6nY6ePXuSlJREYWEhJSUlTJ06ld27d9OrVy/27dtHQUEBxcXF7NmzB0VRSE1Nxd3dnfHjx9OlSxe+/vprw4MWW1vb+ya6hrt/Zm7YsIF69erRvHlz6tatyxNPPGH4gTpw4ACjRo2q1s/gYVTk83J2dubGjRvk5uZSXFxMSkqK4f3lfS5Hjhzh2WefJTQ0lNatW3PgwIEHvq4mePLJJ7l+/bphrtxdu3bRrFkzSktL8fHxoU2bNkybNo0+ffpw5syZMu+11u9NTSE1Yo3c+5N74sSJDBgwgPz8fEaMGIFer8fT05PAwEAURWHs2LG88MIL1KlTh/r16+Po6EifPn346KOPGDJkCA4ODnTu3Jkff/wRAE9PT+bNm3ffA67u3buTn5/PyJEjDceWLVvGG2+8wdq1a7G3tyc2Ntbs86yaS0U/r4kTJxISEkKTJk3KPPnv378/kydPZu3atWWuO2TIEMLCwvD398fe3h4PDw+zdiesTg4ODsTGxhITE8OtW7eoV68esbGxNGjQgJEjRxISEkLt2rVp2rQpgYGB7Nmzx/Bea/3e1BQy6Y8FO3fuHPv27WP8+PEAvPLKKwwfPrxMzwAhRM0nNWIL1rx5c1JTU/Hz80NRFPr27cuAAQO0DksIYWZSIxZCCI3JwzohhNCYJGIhhNCYJGIhhNCYJGJRaZmZmbRr146AgADDNnToULZu3frI154yZYphqfOAgADy8vLKfW1+fj5jx4596DKSk5MZM2bMfccPHz6Mn5+fyfd7eHiQm5v7UGVGRkaybt26h3qPsH7Sa0I8klq1apUZZZWTk4Ofnx8dO3akbdu2ZinjtyPIfuvGjRsybaOo0SQRC7Nq3Lgx7u7upKenc/LkSbZu3cqtW7dwcnJi48aNbNmyhY8++ojS0lJcXFyIjo6mVatW5OTkEBkZiU6no1mzZly9etVwTQ8PDw4dOkSDBg1YvXo1CQkJ2NnZ4e7uzuLFi5k1axa3b98mICCA+Ph40tPTWbBgAdevX0ev1zNmzBhCQkIAeOedd/j0009xcXHB3d3d5P2cO3eON998k5s3b6LT6Wjbti1vv/22YYj022+/TWpqKqWlpbz22muG7oXl3acQD6QKUUkXLlxQu3btWubY999/rz7zzDPqxYsX1W3btqnPPPOMmp+fr6qqqh4+fFh98cUX1Zs3b6qqqqopKSmqj4+Pqqqq+uqrr6qxsbGqqqpqenq62rVrV3Xbtm2qqqpqmzZt1KtXr6pffPGFOnjwYPX69euqqqrqwoUL1VWrVpWJ486dO+qQIUPUtLQ0VVVVNS8vT/Xx8VH//e9/q59//rk6ZMgQNT8/X71z5446efJkdfTo0ffd1zfffKP6+vqqqqqqixcvVhMTE1VVVdXi4mLVz89PTU5ONsS1evVqVVVV9cyZM+qzzz6rXr161eh9zpw5U127du0jfe7C+kiNWDySezVRuDsZT/369Vm2bBlNmzYF7tZm780e969//YuMjIwyw2Vv3LjB9evXOXjwIDNnzgTuzojWo0eP+8o6dOgQzz//PPXq1QMwzAD26yHJ6enpnD9/ntmzZ5eJ8eTJk5w9e5bnnnvOEE9wcDAbN240en8REREcOHCAf/7zn6Snp6PT6bh586bhfGhoKABt2rShVatW/Pvf/+bo0aPl3qcQDyKJWDyS37YR/1adOnUM/y8tLSUgIICIiAjDvk6no169eiiKUmbWswfNmmZra1tmToO8vLz7HuLp9XqcnZ3LxHTlyhXq1q3LsmXLypRha2tr8v5mzJiBXq/Hx8eH/v37k52dXeYaNjb/fd6tqip2dnZG71OIB5FeE6La9OnTh507d6LT6QD46KOPGDduHHB30plPPvkEgIsXL3L48OH73t+7d28+//xzw9JJK1as4P3338fOzg69Xo+qqvzhD3/A0dHRkIizs7Px8/MjLS0NT09PkpOTycvLo7S01ORDQID9+/czdepUhgwZgqIo/PDDD2VmKUtISAAwrFzRpUsXo/cpxINIjVhUG09PT/785z/z0ksvoSgKTk5OrFy5EkVRmDdvHrNmzcLHx4cmTZo8sMdFv379+OmnnwzNAa1btyYmJobatWvTvn17fHx8+Oijj1i1ahULFixg7dq1lJSUMG3aNMOk8WfOnCE4OBhnZ2fatm3LtWvXjMY8ffp0pk6dSr169ahduzbPPPMM58+fN5y/cOECw4YNQ1EU/vd//xcXFxej9ynEg8hcE0IIoTFpmhBCCI1JIhZCCI1JIhZCCI1JIhZCCI1JIhZCCI1JIhZCCI1JIhZCCI1JIhZCCI39P7p4l87/bDiUAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "disp2.plot(cmap='Blues',ax=None)\n",
    "plt.grid(False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "0e2578e9-0df7-48cd-959e-7d91529e3850",
   "metadata": {},
   "outputs": [],
   "source": [
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "62cc7f95-4554-44f4-ab7f-36ba3f8a5415",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file ../models/checkpoint-87/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"bert-base-multilingual-cased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.11.3\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 119547\n",
      "}\n",
      "\n",
      "loading weights file ../models/checkpoint-87/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing BertForSequenceClassification.\n",
      "\n",
      "All the weights of BertForSequenceClassification were initialized from the model checkpoint at ../models/checkpoint-87/.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForSequenceClassification for predictions without further training.\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "***** Running Prediction *****\n",
      "  Num examples = 76\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='10' max='10' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [10/10 01:38]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/koredeakande/opt/anaconda3/envs/jupyterlab/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "loading configuration file ../models/checkpoint-29/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"bert-base-multilingual-cased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.11.3\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 119547\n",
      "}\n",
      "\n",
      "loading weights file ../models/checkpoint-29/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing BertForSequenceClassification.\n",
      "\n",
      "All the weights of BertForSequenceClassification were initialized from the model checkpoint at ../models/checkpoint-29/.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForSequenceClassification for predictions without further training.\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "***** Running Prediction *****\n",
      "  Num examples = 76\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='10' max='10' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [10/10 01:21]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/koredeakande/opt/anaconda3/envs/jupyterlab/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "loading configuration file ../models/checkpoint-290/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"bert-base-multilingual-cased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.11.3\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 119547\n",
      "}\n",
      "\n",
      "loading weights file ../models/checkpoint-290/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing BertForSequenceClassification.\n",
      "\n",
      "All the weights of BertForSequenceClassification were initialized from the model checkpoint at ../models/checkpoint-290/.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForSequenceClassification for predictions without further training.\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "***** Running Prediction *****\n",
      "  Num examples = 76\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='10' max='10' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [10/10 01:19]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file ../models/checkpoint-58/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"bert-base-multilingual-cased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.11.3\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 119547\n",
      "}\n",
      "\n",
      "loading weights file ../models/checkpoint-58/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing BertForSequenceClassification.\n",
      "\n",
      "All the weights of BertForSequenceClassification were initialized from the model checkpoint at ../models/checkpoint-58/.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForSequenceClassification for predictions without further training.\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "***** Running Prediction *****\n",
      "  Num examples = 76\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='10' max='10' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [10/10 01:16]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/koredeakande/opt/anaconda3/envs/jupyterlab/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "loading configuration file ../models/checkpoint-116/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"bert-base-multilingual-cased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.11.3\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 119547\n",
      "}\n",
      "\n",
      "loading weights file ../models/checkpoint-116/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing BertForSequenceClassification.\n",
      "\n",
      "All the weights of BertForSequenceClassification were initialized from the model checkpoint at ../models/checkpoint-116/.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForSequenceClassification for predictions without further training.\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "***** Running Prediction *****\n",
      "  Num examples = 76\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='10' max='10' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [10/10 01:17]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/koredeakande/opt/anaconda3/envs/jupyterlab/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "loading configuration file ../models/checkpoint-174/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"bert-base-multilingual-cased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.11.3\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 119547\n",
      "}\n",
      "\n",
      "loading weights file ../models/checkpoint-174/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing BertForSequenceClassification.\n",
      "\n",
      "All the weights of BertForSequenceClassification were initialized from the model checkpoint at ../models/checkpoint-174/.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForSequenceClassification for predictions without further training.\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "***** Running Prediction *****\n",
      "  Num examples = 76\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='10' max='10' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [10/10 01:16]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/koredeakande/opt/anaconda3/envs/jupyterlab/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "loading configuration file ../models/checkpoint-145/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"bert-base-multilingual-cased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.11.3\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 119547\n",
      "}\n",
      "\n",
      "loading weights file ../models/checkpoint-145/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing BertForSequenceClassification.\n",
      "\n",
      "All the weights of BertForSequenceClassification were initialized from the model checkpoint at ../models/checkpoint-145/.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForSequenceClassification for predictions without further training.\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "***** Running Prediction *****\n",
      "  Num examples = 76\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='10' max='10' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [10/10 01:16]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/koredeakande/opt/anaconda3/envs/jupyterlab/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "loading configuration file ../models/checkpoint-232/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"bert-base-multilingual-cased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.11.3\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 119547\n",
      "}\n",
      "\n",
      "loading weights file ../models/checkpoint-232/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing BertForSequenceClassification.\n",
      "\n",
      "All the weights of BertForSequenceClassification were initialized from the model checkpoint at ../models/checkpoint-232/.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForSequenceClassification for predictions without further training.\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "***** Running Prediction *****\n",
      "  Num examples = 76\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='10' max='10' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [10/10 01:14]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file ../models/checkpoint-203/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"bert-base-multilingual-cased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.11.3\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 119547\n",
      "}\n",
      "\n",
      "loading weights file ../models/checkpoint-203/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing BertForSequenceClassification.\n",
      "\n",
      "All the weights of BertForSequenceClassification were initialized from the model checkpoint at ../models/checkpoint-203/.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForSequenceClassification for predictions without further training.\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "***** Running Prediction *****\n",
      "  Num examples = 76\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='10' max='10' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [10/10 01:17]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/koredeakande/opt/anaconda3/envs/jupyterlab/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "loading configuration file ../models/checkpoint-261/config.json\n",
      "Model config BertConfig {\n",
      "  \"_name_or_path\": \"bert-base-multilingual-cased\",\n",
      "  \"architectures\": [\n",
      "    \"BertForSequenceClassification\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"directionality\": \"bidi\",\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-12,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"model_type\": \"bert\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_fc_size\": 768,\n",
      "  \"pooler_num_attention_heads\": 12,\n",
      "  \"pooler_num_fc_layers\": 3,\n",
      "  \"pooler_size_per_head\": 128,\n",
      "  \"pooler_type\": \"first_token_transform\",\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"problem_type\": \"single_label_classification\",\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.11.3\",\n",
      "  \"type_vocab_size\": 2,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 119547\n",
      "}\n",
      "\n",
      "loading weights file ../models/checkpoint-261/pytorch_model.bin\n",
      "All model checkpoint weights were used when initializing BertForSequenceClassification.\n",
      "\n",
      "All the weights of BertForSequenceClassification were initialized from the model checkpoint at ../models/checkpoint-261/.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BertForSequenceClassification for predictions without further training.\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n",
      "***** Running Prediction *****\n",
      "  Num examples = 76\n",
      "  Batch size = 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='10' max='10' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [10/10 01:17]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#List to store validation set results for the different checkpoints\n",
    "val_results = []\n",
    "\n",
    "#Iterate through all the subfolders in the main directory          \n",
    "for folder in glob('../models/*/'):\n",
    "    \n",
    "    #If it is a model save checkpoint\n",
    "    if 'checkpoint' in folder:\n",
    "    \n",
    "        #Load the checkpoint\n",
    "        model = BertForSequenceClassification.from_pretrained(folder)\n",
    "\n",
    "        training_args = TrainingArguments(\n",
    "        output_dir = \"../model_predictions\",\n",
    "        do_predict = True)\n",
    "\n",
    "        trainer = Trainer(\n",
    "            model           = model,\n",
    "            args            = training_args,\n",
    "            compute_metrics =compute_metrics)\n",
    "\n",
    "        model_preds_and_results = trainer.predict(val_set_dataset)\n",
    "\n",
    "        val_results.append(model_preds_and_results[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72a4ff05-1e6f-4aa3-8a23-9d3a50201655",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "5d289767-e4dc-4a39-aadb-a22b0e359bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "results_df = pd.DataFrame(val_results)\n",
    "results_df.insert(0,'model_checkpoint',[re.search('checkpoint-\\d+',checkpoint)[0] for checkpoint in (glob('../models/*/')) if 'checkpoint' in checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "251867ad-ab60-4061-b8a6-ae22982be324",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model_checkpoint</th>\n",
       "      <th>test_loss</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>test_f1</th>\n",
       "      <th>test_precision</th>\n",
       "      <th>test_recall</th>\n",
       "      <th>test_runtime</th>\n",
       "      <th>test_samples_per_second</th>\n",
       "      <th>test_steps_per_second</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>checkpoint-29</td>\n",
       "      <td>0.985939</td>\n",
       "      <td>0.565789</td>\n",
       "      <td>0.408890</td>\n",
       "      <td>0.320118</td>\n",
       "      <td>0.565789</td>\n",
       "      <td>90.8152</td>\n",
       "      <td>0.837</td>\n",
       "      <td>0.110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>checkpoint-116</td>\n",
       "      <td>1.327372</td>\n",
       "      <td>0.644737</td>\n",
       "      <td>0.570270</td>\n",
       "      <td>0.660313</td>\n",
       "      <td>0.644737</td>\n",
       "      <td>86.2949</td>\n",
       "      <td>0.881</td>\n",
       "      <td>0.116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>checkpoint-58</td>\n",
       "      <td>0.918521</td>\n",
       "      <td>0.657895</td>\n",
       "      <td>0.635467</td>\n",
       "      <td>0.652943</td>\n",
       "      <td>0.657895</td>\n",
       "      <td>86.1463</td>\n",
       "      <td>0.882</td>\n",
       "      <td>0.116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>checkpoint-203</td>\n",
       "      <td>1.201182</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>0.658236</td>\n",
       "      <td>0.646460</td>\n",
       "      <td>0.684211</td>\n",
       "      <td>86.9010</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>checkpoint-290</td>\n",
       "      <td>1.361241</td>\n",
       "      <td>0.697368</td>\n",
       "      <td>0.686283</td>\n",
       "      <td>0.682873</td>\n",
       "      <td>0.697368</td>\n",
       "      <td>88.4328</td>\n",
       "      <td>0.859</td>\n",
       "      <td>0.113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>checkpoint-261</td>\n",
       "      <td>1.327470</td>\n",
       "      <td>0.697368</td>\n",
       "      <td>0.677505</td>\n",
       "      <td>0.660383</td>\n",
       "      <td>0.697368</td>\n",
       "      <td>86.7420</td>\n",
       "      <td>0.876</td>\n",
       "      <td>0.115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>checkpoint-145</td>\n",
       "      <td>1.171518</td>\n",
       "      <td>0.710526</td>\n",
       "      <td>0.684230</td>\n",
       "      <td>0.684649</td>\n",
       "      <td>0.710526</td>\n",
       "      <td>85.9271</td>\n",
       "      <td>0.884</td>\n",
       "      <td>0.116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>checkpoint-232</td>\n",
       "      <td>1.224277</td>\n",
       "      <td>0.710526</td>\n",
       "      <td>0.682639</td>\n",
       "      <td>0.669507</td>\n",
       "      <td>0.710526</td>\n",
       "      <td>83.8298</td>\n",
       "      <td>0.907</td>\n",
       "      <td>0.119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>checkpoint-87</td>\n",
       "      <td>0.884741</td>\n",
       "      <td>0.723684</td>\n",
       "      <td>0.695574</td>\n",
       "      <td>0.674425</td>\n",
       "      <td>0.723684</td>\n",
       "      <td>121.4265</td>\n",
       "      <td>0.626</td>\n",
       "      <td>0.082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>checkpoint-174</td>\n",
       "      <td>0.905348</td>\n",
       "      <td>0.789474</td>\n",
       "      <td>0.756738</td>\n",
       "      <td>0.727052</td>\n",
       "      <td>0.789474</td>\n",
       "      <td>85.8604</td>\n",
       "      <td>0.885</td>\n",
       "      <td>0.116</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  model_checkpoint  test_loss  test_accuracy   test_f1  test_precision  \\\n",
       "1    checkpoint-29   0.985939       0.565789  0.408890        0.320118   \n",
       "4   checkpoint-116   1.327372       0.644737  0.570270        0.660313   \n",
       "3    checkpoint-58   0.918521       0.657895  0.635467        0.652943   \n",
       "8   checkpoint-203   1.201182       0.684211  0.658236        0.646460   \n",
       "2   checkpoint-290   1.361241       0.697368  0.686283        0.682873   \n",
       "9   checkpoint-261   1.327470       0.697368  0.677505        0.660383   \n",
       "6   checkpoint-145   1.171518       0.710526  0.684230        0.684649   \n",
       "7   checkpoint-232   1.224277       0.710526  0.682639        0.669507   \n",
       "0    checkpoint-87   0.884741       0.723684  0.695574        0.674425   \n",
       "5   checkpoint-174   0.905348       0.789474  0.756738        0.727052   \n",
       "\n",
       "   test_recall  test_runtime  test_samples_per_second  test_steps_per_second  \n",
       "1     0.565789       90.8152                    0.837                  0.110  \n",
       "4     0.644737       86.2949                    0.881                  0.116  \n",
       "3     0.657895       86.1463                    0.882                  0.116  \n",
       "8     0.684211       86.9010                    0.875                  0.115  \n",
       "2     0.697368       88.4328                    0.859                  0.113  \n",
       "9     0.697368       86.7420                    0.876                  0.115  \n",
       "6     0.710526       85.9271                    0.884                  0.116  \n",
       "7     0.710526       83.8298                    0.907                  0.119  \n",
       "0     0.723684      121.4265                    0.626                  0.082  \n",
       "5     0.789474       85.8604                    0.885                  0.116  "
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df.sort_values('test_accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f00adba-b433-46b4-b507-2f1a0e9460e9",
   "metadata": {},
   "source": [
    "Checkpoint-174 appeared to do best across most of the metrics. Hence I use this to predict the test set"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
