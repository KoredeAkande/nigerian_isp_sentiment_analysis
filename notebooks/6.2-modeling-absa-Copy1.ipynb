{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fba88215-aab4-4b5a-b8f5-80fc0d628f93",
   "metadata": {},
   "source": [
    "# Modeling: Aspect-Based Sentiment Analysis [Simplistic]\n",
    "Conducting aspect-based sentiment analysis with [ABSA package by Scala Consultants](https://github.com/ScalaConsultants/Aspect-Based-Sentiment-Analysis)\n",
    "\n",
    "**`Goal:`** \n",
    "\n",
    "Conduct ABSA using word relatedness and out-of-the-box ABSA package. This notebook is meant to serve as a start for tweet aspect annotation by getting as much of the aspects indicated and their corresponding sentiments. \n",
    "\n",
    "**Note:** Results will be crosschecked during the annotation phase!\n",
    "\n",
    "**`Process:`** \n",
    "1. List aspects (e.g. speed, price, reliability) determined from earlier data annotation phase\n",
    "2. Get nouns, adjectives and adverbs from the tweets as these will likely be the parts of speech making meaningful reference to aspects\n",
    "3. Check if each of the words from step 2 is very similar to any of the aspects (e.g. speed [aspect] and fast [word in tweet]) by computing relatedness score (via word embedding)\n",
    "4. If relatedness score is past a set thresholdhood, we assume the aspect was referenced in the tweet. Hence, note down that the aspect category was referenced in that given tweet and also note down the word (herein called aspect term) that implied the aspect\n",
    "6. Conduct ABSA using the ABSA package with the tweet and with the aspect term and note sentiment (positive, negative or neutral) towards the main aspect (price, speed, etc.)\n",
    "7. If multiple words make reference to a single aspect, find the average of their sentiments and use to assign a single sentiment "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d062c92e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# python -m spacy download en_core_web_md\n",
    "# python -m spacy download en_core_web_lg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c11b87e-67cd-44e7-a51c-e26a44c442f4",
   "metadata": {},
   "source": [
    "### 1. Library Importation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7ef903c6-788c-4790-ae9a-8e7eaf9dac83",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-16 11:34:43.674381: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import aspect_based_sentiment_analysis as absa\n",
    "import nltk\n",
    "from nltk import pos_tag, RegexpParser\n",
    "\n",
    "#Packages for word relatedness computation\n",
    "import spacy\n",
    "spacy_nlp = spacy.load('en_core_web_lg')\n",
    "\n",
    "from itertools import product\n",
    "from cleantext import clean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f196af6-46fc-46fc-b124-d0c0f8a490e6",
   "metadata": {},
   "source": [
    "### 2. Loading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d50c70f7-0099-4f15-8e56-74c646ee921f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/processed/sample_encoded_and_cleaned_no_punct.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "72aa0c30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ISP_Name</th>\n",
       "      <th>Time</th>\n",
       "      <th>Text</th>\n",
       "      <th>Source</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sprectranet</td>\n",
       "      <td>2020-02-04 18:30:35+00:00</td>\n",
       "      <td>my family used my spectranet and they dont wan...</td>\n",
       "      <td>Twitter for Android</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sprectranet</td>\n",
       "      <td>2019-06-19 04:59:49</td>\n",
       "      <td>spectranetng how can i get the freedom mifi in...</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sprectranet</td>\n",
       "      <td>2020-03-30 07:57:38+00:00</td>\n",
       "      <td>drolufunmilayo iconicremi spectranetng</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sprectranet</td>\n",
       "      <td>2020-12-31 21:07:52+00:00</td>\n",
       "      <td>spectranetng your response just proves how hor...</td>\n",
       "      <td>Twitter for Android</td>\n",
       "      <td>Negative</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sprectranet</td>\n",
       "      <td>2020-09-03 23:09:09+00:00</td>\n",
       "      <td>spectranet is just the worse tbh i cant even w...</td>\n",
       "      <td>Twitter for iPhone</td>\n",
       "      <td>Negative</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      ISP_Name                       Time  \\\n",
       "0  sprectranet  2020-02-04 18:30:35+00:00   \n",
       "1  sprectranet        2019-06-19 04:59:49   \n",
       "2  sprectranet  2020-03-30 07:57:38+00:00   \n",
       "3  sprectranet  2020-12-31 21:07:52+00:00   \n",
       "4  sprectranet  2020-09-03 23:09:09+00:00   \n",
       "\n",
       "                                                Text               Source  \\\n",
       "0  my family used my spectranet and they dont wan...  Twitter for Android   \n",
       "1  spectranetng how can i get the freedom mifi in...   Twitter for iPhone   \n",
       "2             drolufunmilayo iconicremi spectranetng   Twitter for iPhone   \n",
       "3  spectranetng your response just proves how hor...  Twitter for Android   \n",
       "4  spectranet is just the worse tbh i cant even w...   Twitter for iPhone   \n",
       "\n",
       "  sentiment  label  \n",
       "0   Neutral      1  \n",
       "1   Neutral      1  \n",
       "2   Neutral      1  \n",
       "3  Negative      0  \n",
       "4  Negative      0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "24e6e9d1-55fe-489a-bac7-4daad62c23c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Negative    216\n",
       "Neutral     133\n",
       "Positive     29\n",
       "Name: sentiment, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sentiment.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3b8d956e-53a3-4dc9-8da3-dfa6b60d3c9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some layers from the model checkpoint at absa/classifier-rest-0.2 were not used when initializing BertABSClassifier: ['dropout_379']\n",
      "- This IS expected if you are initializing BertABSClassifier from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertABSClassifier from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some layers of BertABSClassifier were not initialized from the model checkpoint at absa/classifier-rest-0.2 and are newly initialized: ['dropout_75']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "#Load the model for ABSA modeling\n",
    "nlp = absa.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5372bfb5-132c-41d5-9b84-05ae1dfa8974",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('price', price),\n",
       " ('speed', speed),\n",
       " ('reliability', reliability),\n",
       " ('coverage', coverage),\n",
       " ('customer service', customer service)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#1. List aspects determined during the annotation phase\n",
    "    #Note: This might not be exhaustive! But it should cover most cases. It is also subjective!\n",
    "    #Also using synonyms of these words will likely yield different results\n",
    "aspects = ['price','speed','reliability','coverage', 'customer service']\n",
    "\n",
    "#2. Pair aspects with their tokenized form to avoid recomputation in the ABSA phase below\n",
    "aspects_with_token = [] #List to store the pairing\n",
    "\n",
    "#Iterate through the aspects and compute their word vector using spacy\n",
    "for aspect in aspects:\n",
    "    aspects_with_token.append((aspect,spacy_nlp(aspect)))\n",
    "    \n",
    "aspects_with_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "166400e7-ab49-4f0d-96db-5a69aecd4fc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Set to store all seen words\n",
    "seen_words = set()\n",
    "\n",
    "#Set to store all aspect implying words found – to avoid recomputing similarity scores\n",
    "aspect_implying_words_glob = set()\n",
    "\n",
    "#Dictionary categorizing all aspect-implying words into their relevant aspects\n",
    "aspects_with_implying_words = {'price':set(),'speed':set(),'reliability':set(),\n",
    "                               'coverage':set(), 'customer service':set()}\n",
    "\n",
    "#List to store detected aspects and their sentiments\n",
    "df_list = []\n",
    "\n",
    "#Similarity threshold\n",
    "sim_thresh = 0.5\n",
    "\n",
    "#Iterate through all the tweets\n",
    "for tweet in df.Text:\n",
    "    \n",
    "    #Set to store the detected aspects at the sentence level\n",
    "    # detected_aspects = set()\n",
    "    \n",
    "    #Dictionary to store the sentiment value for each seen aspect\n",
    "    sentence_lvl_aspect_sentiment = {'price':[],'speed':[],'reliability':[],\n",
    "                                     'coverage':[], 'customer service':[]}\n",
    "        \n",
    "    #Split the tweet into words\n",
    "    text = tweet.split()\n",
    "\n",
    "    #Tag words with part of speech\n",
    "    tokens_tag = pos_tag(text)\n",
    "\n",
    "    #Iterate through all the tagged words\n",
    "    for token in tokens_tag:\n",
    "        \n",
    "        #Get the current word in focus\n",
    "        word_in_focus = token[0]\n",
    "        \n",
    "        #If the word has been seen before\n",
    "        if word_in_focus in seen_words:\n",
    "            \n",
    "            #Check if the word is an aspect-implying word\n",
    "            if word_in_focus in aspect_implying_words_glob:\n",
    "                \n",
    "                #List to store all the aspects found to related to the certain word/token\n",
    "                aspects_implied = []\n",
    "            \n",
    "                #If it is an aspect-implying word, iterate through all the aspects\n",
    "                for aspect in aspects_with_implying_words.keys():\n",
    "                    \n",
    "                    #Check if the word_in_focus was noted as a word implying the aspect\n",
    "                    if word_in_focus in aspects_with_implying_words[aspect]:\n",
    "                        \n",
    "                        #Get all the aspects the word_in_focus implies\n",
    "                        aspects_implied.append(aspect)\n",
    "                        \n",
    "            \n",
    "            else:\n",
    "                continue\n",
    "                    \n",
    "         \n",
    "        #If the word hasn't been seen before\n",
    "        else:\n",
    "            \n",
    "            #Mark the word as seen now\n",
    "            seen_words.add(word_in_focus)\n",
    "        \n",
    "            #Check if the tagged word is a noun, adjective or adverb\n",
    "            regex_match = re.match('NN.?|JJ.?|RB.?',token[1])\n",
    "\n",
    "            #If it is one of the mentioned parts of speech\n",
    "            if regex_match:\n",
    "                \n",
    "                #List to store all the aspects found to related to the certain word/token\n",
    "                #Ideally a given word won't imply multiple of the aspects as they are fairly independent\n",
    "                #-but just in case \n",
    "                aspects_implied = []\n",
    "                \n",
    "                #Iterate through all the aspects\n",
    "                for aspect,asp_token in aspects_with_token:\n",
    "                    \n",
    "                    #Translate word_in_focus to word vector\n",
    "                    spacy_token = spacy_nlp(word_in_focus)\n",
    "\n",
    "                    #Compute the similarity between the two word vectors (i.e. the two words)\n",
    "                    #Round up to 1 d.p.\n",
    "                    similarity_score = round(asp_token.similarity(spacy_token),1)\n",
    "                        \n",
    "                    #If the max similarity score seen is greater than the threshold\n",
    "                    if similarity_score > sim_thresh:\n",
    "\n",
    "                        #Add the word to the set of all aspect-implying words seen\n",
    "                        aspect_implying_words_glob.add(word_in_focus)\n",
    "\n",
    "                        #Add the word to the dictionary of the relevant aspect word\n",
    "                        aspects_with_implying_words[aspect].add(word_in_focus)\n",
    "                        \n",
    "                        #Note that the aspect has been found in this particular sentence\n",
    "                        # detected_aspects.add(aspect)\n",
    "\n",
    "                        #Add the aspect to the list of aspects that the word_in_focus implies\n",
    "                        aspects_implied.append(aspect)\n",
    "                        \n",
    "                        \n",
    "                     \n",
    "                    #If the word is not an aspect implying word, continue to next word\n",
    "                    else:\n",
    "                        \n",
    "                        continue\n",
    "            \n",
    "            else:\n",
    "                continue\n",
    "                \n",
    "        \n",
    "        #Calculate the sentiment scores for the aspect_implying word in the current sentence\n",
    "        sentiment = nlp(tweet ,aspects = [word_in_focus])\n",
    "        sentiment_scores = sentiment.subtasks[word_in_focus].examples[0].scores\n",
    "\n",
    "        #Note down the scores for all the implied aspects\n",
    "        for aspect in aspects_implied:\n",
    "            sentence_lvl_aspect_sentiment[aspect].append(sentiment_scores)\n",
    "    \n",
    "    #List to store the detected aspects from the sentence\n",
    "    detected_aspects = []\n",
    "    \n",
    "    #List to store the determined sentiments of the detected aspects\n",
    "    detected_sentiments = []\n",
    "    \n",
    "    #Iterate through all the aspects\n",
    "    for aspect in sentence_lvl_aspect_sentiment.keys():\n",
    "        \n",
    "        #If the aspect was detected in the sentence\n",
    "        if sentence_lvl_aspect_sentiment[aspect]:\n",
    "            \n",
    "            #Record this\n",
    "            detected_aspects.append(aspect)\n",
    "            \n",
    "            #Calculate the average sentiment scores across the different terms\n",
    "            avg_senti_score = np.array(sentence_lvl_aspect_sentiment[aspect]).mean(axis=0)\n",
    "            \n",
    "            #Get the sentiment category (neutral,negative,positive) with the largest probability\n",
    "            max_idx = np.argmax(avg_senti_score)\n",
    "\n",
    "            if max_idx == 2:\n",
    "\n",
    "                detected_sentiments.append(\"Positive\")\n",
    "\n",
    "            elif max_idx == 1:\n",
    "\n",
    "                detected_sentiments.append(\"Negative\")\n",
    "\n",
    "            else:\n",
    "\n",
    "                detected_sentiments.append(\"Neutral\")\n",
    "    \n",
    "    #Add the detected aspects and sentiments from the sentence to the list\n",
    "    if detected_aspects:\n",
    "        df_list.append([tweet,detected_aspects,detected_sentiments])\n",
    "    else:\n",
    "        df_list.append([tweet,None,None])\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "159d93a0-4570-41c9-9df1-663573e5f1e2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/koredeakande/opt/anaconda3/envs/capstone/lib/python3.7/site-packages/ipykernel_launcher.py:111: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n"
     ]
    }
   ],
   "source": [
    "#Set to store all seen words\n",
    "seen_words = set()\n",
    "\n",
    "#Set to store all aspect implying words found – to avoid recomputing similarity scores\n",
    "aspect_implying_words_glob = set()\n",
    "\n",
    "#Dictionary categorizing all aspect-implying words into their relevant aspects\n",
    "aspects_with_implying_words = {'price':set(),'speed':set(),'reliability':set(),\n",
    "                               'coverage':set(), 'customer service':set()}\n",
    "\n",
    "#List to store detected aspects and their sentiments\n",
    "df_list = []\n",
    "\n",
    "#Similarity threshold\n",
    "sim_thresh = 0.5\n",
    "\n",
    "#Chunk tags to match – i.e. parts of speech to extract\n",
    "CHUNK_TAG = \"\"\"\n",
    "MATCH: {<NN>+|<NN.*>+}\n",
    "{<JJ.*>?}\n",
    "{<RB.*>?}\n",
    "\"\"\"\n",
    "\n",
    "#Initialize chunk tag parser\n",
    "cp = nltk.RegexpParser(CHUNK_TAG)\n",
    "\n",
    "#Iterate through all the tweets\n",
    "for tweet in df.Text:\n",
    "    \n",
    "    #Set to store the detected aspects at the sentence level\n",
    "    # detected_aspects = set()\n",
    "    \n",
    "    #Dictionary to store the sentiment value for each seen aspect\n",
    "    sentence_lvl_aspect_sentiment = {'price':[],'speed':[],'reliability':[],\n",
    "                                     'coverage':[], 'customer service':[]}\n",
    "        \n",
    "    #Split the tweet into words\n",
    "    text = tweet.split()\n",
    "\n",
    "    #Tag the words with their part of speech\n",
    "    tokens_tag = pos_tag(text)\n",
    "    \n",
    "    #Get the words with relevant POS (noun, adverbs, adjectives)\n",
    "    chunk_result = cp.parse(tokens_tag)\n",
    "    \n",
    "    #Extract chunk results from tree into list \n",
    "    chunk_items = [list(n) for n in chunk_result if isinstance(n, nltk.tree.Tree)]\n",
    "    \n",
    "    #Finally fuse/extract chunked words to get (noun) phrases, nouns, adverbs, adjectives\n",
    "    #1. List to store the words\n",
    "    matched_words = []\n",
    "    \n",
    "    #2. Iterate through the chunked words lists and get the relevant words\n",
    "    for item in chunk_items:\n",
    "        if len(item) > 1:\n",
    "            full_string = []\n",
    "\n",
    "            for word in item:\n",
    "                full_string.append(word[0])\n",
    "\n",
    "            matched_words.append(' '.join(full_string))\n",
    "\n",
    "        else:\n",
    "            matched_words.append(item[0][0])\n",
    "        \n",
    "    #Iterate through all the words\n",
    "    for word_in_focus in matched_words:\n",
    "        \n",
    "        #If the word has been seen before\n",
    "        if word_in_focus in seen_words:\n",
    "            \n",
    "            #Check if the word is an aspect-implying word\n",
    "            if word_in_focus in aspect_implying_words_glob:\n",
    "                \n",
    "                #List to store all the aspects found to related to the certain word/token\n",
    "                aspects_implied = []\n",
    "            \n",
    "                #If it is an aspect-implying word, iterate through all the aspects\n",
    "                for aspect in aspects_with_implying_words.keys():\n",
    "                    \n",
    "                    #Check if the word_in_focus was noted as a word implying the aspect\n",
    "                    if word_in_focus in aspects_with_implying_words[aspect]:\n",
    "                        \n",
    "                        #Get all the aspects the word_in_focus implies\n",
    "                        aspects_implied.append(aspect)\n",
    "                        \n",
    "            \n",
    "            else:\n",
    "                continue\n",
    "                    \n",
    "         \n",
    "        #If the word hasn't been seen before\n",
    "        else:\n",
    "            \n",
    "            #Mark the word as seen now\n",
    "            seen_words.add(word_in_focus)\n",
    "                \n",
    "            #List to store all the aspects found to related to the certain word/token\n",
    "            #Ideally a given word won't imply multiple of the aspects as they are fairly independent\n",
    "            #-but just in case \n",
    "            aspects_implied = []\n",
    "\n",
    "            #Iterate through all the aspects\n",
    "            for aspect,asp_token in aspects_with_token:\n",
    "\n",
    "                #Translate word_in_focus to word vector\n",
    "                spacy_token = spacy_nlp(word_in_focus)\n",
    "\n",
    "                #Compute the similarity between the two word vectors (i.e. the two words)\n",
    "                #Round up to 1 d.p.\n",
    "                similarity_score = round(asp_token.similarity(spacy_token),1)\n",
    "\n",
    "                #If the max similarity score seen is greater than the threshold\n",
    "                if similarity_score >= sim_thresh:\n",
    "\n",
    "                    #Add the word to the set of all aspect-implying words seen\n",
    "                    aspect_implying_words_glob.add(word_in_focus)\n",
    "\n",
    "                    #Add the word to the dictionary of the relevant aspect word\n",
    "                    aspects_with_implying_words[aspect].add(word_in_focus)\n",
    "\n",
    "                    #Note that the aspect has been found in this particular sentence\n",
    "                    # detected_aspects.add(aspect)\n",
    "\n",
    "                    #Add the aspect to the list of aspects that the word_in_focus implies\n",
    "                    aspects_implied.append(aspect)\n",
    "\n",
    "\n",
    "\n",
    "                #If the word is not an aspect implying word, continue to next word\n",
    "                else:\n",
    "\n",
    "                    continue\n",
    "                \n",
    "        \n",
    "        #Calculate the sentiment scores for the aspect_implying word in the current sentence\n",
    "        sentiment = nlp(tweet ,aspects = [word_in_focus])\n",
    "        sentiment_scores = sentiment.subtasks[word_in_focus].examples[0].scores\n",
    "\n",
    "        #Note down the scores for all the implied aspects\n",
    "        for aspect in aspects_implied:\n",
    "            sentence_lvl_aspect_sentiment[aspect].append(sentiment_scores)\n",
    "    \n",
    "    #List to store the detected aspects from the sentence\n",
    "    detected_aspects = []\n",
    "    \n",
    "    #List to store the determined sentiments of the detected aspects\n",
    "    detected_sentiments = []\n",
    "    \n",
    "    #Iterate through all the aspects\n",
    "    for aspect in sentence_lvl_aspect_sentiment.keys():\n",
    "        \n",
    "        #If the aspect was detected in the sentence\n",
    "        if sentence_lvl_aspect_sentiment[aspect]:\n",
    "            \n",
    "            #Record this\n",
    "            detected_aspects.append(aspect)\n",
    "            \n",
    "            #Calculate the average sentiment scores across the different terms\n",
    "            avg_senti_score = np.array(sentence_lvl_aspect_sentiment[aspect]).mean(axis=0)\n",
    "            \n",
    "            #Get the sentiment category (neutral,negative,positive) with the largest probability\n",
    "            max_idx = np.argmax(avg_senti_score)\n",
    "\n",
    "            if max_idx == 2:\n",
    "\n",
    "                detected_sentiments.append(\"Positive\")\n",
    "\n",
    "            elif max_idx == 1:\n",
    "\n",
    "                detected_sentiments.append(\"Negative\")\n",
    "\n",
    "            else:\n",
    "\n",
    "                detected_sentiments.append(\"Neutral\")\n",
    "    \n",
    "    #Add the detected aspects and sentiments from the sentence to the list\n",
    "    if detected_aspects:\n",
    "        df_list.append([tweet,detected_aspects,detected_sentiments])\n",
    "    else:\n",
    "        df_list.append([tweet,None,None])\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a4e5e34d-297c-4dfd-a6de-5f0044861094",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'price': {'buy spectranetng',\n",
       "  'price',\n",
       "  'purchase',\n",
       "  'value',\n",
       "  'value spectranet'},\n",
       " 'speed': {'download speed',\n",
       "  'fast',\n",
       "  'internet speed',\n",
       "  'slow',\n",
       "  'slower',\n",
       "  'snail speed',\n",
       "  'speed',\n",
       "  'speed abeg',\n",
       "  'speeds'},\n",
       " 'reliability': {'network quality', 'reliable', 'usefulness'},\n",
       " 'coverage': {'coverage', 'insurance claim', 'network coverage'},\n",
       " 'customer service': {'business',\n",
       "  'company',\n",
       "  'customer',\n",
       "  'customer care',\n",
       "  'customer care line isnt',\n",
       "  'customer service',\n",
       "  'customer service experience',\n",
       "  'customers',\n",
       "  'disgusting customer service',\n",
       "  'ifes business',\n",
       "  'internet connection',\n",
       "  'internet service',\n",
       "  'internet service provider',\n",
       "  'isp business',\n",
       "  'network provider',\n",
       "  'network quality',\n",
       "  'network reception',\n",
       "  'network service',\n",
       "  'provider i',\n",
       "  'providers',\n",
       "  'reliable',\n",
       "  'service',\n",
       "  'service i',\n",
       "  'service provider',\n",
       "  'service subscription failure',\n",
       "  'services',\n",
       "  'services i',\n",
       "  'spectranet ltd internet subscription n18525',\n",
       "  'teleport service',\n",
       "  'ticket number internet',\n",
       "  'tizeti internet service provider'}}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aspects_with_implying_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ea665475-4c9a-4a45-841f-c18421790031",
   "metadata": {},
   "outputs": [],
   "source": [
    "absa_df = pd.DataFrame(df_list, \n",
    "                       columns=['Tweets','Detected aspects','Corresponding sentiment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b218bfb5-5716-4480-a9f0-4c296cbbe876",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Tweets</th>\n",
       "      <th>Detected aspects</th>\n",
       "      <th>Corresponding sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>my family used my spectranet and they dont wan...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>spectranetng how can i get the freedom mifi in...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>drolufunmilayo iconicremi spectranetng</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>spectranetng your response just proves how hor...</td>\n",
       "      <td>[customer service]</td>\n",
       "      <td>[Negative]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>spectranet is just the worse tbh i cant even w...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>373</th>\n",
       "      <td>spectranet unlimited value for money</td>\n",
       "      <td>[price]</td>\n",
       "      <td>[Positive]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>374</th>\n",
       "      <td>from 30th may to date mtn mifi 10k spectranet ...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>375</th>\n",
       "      <td>spectranetng fritzthejanitor will they help me...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>376</th>\n",
       "      <td>thefunkydee spectranetng im giving spectranetn...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>377</th>\n",
       "      <td>50gb gone in one week spectranetng na so i am ...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>378 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Tweets    Detected aspects  \\\n",
       "0    my family used my spectranet and they dont wan...                None   \n",
       "1    spectranetng how can i get the freedom mifi in...                None   \n",
       "2               drolufunmilayo iconicremi spectranetng                None   \n",
       "3    spectranetng your response just proves how hor...  [customer service]   \n",
       "4    spectranet is just the worse tbh i cant even w...                None   \n",
       "..                                                 ...                 ...   \n",
       "373               spectranet unlimited value for money             [price]   \n",
       "374  from 30th may to date mtn mifi 10k spectranet ...                None   \n",
       "375  spectranetng fritzthejanitor will they help me...                None   \n",
       "376  thefunkydee spectranetng im giving spectranetn...                None   \n",
       "377  50gb gone in one week spectranetng na so i am ...                None   \n",
       "\n",
       "    Corresponding sentiment  \n",
       "0                      None  \n",
       "1                      None  \n",
       "2                      None  \n",
       "3                [Negative]  \n",
       "4                      None  \n",
       "..                      ...  \n",
       "373              [Positive]  \n",
       "374                    None  \n",
       "375                    None  \n",
       "376                    None  \n",
       "377                    None  \n",
       "\n",
       "[378 rows x 3 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "absa_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "86bf7687-1086-4c66-8523-0f1e96f07cc4",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'list'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.map_locations\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: unhashable type: 'list'"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: 'pandas._libs.index.IndexEngine._call_map_locations'\n",
      "Traceback (most recent call last):\n",
      "  File \"pandas/_libs/hashtable_class_helper.pxi\", line 5231, in pandas._libs.hashtable.PyObjectHashTable.map_locations\n",
      "TypeError: unhashable type: 'list'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Negative]                        41\n",
       "[Positive]                        18\n",
       "[Neutral]                         11\n",
       "[Negative, Negative]               4\n",
       "[Negative, Neutral]                1\n",
       "[Positive, Positive, Positive]     1\n",
       "Name: Corresponding sentiment, dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "absa_df[absa_df['Detected aspects'].notnull()]['Corresponding sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2672b4ae-21f7-4496-94e3-ee766530deb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "absa_df.to_csv('../data/model-generated/tweet_absa_default.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74566115-5f61-4f94-b2f7-d05236798808",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8cbc762-a702-4650-9c48-063780ce09e6",
   "metadata": {},
   "source": [
    "[('price', price),\n",
    " ('speed', speed),\n",
    " ('reliability', reliability),\n",
    " ('coverage', coverage),\n",
    " ('customer service', customer service)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c0ad8e3-cb5f-465a-9c07-27a0f2ff3329",
   "metadata": {},
   "source": [
    "- Struggles with connotations and implied meanings. For example, it detected no aspects in the following sentence, despite it hinting at speed:\n",
    "    - 'spectranet is just the worse tbh i cant even watch a 5min video without serious lagging'\n",
    "    - 'day or night spectranetng remain useless' -> Hinting that it is not a reliability service\n",
    " \n",
    "- Struggles to detect references to price or speed if metrics e.g. actual monetary cost in naira or speed in e.g. kbps are referenced\n",
    "    - depend on the kind of mifi smile is 9800 spectranet is like 15k -> Did not detect price\n",
    "    - wifisupport1 tizeti well done ooo 2 hours to download 9mb but na broadband\n",
    "    \n",
    "- Sometimes accurately detects aspects but that isn't always all we want. We want the aspect detected for a particular ISP. E.g.:\n",
    "    - adefola09 they said they dont have coverage at my side oo thinking of getting ipnx. It detects coverage there but this doesn't speak to coverage concerns for ipnx\n",
    "    \n",
    "Struggles with contextual meaning of words:\n",
    "\n",
    "- Any reference to service is automatically related to customer service (since the similarity between both is undoubtedly really high) and customers sometimes use the word 'service' to refer to network quality or coverage (see below). This is a problem of using word relatedness:\n",
    "    - omo ive been wallowing in ignoranceappaz my spectranet sub had elapsed 100gb and i didnt even realize and ive been ranting about **bad service** meanwhile they have another package for 19k that is 500gb and ive been doing 100gb for 18k e be things o\n",
    "    - ripples143 wifisupport1 tizeti they have a lot of downtime like a lot they are making it seem as though its **free service** i ducking pay for this you are not doing me a favour\n",
    "    \n",
    "- Similarly, any reference to speed is assumed to reference the network speed\n",
    "\n",
    "\n",
    "No real reference to reliability as it is often inferred from downtime or long stretches of poor service\n",
    "    \n",
    "**Note:** Only marked down tweets that referred clearly to an aspect of the ISP's service – some where vague and so the aspect couldn't be determined e.g. 'airtel and tizeti have failed me'\n",
    "\n",
    "\n",
    "Huge overlap between coverage, speed, and reliability.\n",
    "    \n",
    "Also the issue that users cite the wrong issue for their problem. For example one tweet says 'can't even get internet to do my work.' It could very well be the case that there is coverage (i.e. internet signal), but the speed isn't ideal\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea9a223e-8686-4c00-8679-aa58f0fafb50",
   "metadata": {},
   "source": [
    "## Terminology"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fbabb49-6201-41a4-91fc-e41485d92d70",
   "metadata": {},
   "source": [
    "Network availability is the percentage of time the infrastructure is operational during a given time period. ... Network reliability tracks how long the infrastructure is functional without interruption.\n",
    "\n",
    "\n",
    "Network availability provides a glimpse into infrastructure accessibility, while network reliability highlights how well the infrastructure runs to support functional processes.\n",
    "\n",
    "\n",
    "https://www.techtarget.com/searchnetworking/answer/Whats-the-difference-between-network-availability-and-reliability#:~:text=Although%20the%20terms%20are%20sometimes,during%20a%20given%20time%20period.&text=Network%20reliability%20tracks%20how%20long%20the%20infrastructure%20is%20functional%20without%20interruption."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7616b075-fc65-4108-a0f7-f9472ac7f9c1",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Simply put, network reliability signifies the ability of a network to minimize the scope and frequency of network incidents, continue operations while under pressure and recover as quickly as possible.\n",
    "- Downtime: How much time does your network to recover from incidents? How does it graph over time?\n",
    "- Failure frequency: Frequency with which your network fails to act or respond the way it is designed to.\n",
    "\n",
    "\n",
    "Simply put, network reliability highlights your network’s ability to run the infrastructure and support core processes whereas network availability just provides a measure of infrastructure accessibility.\n",
    "\n",
    "https://www.newchartertech.com/network-reliability-the-invisible-driver-of-business-productivity/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa2bec1c-5a99-49ce-983a-a3d663ea5a24",
   "metadata": {},
   "source": [
    "\n",
    "**Reliability:** Ability of a system or component to perform its required functions under stated\n",
    "conditions for a specified period of time. \n",
    "\n",
    "https://www.iiconsortium.org/pdf/Trustworthiness_Framework_Foundations.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5d47137-b5a6-4fcc-b7d8-1b96bb73702c",
   "metadata": {},
   "source": [
    "---\n",
    "## Thoughts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad2bd5ed-088a-4ec7-bcc4-4a16fc63540a",
   "metadata": {},
   "source": [
    "- Include notion of honesty or trust?\n",
    "- The word relatedness usage is only as good as the word embedding – scam and dishonest were not recognized as being very related.\n",
    "    - **Solution:** Try other word embeddings? GLove perhaps\n",
    "- Add device-related feature e.g. device#battery? Based on the following tweet:\n",
    "    - im essentially grateful for my spectranet battery strength health that shit can go 910 hours on full charge its amazing\n",
    "- Network generally?\n",
    "- How might we make it learn speed? E.g. kbps, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a81f57ca-affe-411f-a958-d8ecf521f2e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['price', 'speed', 'reliability', 'coverage', 'customer service']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aspects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d4e08ae0-c021-4011-8960-16e4e13b2be5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                    None\n",
       "1                    None\n",
       "2                    None\n",
       "3      [customer service]\n",
       "4                    None\n",
       "              ...        \n",
       "373               [price]\n",
       "374                  None\n",
       "375                  None\n",
       "376                  None\n",
       "377                  None\n",
       "Name: Detected aspects, Length: 378, dtype: object"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "absa_df['Detected aspects']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a9452f9-6f2c-4029-be8d-5a4bbe3f6bcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def micro_precision(true_aspects,aspect_preds):\n",
    "    \n",
    "    #Iterate through all the aspects\n",
    "    for aspect in aspects:\n",
    "        \n",
    "        #Initialize counters for true and false positives\n",
    "        TP,FP = 0, 0\n",
    "        \n",
    "        for idx in len(aspect_preds):\n",
    "            \n",
    "            \n",
    "        \n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
